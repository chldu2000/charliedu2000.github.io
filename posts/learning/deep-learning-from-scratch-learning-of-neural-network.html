<!DOCTYPE html><html lang="en"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="icon" href="https://afool.top/afool.svg"><script>const prefersDark=window.matchMedia&&window.matchMedia("(prefers-color-scheme: dark)").matches,colorSchemeSetting=localStorage.getItem("vueuse-color-scheme")||"auto";("dark"===colorSchemeSetting||prefersDark&&"light"!==colorSchemeSetting)&&document.documentElement.classList.toggle("dark",!0)</script><script>const locale=localStorage.getItem("valaxy-locale")||"zh-CN";document.documentElement.setAttribute("lang",locale)</script><script type="module" async="" crossorigin="" src="/assets/app-025bdceb.js"></script><style>@charset "UTF-8";.back-to-top{position:fixed;right:-1.5rem;bottom:1rem;z-index:var(--yun-z-go-up-btn);opacity:0;pointer-events:none;color:var(--va-c-primary);transform:translate(0) rotate(270deg);transition:transform var(--va-transition-duration),opacity var(--va-transition-duration-fast)!important}.progress-circle{transition:.3s stroke-dashoffset;transform:rotate(-90deg);transform-origin:50% 50%}.progress-circle-container{position:absolute}.menu-btn{display:inline-flex;position:fixed;left:.8rem;top:.6rem;line-height:1;z-index:var(--yun-z-menu-btn);cursor:pointer}.sidebar .links{display:flex;justify-content:center}.sidebar .link-item{display:inline-flex}.sidebar .link-item .icon{width:2rem;height:2rem}.links-of-author{display:flex;flex-wrap:wrap;justify-content:center}.links-of-author .icon{width:1.5rem;height:1.5rem}.links-of-author-item{line-height:1;font-size:.9rem}.site-nav{display:flex;justify-content:center;overflow:hidden;line-height:1.5;white-space:nowrap;text-align:center;margin-top:1rem}.site-link-item{display:flex;padding:0 15px;align-items:center;border-left:1px solid var(--va-c-gray);flex-direction:column;color:var(--va-c-text)}.site-link-item:first-child,.site-link-item:last-child{line-height:1;padding:0}.site-link-item:first-child{border-left:none;border-right:1px solid var(--va-c-gray)}.site-link-item:last-child{border-left:1px solid var(--va-c-gray)}.site-link-item:nth-child(2){border:none}.site-link-item .count{color:var(--va-c-text);font-family:var(--va-font-sans);display:block;text-align:center;font-size:1rem}.site-link-item .icon{width:1.5rem;height:1.5rem}.site-link-item .icon:hover{color:var(--va-c-primary-light)}.sidebar-panel{padding:.5rem}.site-author-avatar{display:inline-block;line-height:0;position:relative}.site-author-avatar img{height:96px;width:96px;max-width:100%;margin:0;padding:4px;background-color:#fff;box-shadow:0 0 10px #0003;transition:.4s}.site-author-avatar img:hover{box-shadow:0 0 30px rgba(var(--va-c-primary-rgb),.2)}.site-author-name{margin-top:0;margin-bottom:1rem;line-height:1.5}.site-author-status{position:absolute;height:1.8rem;width:1.8rem;bottom:0;right:0;line-height:1.8rem;border-radius:50%;box-shadow:0 1px 2px #0003;background-color:var(--va-c-bg-light);border:1px solid rgba(255,255,255,.1)}.site-name{color:var(--va-c-text);font-family:var(--va-font-serif);font-weight:900}.site-subtitle{color:var(--va-c-gray);display:block}.site-description{color:var(--va-c-text);font-size:.8rem}.va-bg{position:fixed;width:100%;height:100%;z-index:-1;background-image:var(--va-bg-img);background-size:cover;background-position:center;background-repeat:no-repeat;background-attachment:fixed;animation-name:bgFadeIn;animation-duration:2s;opacity:var(--va-bg-img-opacity,1)}@supports (-webkit-touch-callout:none){.va-bg{background-attachment:scroll}}@keyframes bgFadeIn{0%{opacity:0}to{opacity:var(--va-bg-img-opacity,1)}}canvas.fireworks{position:fixed;left:0;top:0;z-index:1;pointer-events:none}*,:after,:before{box-sizing:border-box;border-width:0;border-style:solid;border-color:#e5e7eb}html{line-height:1.5;-webkit-text-size-adjust:100%;-moz-tab-size:4;tab-size:4;font-family:ui-sans-serif,system-ui,-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,Noto Sans,sans-serif,"Apple Color Emoji","Segoe UI Emoji",Segoe UI Symbol,"Noto Color Emoji"}body{margin:0;line-height:inherit}hr{height:0;color:inherit;border-top-width:1px}h1,h2,h3,h4{font-size:inherit;font-weight:inherit}a{color:inherit;text-decoration:inherit}strong{font-weight:bolder}code,pre{font-family:ui-monospace,SFMono-Regular,Menlo,Monaco,Consolas,Liberation Mono,Courier New,monospace;font-size:1em}button{font-family:inherit;font-size:100%;font-weight:inherit;line-height:inherit;color:inherit;margin:0;padding:0}button{text-transform:none}[type=button],button{-webkit-appearance:button;background-color:transparent;background-image:none}blockquote,h1,h2,h3,h4,hr,p,pre{margin:0}ul{list-style:none;margin:0;padding:0}button{cursor:pointer}canvas,img,svg{display:block;vertical-align:middle}img{max-width:100%;height:auto}@font-face{font-family:KaTeX_Main;font-style:normal;font-weight:700;src:url(/assets/KaTeX_Main-Bold-0f60d1b8.woff2) format("woff2"),url(/assets/KaTeX_Main-Bold-c76c5d69.woff) format("woff"),url(/assets/KaTeX_Main-Bold-138ac28d.ttf) format("truetype")}@font-face{font-family:KaTeX_Main;font-style:italic;font-weight:700;src:url(/assets/KaTeX_Main-BoldItalic-99cd42a3.woff2) format("woff2"),url(/assets/KaTeX_Main-BoldItalic-a6f7ec0d.woff) format("woff"),url(/assets/KaTeX_Main-BoldItalic-70ee1f64.ttf) format("truetype")}@font-face{font-family:KaTeX_Main;font-style:italic;font-weight:400;src:url(/assets/KaTeX_Main-Italic-97479ca6.woff2) format("woff2"),url(/assets/KaTeX_Main-Italic-f1d6ef86.woff) format("woff"),url(/assets/KaTeX_Main-Italic-0d85ae7c.ttf) format("truetype")}@font-face{font-family:KaTeX_Main;font-style:normal;font-weight:400;src:url(/assets/KaTeX_Main-Regular-c2342cd8.woff2) format("woff2"),url(/assets/KaTeX_Main-Regular-c6368d87.woff) format("woff"),url(/assets/KaTeX_Main-Regular-d0332f52.ttf) format("truetype")}@font-face{font-family:KaTeX_Math;font-style:italic;font-weight:700;src:url(/assets/KaTeX_Math-BoldItalic-dc47344d.woff2) format("woff2"),url(/assets/KaTeX_Math-BoldItalic-850c0af5.woff) format("woff"),url(/assets/KaTeX_Math-BoldItalic-f9377ab0.ttf) format("truetype")}@font-face{font-family:KaTeX_Math;font-style:italic;font-weight:400;src:url(/assets/KaTeX_Math-Italic-7af58c5e.woff2) format("woff2"),url(/assets/KaTeX_Math-Italic-8a8d2445.woff) format("woff"),url(/assets/KaTeX_Math-Italic-08ce98e5.ttf) format("truetype")}@font-face{font-family:KaTeX_Size2;font-style:normal;font-weight:400;src:url(/assets/KaTeX_Size2-Regular-d04c5421.woff2) format("woff2"),url(/assets/KaTeX_Size2-Regular-2014c523.woff) format("woff"),url(/assets/KaTeX_Size2-Regular-a6b2099f.ttf) format("truetype")}@font-face{font-family:KaTeX_Size3;font-style:normal;font-weight:400;src:url(data:font/woff2;base64,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) format("woff2"),url(/assets/KaTeX_Size3-Regular-6ab6b62e.woff) format("woff"),url(/assets/KaTeX_Size3-Regular-500e04d5.ttf) format("truetype")}.katex{text-rendering:auto;font:1.21em KaTeX_Main,Times New Roman,serif;line-height:1.2;text-indent:0}.katex *{-ms-high-contrast-adjust:none!important;border-color:currentColor}.katex .katex-mathml{clip:rect(1px,1px,1px,1px);border:0;height:1px;overflow:hidden;padding:0;position:absolute;width:1px}.katex .katex-html>.newline{display:block}.katex .base{position:relative;white-space:nowrap;width:-webkit-min-content;width:-moz-min-content;width:min-content}.katex .base,.katex .strut{display:inline-block}.katex .mathnormal{font-family:KaTeX_Math;font-style:italic}.katex .boldsymbol{font-family:KaTeX_Math;font-style:italic;font-weight:700}.katex .vlist-t{border-collapse:collapse;display:inline-table;table-layout:fixed}.katex .vlist-r{display:table-row}.katex .vlist{display:table-cell;position:relative;vertical-align:bottom}.katex .vlist>span{display:block;height:0;position:relative}.katex .vlist>span>span{display:inline-block}.katex .vlist>span>.pstrut{overflow:hidden;width:0}.katex .vlist-t2{margin-right:-2px}.katex .vlist-s{display:table-cell;font-size:1px;min-width:2px;vertical-align:bottom;width:2px}.katex .msupsub{text-align:left}.katex .mfrac>span>span{text-align:center}.katex .mfrac .frac-line{border-bottom-style:solid;display:inline-block;width:100%}.katex .mfrac .frac-line{min-height:1px}.katex .mspace{display:inline-block}.katex .sizing.reset-size3.size1{font-size:.71428571em}.katex .sizing.reset-size6.size3{font-size:.7em}.katex .delimsizing.size3{font-family:KaTeX_Size3}.katex .nulldelimiter{display:inline-block;width:.12em}.katex .delimcenter,.katex .op-symbol{position:relative}.katex .op-symbol.large-op{font-family:KaTeX_Size2}.katex .op-limits>.vlist-t{text-align:center}.katex .mtable .arraycolsep{display:inline-block}.katex .mtable .col-align-c>.vlist-t{text-align:center}.katex-display{display:block;margin:1em 0;text-align:center}.katex-display>.katex{display:block;text-align:center;white-space:nowrap}.katex-display>.katex>.katex-html{display:block;position:relative}body{counter-reset:katexEqnNo mmlEqnNo}html{-webkit-tap-highlight-color:transparent}a{color:var(--va-c-link);font-weight:500}*{outline:0}hr{opacity:.2;margin:1rem}.va-card{background-color:var(--va-c-bg-light)}.flex-center{display:flex;justify-content:center;align-items:center}.inline-flex-center{display:inline-flex;justify-content:center;align-items:center}#app,body,html{margin:0;padding:0;line-height:2}body{background-color:var(--va-c-bg)}a{cursor:pointer}@media screen and (max-width:640px){.markdown-body div[class*=language-]{margin:0 var(--va-code-mobile-margin-x,-1rem)}}@media (min-width:640px){.markdown-body div[class*=language-]{border-radius:6px;margin:16px 0}}.markdown-body code{font-size:.85em}.markdown-body div[class*=language-]{position:relative;background-color:var(--va-code-block-bg);overflow-x:auto}.markdown-body div[class*=language-] code{padding:0 24px;line-height:var(--va-code-line-height);font-size:var(--va-code-font-size);color:var(--va-code-block-color);transition:color .5s;width:fit-content;text-align:left;white-space:pre;word-spacing:normal;word-break:normal;word-wrap:normal;-moz-tab-size:4;-o-tab-size:4;tab-size:4;-webkit-hyphens:none;-moz-hyphens:none;-ms-hyphens:none;hyphens:none}.markdown-body div[class*=language-] pre{position:relative;z-index:1;margin:0;padding:1rem 0;background:0 0;overflow-x:auto}.markdown-body div[class*=language-] pre code{display:block}.markdown-body [class*=language-]>span.copy{position:absolute;top:8px;right:8px;z-index:2;display:block;justify-content:center;align-items:center;border-radius:4px;width:40px;height:40px;background-color:var(--va-code-block-bg);opacity:0;cursor:pointer;background-image:var(--va-icon-copy);background-position:50%;background-size:20px;background-repeat:no-repeat;transition:opacity .25s}.markdown-body [class*=language-]:hover>span.copy{opacity:1}.markdown-body [class*=language-]>span.copy:hover{background-color:var(--va-code-copy-code-hover-bg)}.markdown-body [class*=language-]:before{position:absolute;top:6px;right:12px;z-index:2;font-size:12px;font-weight:500;color:var(--va-c-text-dark-3);transition:color .5s,opacity .5s}.markdown-body [class*=language-]:hover:before{opacity:0}.markdown-body [class~=language-python]:before{content:"py"}.markdown-body [class~=language-bash]:before{content:"sh"}:root{--va-c-text-warning:#544500}.vt-hamburger{display:flex;justify-content:center;align-items:center}.vt-hamburger:hover .vt-hamburger-top{transform:translate(-5.5px)}.vt-hamburger:hover .vt-hamburger-middle{transform:translate(0)}.vt-hamburger:hover .vt-hamburger-bottom{transform:translate(-11px)}.vt-hamburger-container{position:relative;width:22px;height:20px;overflow:hidden}.vt-hamburger-bottom,.vt-hamburger-middle,.vt-hamburger-top{left:0;position:absolute;width:22px;height:2px;background-color:var(--va-c-primary);transition:top .25s,background-color .5s,transform .25s}.vt-hamburger-top{top:0;transform:translate(0)}.vt-hamburger-middle{top:9px;transform:translate(-11px)}.vt-hamburger-bottom{top:18px;transform:translate(-5.5px)}.sidebar{position:fixed;overflow-y:auto;top:0;bottom:0;left:0;width:calc(100vw - 64px);max-width:var(--va-sidebar-width);background-image:var(--yun-sidebar-bg-img);background-color:var(--yun-sidebar-bg-color);background-size:contain;background-repeat:no-repeat;background-position:bottom 1rem center;text-align:center;z-index:var(--yun-z-sidebar);transform:translate(-100%);transition:box-shadow var(--va-transition-duration),background-color var(--va-transition-duration),opacity .25s,transform var(--va-transition-duration) cubic-bezier(.19,1,.22,1)!important}h2:focus .header-anchor,h2:hover .header-anchor,h3:focus .header-anchor,h3:hover .header-anchor{visibility:visible;opacity:1}a.header-anchor{float:left;margin-top:.125em;margin-left:-.87em;padding-right:.23em;font-size:.85em;visibility:hidden;opacity:0;transition:opacity var(--va-transition-duration)}a.header-anchor:before{content:none}a.header-anchor:focus,a.header-anchor:hover{text-decoration:none}:root{--va-aside-width:256px;--va-sidebar-width:300px;--va-border-width:1px;--va-font-serif:"Noto Serif SC",STZhongsong,STKaiti,KaiTi,Roboto,serif;--va-font-sans:Inter,-apple-system,BlinkMacSystemFont,"Segoe UI",Roboto,Oxygen,Ubuntu,Cantarell,"Fira Sans","Droid Sans","Helvetica Neue",sans-serif;--va-font-mono:Menlo,Monaco,Consolas,"Courier New",monospace;--va-transition-duration-fast:.2s;--va-transition-duration:.4s;--va-transition-duration-slow:.6s;--va-transition:all var(--va-transition-duration-fast) ease-in-out}:root{--va-c-white:#ffffff;--va-c-black:#1a1a1a;--va-c-gray:#8e8e8e;--va-c-danger:#db2828;--va-c-warning:#f2711c;--va-c-text-light-1:#213547;--va-c-text-light-2:rgba(60, 60, 60, .7);--va-c-text-light-3:rgba(60, 60, 60, .33);--va-c-text-light-4:rgba(60, 60, 60, .18);--va-c-text-dark-1:rgba(255, 255, 255, .87);--va-c-text-dark-2:rgba(235, 235, 235, .6);--va-c-text-dark-3:rgba(235, 235, 235, .38);--va-c-text-dark-4:rgba(235, 235, 235, .18);--va-c-primary-light:#359eff;--va-c-primary-lighter:#81c2ff;--va-c-primary-dark:#006bce;--va-c-primary:#0078E7}:root{color-scheme:light;--va-c-brand:#0078E7;--va-border-color:#222;--va-c-bg:white;--va-c-bg-light:white;--va-c-bg-dark:#fafafa;--va-c-bg-opacity:rgba(255, 255, 255, .8);--va-c-bg-soft:#f9f9f9;--va-c-bg-alt:#f9f9f9;--va-c-bg-mute:#f1f1f1;--va-c-text:#333;--va-c-text-light:#555;--va-c-text-lighter:#666;--va-c-text-dark:#111;--va-c-primary-rgb:0,120,231;--va-c-link:var(--va-c-primary-dark);--va-c-divider:rgba(60, 60, 60, .2)}:root{--va-code-line-height:1.7;--va-code-font-size:.875em;--va-code-block-color:var(--va-c-text-dark-1);--va-code-block-bg:#282c34;--va-code-line-highlight-color:rgba(0, 0, 0, .5);--va-code-line-number-color:var(--va-c-text-dark-3);--va-code-copy-code-hover-bg:rgba(255, 255, 255, .05);--va-code-copy-code-active-text:var(--va-c-text-dark-2)}:root{--va-icon-copy:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' fill='none' height='20' width='20' stroke='rgba(128,128,128,1)' stroke-width='2' class='h-6 w-6' viewBox='0 0 24 24'%3E%3Cpath stroke-linecap='round' stroke-linejoin='round' d='M9 5H7a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V7a2 2 0 0 0-2-2h-2M9 5a2 2 0 0 0 2 2h2a2 2 0 0 0 2-2M9 5a2 2 0 0 1 2-2h2a2 2 0 0 1 2 2'/%3E%3C/svg%3E");--va-icon-copied:url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' fill='none' height='20' width='20' stroke='rgba(128,128,128,1)' stroke-width='2' class='h-6 w-6' viewBox='0 0 24 24'%3E%3Cpath stroke-linecap='round' stroke-linejoin='round' d='M9 5H7a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V7a2 2 0 0 0-2-2h-2M9 5a2 2 0 0 0 2 2h2a2 2 0 0 0 2-2M9 5a2 2 0 0 1 2-2h2a2 2 0 0 1 2 2m-6 9 2 2 4-4'/%3E%3C/svg%3E")}.post-category{color:var(--va-c-text)}.post-tag{white-space:nowrap;color:var(--yun-tag-color)}.post-tag:hover{color:var(--va-c-primary)}.yun-main{padding-left:var(--va-sidebar-width);transition:padding-left var(--va-transition-duration);box-sizing:border-box}.yun-icon-btn{cursor:pointer;display:inline-flex;align-items:center;justify-content:center;border:none;width:3rem;height:3rem;border-radius:50%;transition:background-color var(--va-transition-duration)}.yun-icon-btn div{font-size:1.2rem}.yun-icon-btn:hover{background-color:rgba(var(--va-c-primary-rgb),.08)}.yun-icon-btn:active{background-color:rgba(var(--va-c-primary-rgb),.16)}:root{--smc-font-sans:Raleway,-apple-system,"PingFang SC","Microsoft YaHei",Arial,sans-serif;--smc-font-serif:"Songti SC","Noto Serif SC",STZhongsong,STKaiti,KaiTi,Roboto,serif;--smc-font-mono:Menlo,Monaco,Consolas,"Courier New",monospace}:root{--smc-c-primary-light:#4eaaff;--smc-c-primary-lighter:#9bcfff;--smc-c-primary:#0078E7;--smc-theme-name:yun;--smc-line-height:1.8;--smc-c-primary-rgb:0,120,231;--smc-c-text:#24292e;--smc-c-text-light:#555;--smc-c-text-lighter:#666;--smc-header-bottom-color:#eaecef;--smc-border-color:var(--smc-c-primary-light);--smc-code-bg-color:#f6f8fa;--smc-link-color:#005eb4}.markdown-body{-ms-text-size-adjust:100%;-webkit-text-size-adjust:100%;background:var(--smc-bg-color);color:var(--smc-c-text);font-family:var(--smc-font-sans);font-size:1rem;line-height:var(--smc-line-height);overflow-wrap:break-word}.markdown-body *{box-sizing:border-box}.markdown-body a{background-color:transparent}.markdown-body a:active,.markdown-body a:hover{outline-width:0}.markdown-body blockquote{margin:1rem 0;padding:0 1rem;border-left:.25em solid var(--smc-border-color)}.markdown-body code,.markdown-body pre{font-family:Source Code Pro,Consolas,Monaco,SFMono-Regular,Ubuntu Mono,Menlo,monospace}.markdown-body code{padding:3px 6px;font-size:.85rem;color:var(--smc-c-text-light);background:var(--smc-code-bg-color);border-radius:3px}.markdown-body pre{margin-top:0;margin-bottom:0;overflow-wrap:normal;padding:1rem;overflow:auto;background-color:var(--smc-code-bg-color);border-radius:3px}.markdown-body pre>code{font-size:.85rem;white-space:pre}.markdown-body pre code{display:block;padding:0;margin:0;overflow:visible;line-height:inherit;word-break:normal;background-color:transparent;border:0}.markdown-body img{display:block;margin:1rem auto;max-width:92%;max-height:600px;border-radius:.2rem;transition:.4s;--tw-shadow:0 1px 3px 0 rgb(0 0 0/.1),0 1px 2px -1px rgb(0 0 0/.1);--tw-shadow-colored:0 1px 3px 0 var(--tw-shadow-color),0 1px 2px -1px var(--tw-shadow-color);-webkit-box-shadow:var(--tw-ring-offset-shadow,0 0 transparent),var(--tw-ring-shadow,0 0 transparent),var(--tw-shadow);box-shadow:var(--tw-ring-offset-shadow,0 0 transparent),var(--tw-ring-shadow,0 0 transparent),var(--tw-shadow)}.markdown-body img:hover{--tw-shadow:0 4px 6px -1px rgb(0 0 0/.1),0 2px 4px -2px rgb(0 0 0/.1);--tw-shadow-colored:0 4px 6px -1px var(--tw-shadow-color),0 2px 4px -2px var(--tw-shadow-color)}.markdown-body img:before{content:"\300c  LOADING ERROR \300d"}@media screen and (min-width:1600px){.markdown-body img{max-width:800px}}.markdown-body a{color:var(--smc-c-primary);text-decoration:none;border-bottom:1px solid transparent;transition:all .2s ease-in-out}.markdown-body a:hover{color:var(--smc-link-color);border-bottom:1px solid var(--smc-link-color)}.markdown-body ul{padding-left:2em}.markdown-body ul ul{margin-top:0;margin-bottom:0}.markdown-body li{overflow-wrap:break-all;margin-top:.25em}.markdown-body strong{font-family:var(--smc-font-serif);font-weight:900}.markdown-body p{margin-top:1rem;margin-bottom:1rem;overflow-x:auto;overflow-y:hidden}.markdown-body h2,.markdown-body h3{margin-top:1.5rem;margin-bottom:1rem;font-weight:300;line-height:1.5}.markdown-body h2{font-size:2.2rem;border-bottom:1px solid var(--smc-header-bottom-color)}.markdown-body h3{font-size:1.9rem}@media screen and (max-width:768px){.markdown-body h2{font-size:1.8rem}.markdown-body h3{font-size:1.6rem}}.markdown-body{--smc-font-family:var(--va-font-sans);--c-toc-link:var(--va-c-text-light)}.markdown-body{word-wrap:break-word}.markdown-body h2,.markdown-body h3{font-family:var(--va-font-serif);font-weight:900}.markdown-body ul{list-style:initial}.markdown-body img{margin:auto}.markdown-body p{overflow:unset}:root{--yun-post-card-max-width:900px;--yun-c-cloud:white;--yun-z-toc-btn:7;--yun-z-cloud:7;--yun-z-go-down:9;--yun-z-backdrop:9;--yun-z-sidebar:10;--yun-z-fireworks:11;--yun-z-menu-btn:20;--yun-z-go-up-btn:20;--yun-z-search-popup:30;--yun-z-search-btn:31;--va-z-overlay:var(--yun-z-backdrop)}:root{--yun-bg-img:url(https://cdn.yunyoujun.cn/img/bg/stars-timing-0-blur-30px.jpg);--yun-sidebar-bg-color:var(--va-c-bg-light);--yun-sidebar-bg-img:url(https://cdn.yunyoujun.cn/img/bg/alpha-stars-timing-1.webp)}*,:after,:before{--un-rotate:0;--un-rotate-x:0;--un-rotate-y:0;--un-rotate-z:0;--un-scale-x:1;--un-scale-y:1;--un-scale-z:1;--un-skew-x:0;--un-skew-y:0;--un-translate-x:0;--un-translate-y:0;--un-translate-z:0;--un-scroll-snap-strictness:proximity;--un-border-spacing-x:0;--un-border-spacing-y:0;--un-ring-offset-shadow:0 0 rgba(0,0,0,0);--un-ring-shadow:0 0 rgba(0,0,0,0);--un-shadow:0 0 rgba(0,0,0,0);--un-ring-offset-width:0px;--un-ring-offset-color:#fff;--un-ring-width:0px;--un-ring-color:rgba(147,197,253,.5)}[i-ri-archive-line=""]{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M3 10H2V4.003C2 3.449 2.455 3 2.992 3h18.016A.99.99 0 0 1 22 4.003V10h-1v10.002a.996.996 0 0 1-.993.998H3.993A.996.996 0 0 1 3 20.002V10Zm16 0H5v9h14v-9ZM4 5v3h16V5H4Zm5 7h6v2H9v-2Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}[i-ri-arrow-left-s-line=""]{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='m10.828 12l4.95 4.95l-1.414 1.415L8 12l6.364-6.364l1.414 1.414l-4.95 4.95Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}[i-ri-arrow-right-s-line=""]{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='m13.171 12l-4.95-4.95l1.415-1.413L16 12l-6.364 6.364l-1.414-1.415l4.95-4.95Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}[i-ri-arrow-up-s-line=""]{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='m12 10.828l-4.95 4.95l-1.414-1.414L12 8l6.364 6.364l-1.415 1.414l-4.95-4.95Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}.i-ri-bilibili-line{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M7.172 2.757L10.414 6h3.171l3.243-3.242a1 1 0 1 1 1.415 1.414L16.414 6H18.5A3.5 3.5 0 0 1 22 9.5v8a3.5 3.5 0 0 1-3.5 3.5h-13A3.5 3.5 0 0 1 2 17.5v-8A3.5 3.5 0 0 1 5.5 6h2.085L5.757 4.171a1 1 0 0 1 1.415-1.414ZM18.5 8h-13a1.5 1.5 0 0 0-1.493 1.355L4 9.5v8a1.5 1.5 0 0 0 1.356 1.493L5.5 19h13a1.5 1.5 0 0 0 1.493-1.356L20 17.5v-8A1.5 1.5 0 0 0 18.5 8ZM8 11a1 1 0 0 1 1 1v2a1 1 0 1 1-2 0v-2a1 1 0 0 1 1-1Zm8 0a1 1 0 0 1 1 1v2a1 1 0 1 1-2 0v-2a1 1 0 0 1 1-1Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}[i-ri-calendar-line=""]{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M9 1v2h6V1h2v2h4a1 1 0 0 1 1 1v16a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V4a1 1 0 0 1 1-1h4V1h2Zm11 10H4v8h16v-8ZM7 5H4v4h16V5h-3v2h-2V5H9v2H7V5Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}.i-ri-clipboard-line{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M7 4V2h10v2h3.007c.548 0 .993.445.993.993v16.014a.994.994 0 0 1-.993.993H3.993A.993.993 0 0 1 3 21.007V4.993C3 4.445 3.445 4 3.993 4H7Zm0 2H5v14h14V6h-2v2H7V6Zm2-2v2h6V4H9Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}.i-ri-cloud-line{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M12 2a7 7 0 0 1 6.992 7.339A6 6 0 0 1 17 21H7A6 6 0 0 1 5.008 9.339A7 7 0 0 1 12 2Zm0 2a5 5 0 0 0-4.994 5.243l.07 1.488l-1.404.494A4.002 4.002 0 0 0 7 19h10a4 4 0 1 0-3.796-5.265l-1.898-.633A6.003 6.003 0 0 1 17 9a5 5 0 0 0-5-5Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}[i-ri-file-list-line=""]{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M20 22H4a1 1 0 0 1-1-1V3a1 1 0 0 1 1-1h16a1 1 0 0 1 1 1v18a1 1 0 0 1-1 1Zm-1-2V4H5v16h14ZM8 7h8v2H8V7Zm0 4h8v2H8v-2Zm0 4h8v2H8v-2Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}[i-ri-folder-2-line=""]{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M12.414 5H21a1 1 0 0 1 1 1v14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V4a1 1 0 0 1 1-1h7.414l2 2ZM20 11H4v8h16v-8Zm0-2V7h-8.414l-2-2H4v4h16Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}.i-ri-genderless-line{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M13 7.066A7.501 7.501 0 0 1 12 22a7.5 7.5 0 0 1-1-14.934V1h2v6.066ZM12 20a5.5 5.5 0 1 0 0-11a5.5 5.5 0 0 0 0 11Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}.i-ri-github-line{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M5.884 18.653c-.3-.2-.558-.456-.86-.816a50.59 50.59 0 0 1-.466-.579c-.463-.575-.755-.841-1.056-.95a1 1 0 1 1 .675-1.882c.752.27 1.261.735 1.947 1.588c-.094-.117.34.427.433.539c.19.227.33.365.44.438c.204.137.588.196 1.15.14c.024-.382.094-.753.202-1.096c-2.968-.725-4.648-2.64-4.648-6.396c0-1.238.37-2.355 1.058-3.291c-.218-.894-.185-1.975.302-3.192a1 1 0 0 1 .63-.583c.081-.024.127-.034.208-.047c.803-.123 1.937.17 3.415 1.097a11.731 11.731 0 0 1 2.687-.308c.912 0 1.819.103 2.684.308c1.477-.933 2.614-1.227 3.422-1.097c.085.014.158.032.218.051a1 1 0 0 1 .616.58c.487 1.215.52 2.296.302 3.19c.691.936 1.058 2.045 1.058 3.292c0 3.758-1.674 5.666-4.642 6.393c.125.415.19.878.19 1.38c0 .664-.002 1.299-.007 2.01c0 .19-.002.394-.005.706a1 1 0 0 1-.018 1.957c-1.14.228-1.984-.532-1.984-1.524l.002-.447l.005-.705c.005-.707.008-1.338.008-1.997c0-.697-.184-1.152-.426-1.361c-.661-.57-.326-1.654.541-1.751c2.966-.334 4.336-1.483 4.336-4.66c0-.955-.312-1.745-.913-2.405a1 1 0 0 1-.189-1.044c.166-.415.236-.957.095-1.614l-.01.002c-.491.14-1.11.44-1.858.95a1 1 0 0 1-.833.135a9.626 9.626 0 0 0-2.592-.35c-.89 0-1.772.12-2.592.35a1 1 0 0 1-.829-.133c-.753-.507-1.374-.807-1.87-.947c-.143.653-.072 1.194.093 1.607a1 1 0 0 1-.189 1.044c-.597.656-.913 1.459-.913 2.404c0 3.172 1.371 4.33 4.322 4.66c.865.098 1.202 1.178.545 1.749c-.193.167-.43.732-.43 1.364v3.149c0 .986-.834 1.726-1.96 1.529a1 1 0 0 1-.04-1.963v-.99c-.91.062-1.661-.087-2.254-.484Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}[i-ri-home-4-line=""]{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M19 21H5a1 1 0 0 1-1-1v-9H1l10.327-9.388a1 1 0 0 1 1.346 0L23 11h-3v9a1 1 0 0 1-1 1Zm-6-2h5V9.158l-6-5.455l-6 5.455V19h5v-6h2v6Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}.i-ri-mail-line{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M3 3h18a1 1 0 0 1 1 1v16a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V4a1 1 0 0 1 1-1Zm17 4.238l-7.928 7.1L4 7.216V19h16V7.238ZM4.511 5l7.55 6.662L19.502 5H4.511Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}[i-ri-price-tag-3-line=""]{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='m10.904 2.1l9.9 1.414l1.414 9.9l-9.193 9.192a1 1 0 0 1-1.414 0l-9.9-9.9a1 1 0 0 1 0-1.413L10.905 2.1Zm.707 2.121L3.833 12l8.485 8.485l7.779-7.778l-1.061-7.425l-7.425-1.06Zm2.122 6.364a2 2 0 1 1 2.828-2.828a2 2 0 0 1-2.828 2.828Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}[i-ri-translate=""]{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M5 15v2a2 2 0 0 0 1.85 1.994L7 19h3v2H7a4 4 0 0 1-4-4v-2h2Zm13-5l4.4 11h-2.155l-1.201-3h-4.09l-1.199 3h-2.154L16 10h2Zm-1 2.885L15.753 16h2.492L17 12.885ZM8 2v2h4v7H8v3H6v-3H2V4h4V2h2Zm9 1a4 4 0 0 1 4 4v2h-2V7a2 2 0 0 0-2-2h-3V3h3ZM6 6H4v3h2V6Zm4 0H8v3h2V6Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}[i~=ri-sun-line]{--un-icon:url("data:image/svg+xml;utf8,%3Csvg viewBox='0 0 24 24' width='1.2em' height='1.2em' xmlns='http://www.w3.org/2000/svg' %3E%3Cpath fill='currentColor' d='M12 18a6 6 0 1 1 0-12a6 6 0 0 1 0 12Zm0-2a4 4 0 1 0 0-8a4 4 0 0 0 0 8ZM11 1h2v3h-2V1Zm0 19h2v3h-2v-3ZM3.515 4.929l1.414-1.414L7.05 5.636L5.636 7.05L3.515 4.93ZM16.95 18.364l1.414-1.414l2.121 2.121l-1.414 1.414l-2.121-2.121Zm2.121-14.85l1.414 1.415l-2.121 2.121l-1.414-1.414l2.121-2.121ZM5.636 16.95l1.414 1.414l-2.121 2.121l-1.414-1.414l2.121-2.121ZM23 11v2h-3v-2h3ZM4 11v2H1v-2h3Z'/%3E%3C/svg%3E");-webkit-mask:var(--un-icon) no-repeat;mask:var(--un-icon) no-repeat;-webkit-mask-size:100% 100%;mask-size:100% 100%;background-color:currentColor;color:inherit;width:1.2em;height:1.2em}.yun-card{margin:auto;--un-shadow:var(--un-shadow-inset) 0 1px 3px 0 var(--un-shadow-color, rgba(0,0,0,.1)),var(--un-shadow-inset) 0 1px 2px -1px var(--un-shadow-color, rgba(0,0,0,.1));box-shadow:var(--un-ring-offset-shadow),var(--un-ring-shadow),var(--un-shadow);transition-property:color,background-color,border-color,outline-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,backdrop-filter;transition-timing-function:cubic-bezier(.4,0,.2,1);transition-duration:.15s;transition-duration:var(--va-transition-duration)}.va-card{--un-shadow:var(--un-shadow-inset) 0 1px 3px 0 var(--un-shadow-color, rgba(0,0,0,.1)),var(--un-shadow-inset) 0 1px 2px -1px var(--un-shadow-color, rgba(0,0,0,.1));box-shadow:var(--un-ring-offset-shadow),var(--un-ring-shadow),var(--un-shadow)}.va-card:hover,.yun-card:hover{--un-shadow:var(--un-shadow-inset) 0 10px 15px -3px var(--un-shadow-color, rgba(0,0,0,.1)),var(--un-shadow-inset) 0 4px 6px -4px var(--un-shadow-color, rgba(0,0,0,.1));box-shadow:var(--un-ring-offset-shadow),var(--un-ring-shadow),var(--un-shadow)}@media (max-width:767.9px){.yun-main{padding-left:0}}.fixed{position:fixed}.relative{position:relative}[bottom~="19"]{bottom:4.75rem}[right~="2"]{right:.5rem}.z-1{z-index:1}.z-350{z-index:350}[m~="0"]{margin:0}[m~="2"]{margin:.5rem}[m~=y-4]{margin-top:1rem;margin-bottom:1rem}.my-1{margin-top:.25rem;margin-bottom:.25rem}[m~=x-1]{margin-left:.25rem;margin-right:.25rem}[mx~="2"]{margin-left:.5rem;margin-right:.5rem}[m~=y-2]{margin-top:.5rem;margin-bottom:.5rem}.mb-2,[m~=b-2]{margin-bottom:.5rem}[m~=l-1]{margin-left:.25rem}[m~=t-4]{margin-top:1rem}[mt-6=""],[m~=t-6]{margin-top:1.5rem}[m~=l-4]{margin-left:1rem}[m~=r-1]{margin-right:.25rem}.block,[display~=block]{display:block}.inline-block{display:inline-block}[h~="8"]{height:2rem}[w~="8"]{width:2rem}[w~=full]{width:100%}.flex,[flex~="~"]{display:flex}.inline-flex,[inline-flex=""]{display:inline-flex}.flex-grow,[flex~=grow]{flex-grow:1}[flex~=col]{flex-direction:column}.transform{transform:translate(var(--un-translate-x)) translateY(var(--un-translate-y)) translateZ(var(--un-translate-z)) rotate(var(--un-rotate)) rotateX(var(--un-rotate-x)) rotateY(var(--un-rotate-y)) rotate(var(--un-rotate-z)) skew(var(--un-skew-x)) skewY(var(--un-skew-y)) scaleX(var(--un-scale-x)) scaleY(var(--un-scale-y)) scaleZ(var(--un-scale-z))}@keyframes pulse{0%,to{opacity:1}50%{opacity:.5}}.animate-pulse{animation:pulse 2s cubic-bezier(.4,0,.6,1) infinite}.items-center,[items~=center]{align-items:center}.justify-center,[justify~=center]{justify-content:center}.gap-2{grid-gap:.5rem;gap:.5rem}[overflow~=auto]{overflow:auto}.truncate{overflow:hidden;text-overflow:ellipsis;white-space:nowrap}.rounded-full{border-radius:9999px}[stroke-width~="2"]{stroke-width:2px}.p-4,[p~="4"]{padding:1rem}[p~="1"]{padding:.25rem}[p~="2"]{padding:.5rem}[p~=x-4]{padding-left:1rem;padding-right:1rem}[py~="1"]{padding-top:.25rem;padding-bottom:.25rem}[p~=b-8]{padding-bottom:2rem}[p~=l-4]{padding-left:1rem}[text~=center]{text-align:center}[text~="2xl"]{font-size:1.5rem;line-height:2rem}[text-xl=""]{font-size:1.25rem;line-height:1.75rem}[text~=xs]{font-size:.75rem;line-height:1rem}[text~=sm]{font-size:.875rem;line-height:1.25rem}[font~=black]{font-weight:900}.leading-none{line-height:1}.text-\$va-c-text-light{color:var(--va-c-text-light)}[op~="80"]{opacity:.8}.shadow{--un-shadow:var(--un-shadow-inset) 0 1px 3px 0 var(--un-shadow-color, rgba(0,0,0,.1)),var(--un-shadow-inset) 0 1px 2px -1px var(--un-shadow-color, rgba(0,0,0,.1));box-shadow:var(--un-ring-offset-shadow),var(--un-ring-shadow),var(--un-shadow)}.transition{transition-property:color,background-color,border-color,outline-color,text-decoration-color,fill,stroke,opacity,box-shadow,transform,filter,backdrop-filter;transition-timing-function:cubic-bezier(.4,0,.2,1);transition-duration:.15s}[font~=serif]{font-family:var(--va-font-serif)}@media (max-width:767.9px){.lt-md\:ml-0{margin-left:0}[p~="lt-md:0"]{padding:0}}@media (min-width:640px){.sm\:p-6{padding:1.5rem}.sm\:px-6{padding-left:1.5rem;padding-right:1.5rem}}@media (min-width:768px){.md\:hidden{display:none}.md\:translate-x-0{--un-translate-x:0;transform:translate(var(--un-translate-x)) translateY(var(--un-translate-y)) translateZ(var(--un-translate-z)) rotate(var(--un-rotate)) rotateX(var(--un-rotate-x)) rotateY(var(--un-rotate-y)) rotate(var(--un-rotate-z)) skew(var(--un-skew-x)) skewY(var(--un-skew-y)) scaleX(var(--un-scale-x)) scaleY(var(--un-scale-y)) scaleZ(var(--un-scale-z))}}@media (min-width:1024px){.lg\:px-12{padding-left:3rem;padding-right:3rem}}@media (min-width:1280px){.xl\:hidden{display:none}.xl\:px-16{padding-left:4rem;padding-right:4rem}}.post-copyright{font-size:.9rem;padding:.5rem 1rem;border-left:4px solid #ff5252;background-color:var(--va-c-bg-dark);list-style:none;word-break:break-all;position:relative;overflow:hidden}.post-copyright:after{pointer-events:none;position:absolute;color:#fff;background:url("data:image/svg+xml;charset=utf-8,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 496 512'%3E%3Cpath fill='gray' d='M245.8 214.9l-33.2 17.3c-9.4-19.6-25.2-20-27.4-20-22.2 0-33.3 14.6-33.3 43.9 0 23.5 9.2 43.8 33.3 43.8 14.4 0 24.6-7 30.5-21.3l30.6 15.5a73.2 73.2 0 01-65.1 39c-22.6 0-74-10.3-74-77 0-58.7 43-77 72.6-77 30.8-.1 52.7 11.9 66 35.8zm143 0l-32.7 17.3c-9.5-19.8-25.7-20-27.9-20-22.1 0-33.2 14.6-33.2 43.9 0 23.5 9.2 43.8 33.2 43.8 14.5 0 24.7-7 30.5-21.3l31 15.5c-2 3.8-21.3 39-65 39-22.7 0-74-9.9-74-77 0-58.7 43-77 72.6-77C354 179 376 191 389 214.8zM247.7 8C104.7 8 0 123 0 256c0 138.4 113.6 248 247.6 248C377.5 504 496 403 496 256 496 118 389.4 8 247.6 8zm.8 450.8c-112.5 0-203.7-93-203.7-202.8 0-105.5 85.5-203.3 203.8-203.3A201.7 201.7 0 01451.3 256c0 121.7-99.7 202.9-202.9 202.9z'/%3E%3C/svg%3E");content:" ";height:10rem;width:10rem;right:-2rem;top:-2rem;opacity:.1}.va-toc[data-v-3ec1ec4d]{text-align:left}.content[data-v-3ec1ec4d]{position:relative;padding-left:16px;font-size:14px;text-align:left}.outline-marker[data-v-3ec1ec4d]{position:absolute;top:32px;left:-2px;z-index:0;opacity:0;width:4px;height:18px;background-color:var(--va-c-brand);transition:top .25s cubic-bezier(0,1,.5,1),background-color .5s,opacity .25s;border-top-right-radius:2px;border-bottom-right-radius:2px}.outline-title[data-v-3ec1ec4d]{letter-spacing:.4px;line-height:28px;font-size:14px;font-weight:600}.visually-hidden[data-v-3ec1ec4d]{position:absolute;width:1px;height:1px;white-space:nowrap;clip:rect(0 0 0 0);clip-path:inset(50%);overflow:hidden}.aside{position:fixed;right:0;top:0;bottom:0;width:var(--va-sidebar-width,300px);transform:translate(100%);transition:box-shadow var(--va-transition-duration),background-color var(--va-transition-duration),opacity .25s,transform var(--va-transition-duration) cubic-bezier(.19,1,.22,1)}.aside-container{position:sticky;top:0;height:100vh}@media screen and (min-width:1280px){.aside{transform:translate(0)}}.toc-btn{color:var(--va-c-primary);background-color:#fff;z-index:var(--yun-z-toc-btn)}.post-nav{display:flex;justify-content:space-between;align-items:center}.post-nav-item{display:inline-flex;justify-content:center;align-items:center;color:var(--va-c-primary);outline:0;font-size:1.5rem;font-weight:700;text-transform:uppercase;height:3rem;transition:.4s}.post-nav-item:hover{background-color:rgba(var(--va-c-primary-rgb),.1);box-shadow:0 0 15px #0000001a}.post-nav-prev{padding:0 .6rem 0 .1rem}.post-nav-next{padding:0 .1rem 0 .6rem}.post-nav-next,.post-nav-prev{display:inline-flex;align-items:center;height:3rem;font-size:1rem}.post-nav-next .title,.post-nav-prev .title{overflow:hidden;max-width:10rem}.post-nav-next .icon,.post-nav-prev .icon{width:1.2rem;height:1.2rem}@media screen and (min-width:1024px){.post-nav-next .title,.post-nav-prev .title{max-width:18rem}}@media screen and (min-width:1280px){.content{max-width:calc(100vw - 2 * var(--va-sidebar-width) - 1rem - 8px)}}</style><link rel="preload" href="/assets/index-67f11a9b.css" as="style"><link rel="modulepreload" crossorigin="" href="/assets/post-7f4e4e49.js"><link rel="preload" href="/assets/post-1d1be697.css" as="style"><link rel="modulepreload" crossorigin="" href="/assets/deep-learning-from-scratch-learning-of-neural-network-b6fcae25.js"><link rel="modulepreload" crossorigin="" href="/assets/ValaxyMain.vue_vue_type_style_index_0_lang-40050c3d.js"><link rel="preload" href="/assets/ValaxyMain-e55e6dd1.css" as="style"><title>深度学习入门：神经网络的学习 - 愚人而已</title><link rel="icon" href="https://afool.top/afool.svg" type="image/svg+xml"><meta name="theme-color" content="#ffffff"><meta name="msapplication-TileColor" content="#ffffff"><meta name="generator" content="Valaxy 0.14.25"><meta name="description" content="敬请见证！（bushi"><meta property="og:description" content="敬请见证！（bushi"><meta property="og:locale" content="zh-CN"><meta property="og:site_name" content="愚人而已"><meta property="og:title" content="深度学习入门：神经网络的学习"><meta property="og:image" content="https://afool.top/afool.svg"><meta property="og:url" content="https://afool.top/"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Noto+Serif+SC:wght@900&amp;display=swap"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_AMS-Regular-0cdd387c.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_Caligraphic-Bold-de7701e4.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_Caligraphic-Regular-5d53e70a.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_Fraktur-Bold-74444efd.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_Fraktur-Regular-51814d27.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_Main-Bold-0f60d1b8.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_Main-BoldItalic-99cd42a3.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_Main-Italic-97479ca6.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_Main-Regular-c2342cd8.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_Math-BoldItalic-dc47344d.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_Math-Italic-7af58c5e.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_SansSerif-Bold-e99ae511.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_SansSerif-Italic-00b26ac8.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_SansSerif-Regular-68e8c73e.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_Script-Regular-036d4e95.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_Size1-Regular-6b47c401.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_Size2-Regular-d04c5421.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="data:font/woff2;base64,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"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_Size4-Regular-a4af7d41.woff2"><link rel="preload" as="font" crossorigin="anonymous" href="/assets/KaTeX_Typewriter-Regular-71d517d6.woff2"></head><body><div id="app" data-server-rendered="true"><!--[--><!--[--><canvas class="fireworks"></canvas><!--[--><div class="va-bg"></div><!--]--><!----><!--]--><!--[--><!--]--><!----><!--[--><!--[--><!----><button type="button" class="vt-hamburger menu-btn sidebar-toggle yun-icon-btn md:hidden" aria-label="mobile navigation" aria-expanded="false"><span class="vt-hamburger-container"><span class="vt-hamburger-top"></span><span class="vt-hamburger-middle"></span><span class="vt-hamburger-bottom"></span></span></button><aside class="md:translate-x-0 va-card transition sidebar"><!--[--><!--[--><!--[--><!----><div class=""><!--[--><div class="sidebar-panel"><div class="site-info" m="t-6"><a href="/about" class="site-author-avatar"><img class="rounded-full" src="https://afool.top/images/nekosense.jpeg" alt="avatar"><span class="site-author-status">🌌</span></a><div class="site-author-name"><a href="/about" class="">零歌</a></div><span class="site-name">愚人而已</span><h4 class="site-subtitle block" text="xs">以愚者之名攀上顶峰</h4><div class="site-description my-1">敬请见证！（bushi</div></div><nav class="site-nav" text-xl="" mt-6=""><a href="/" class="site-link-item yun-icon-btn" title="首页"><div i-ri-home-4-line=""></div></a><a href="/archives/" class="site-link-item" title="归档"><div class="icon" i-ri-archive-line=""></div><span class="count">50</span></a><a href="/categories/" class="site-link-item" title="分类"><div class="icon" i-ri-folder-2-line=""></div><span class="count">6</span></a><a href="/tags/" class="site-link-item" title="标签"><div class="icon" i-ri-price-tag-3-line=""></div><span class="count">36</span></a><a href="/about" class="site-link-item yun-icon-btn" title="关于"><!--[--><div class="i-ri-clipboard-line"></div><!--]--></a></nav><hr m="t-4 b-2"><div class="links-of-author"><!--[--><a class="links-of-author-item yun-icon-btn" rel="noopener" href="https://github.com/charliedu2000" title="GitHub" target="_blank" style="color:#6e5494"><div class="i-ri-github-line icon"></div></a><a class="links-of-author-item yun-icon-btn" rel="noopener" href="https://space.bilibili.com/22660607" title="哔哩哔哩" target="_blank" style="color:#ff8eb3"><div class="i-ri-bilibili-line icon"></div></a><a class="links-of-author-item yun-icon-btn" rel="noopener" href="mailto:charliedu2000@hotmail.com" title="E-Mail" target="_blank" style="color:#8e71c1"><div class="i-ri-mail-line icon"></div></a><!--]--></div><hr m="y-2"><div class="links"><!--[--><a href="/links/" class="link-item yun-icon-btn" title="我的小伙伴们" style="color:#1e90ff"><!--[--><div class="i-ri-genderless-line icon"></div><!--]--></a><!--]--></div><br></div><div><button class="yun-icon-btn" title="切换深色模式" style="color:#f1cb64"><div i="ri-sun-line dark:ri-moon-line"></div></button><button class="yun-icon-btn" title="切换语言" style="color:var(--va-c-text)"><div i-ri-translate="" class="transition transform"></div></button></div><!--]--></div><!--]--><!--]--><!--]--></aside><!--]--><main class="yun-main lt-md:ml-0" flex="~"><div w="full" flex="~"><!--[--><div class="content" flex="~ col grow" w="full" p="l-4 lt-md:0"><div class="yun-card relative" m="0" style=""><!----><!----><!--[--><!--[--><header class="post-header mb-2" m="t-4"><h1 class="post-title flex-center" p="2" text="2xl center" font="serif black" style=""><!----><span inline-flex="" class="leading-none">深度学习入门：神经网络的学习</span></h1></header><!--]--><!--[--><!--[--><!--[--><!--[--><!----><!----><!----><div class="post-meta" flex="~ col" justify="center" items="center" text="sm" py="1"><div class="post-time flex items-center"><span class="inline-flex-center" title="发表于"><div class="inline-block" i-ri-calendar-line=""></div><time m="l-1">2022-10-07</time></span><!----></div><!----></div><!--[--><!--]--><!--]--><!----><div class="inline-flex" text="sm" py="1"><a href="/categories/?category=%E5%BF%AB%E5%8E%BB%E5%AD%A6%E4%B9%A0" class="post-category inline-flex-center"><div m="x-1" inline-flex="" i-ri-folder-2-line=""></div><span>快去学习</span></a><span mx="2">-</span><!--[--><a href="/tags/?tag=%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C" class="post-tag inline-flex-center" m="x-1"><div m="r-1" i-ri-price-tag-3-line=""></div><span>神经网络</span></a><a href="/tags/?tag=%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0" class="post-tag inline-flex-center" m="x-1"><div m="r-1" i-ri-price-tag-3-line=""></div><span>深度学习</span></a><!--]--></div><!--]--><!--]--><!--]--><div p="x-4 b-8" class="sm:px-6 lg:px-12 xl:px-16" w="full"><!--[--><article class="markdown-body"><blockquote op="80">本文最后更新于 1 年前，文中所描述的信息可能已发生改变。</blockquote><!--[--><!--[--><p>内容参考：</p><ul><li>《深度学习入门：基于 Python 的理论与实现》(斋藤康毅)</li><li><a target="_blank" rel="noreferrer" href="https://github.com/oreilly-japan/deep-learning-from-scratch"><!--[-->上述书籍作者提供的代码<!--]--><!----></a></li></ul><p>之前实现了神经网络的前向传播过程，但是用到的权重参数是预先准备好的，那么接下来的目标自然就是“学习”——从训练数据中自动获取最优权重参数。</p><h2 id="从数据中学习" tabindex="-1">从数据中学习 <a aria-current="page" href="/posts/learning/deep-learning-from-scratch-learning-of-neural-network#从数据中学习" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h2><p>机器学习是以数据为核心的，尝试从数据中发现答案和模式。<em>神经网络或深度学习则比以往的机器学习方法更能避免人为介入</em>。</p><p>要理解上面这些描述还是要从具体的问题开始，比如要实现数字“5”的识别该用什么算法呢？人很容易认出来眼前的是不是5，这可以说是基于经验和某些规律得出的结果，但是机器怎么知道这些经验或者规律是什么呢？与其想办法用算法表示这些规律（显然很难），不如想办法让机器从数据中直接获取需要的“规律”。现有的一种方案是先从图像中提取<strong>特征量</strong>，再用机器学习来学习这些特征量的模式。</p><blockquote><p>这里所说的“特征量”是指可以从输入数据（输入图像）中准确地提取本质数据（重要的数据）的转换器。图像的特征量通常表示为向量的形式。在计算机视觉领域，常用的特征量包括SIFT、SURF和HOG等。使用这些特征量将图像数据转换为向量，然后对转换后的向量使用机器学习中的SVM、KNN等分类器进行学习。</p></blockquote><p>在上面所说的方法中，将图像转换为向量时所用的特征量仍是人为设计的，对于不同的问题需要考虑不同的特征量。在深度学习中，这里所说的特征量也是由机器来学习的。</p><p><img src="https://s2.loli.net/2022/10/08/jr6XuH83fihJRdU.png" alt="从人工设计规则转变为由机器从数据中学习"></p><p>书上给出的这幅图说明了识别的方法，从这里也能看出所谓“机器学习”和“深度学习”之间的一些区别。</p><blockquote><p>深度学习有时也称为端到端机器学习（end-to-end machine learning）。这里所说的端到端是指从一端到另一端的意思，也就是从原始数据（输入）中获得目标结果（输出）的意思。</p></blockquote><p><s>就是说中间的过程不需要人为干预吗……</s></p><h3 id="一些注意事项：-训练数据和测试数据" tabindex="-1">一些注意事项： 训练数据和测试数据 <a aria-current="page" href="/posts/learning/deep-learning-from-scratch-learning-of-neural-network#一些注意事项：-训练数据和测试数据" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>很明显，<strong>训练数据</strong>就是用来学习、寻找最优参数所用的那部分数据，而<strong>测试数据</strong>（监督数据）的作用是评价模型的泛化能力，自然不可缺少。如果只用已有的数据来学习和评价，可能会造成模型无法正确处理其他数据集，也就是出现<strong>过拟合</strong>现象。</p><h2 id="损失函数" tabindex="-1">损失函数 <a aria-current="page" href="/posts/learning/deep-learning-from-scratch-learning-of-neural-network#损失函数" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h2><p><strong>损失函数</strong>可以表示神经网络的“状态”，神经网络就参考这个状态指标来寻找最优权重参数。这里说的损失函数表示的“状态”是指当前神经网络神经网络对监督数据在多大程度上不拟合、不一致，或者说性能有多坏（当然，为损失函数乘上一个负值就可以表示性能有多好）。损失函数一般用均方误差和交叉熵误差等。</p><h3 id="均方误差" tabindex="-1">均方误差 <a aria-current="page" href="/posts/learning/deep-learning-from-scratch-learning-of-neural-network#均方误差" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>均方误差的公式如下：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>E</mi><mo>=</mo><mfrac><mn>1</mn><mn>2</mn></mfrac><munder><mo>∑</mo><mi>k</mi></munder><mo stretchy="false">(</mo><msub><mi>y</mi><mi>k</mi></msub><mo>−</mo><msub><mi>t</mi><mi>k</mi></msub><msup><mo stretchy="false">)</mo><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">E = \frac{1}{2} \sum \limits_k (y_k - t_k)^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord mathnormal" style="margin-right:.05764em">E</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:2.6236em;vertical-align:-1.3021em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.1667em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em"><span style="top:-1.8479em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3021em"><span></span></span></span></span></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:-.0359em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-.25em"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8641em"><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span></p><p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">y_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:-.0359em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 表示神经网络的输出，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">t_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.7651em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 表示监督数据，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6944em"></span><span class="mord mathnormal" style="margin-right:.03148em">k</span></span></span></span> 表示数据的维数。比方说在之前的手写数字识别的例子中，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">y_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:-.0359em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">t_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.7651em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 就是由10个元素构成的数据：</p><div class="language-pycon"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">&gt;&gt;&gt; y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]</span></span>
<span class="line"><span style="color:#a6accd">&gt;&gt;&gt; t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><code>y</code> 是 <code>softmax</code> 函数的输出，<code>t</code> 是监督数据的独热编码形式，均方误差会计算 <code>y</code> 和 <code>t</code> 的各个对应元素之差的平方，再求总和。实现方式可以是：</p><div class="language-python"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#676e95;font-style:italic"># 均方误差</span></span>
<span class="line"><span style="color:#c792ea">def</span><span style="color:#a6accd"> </span><span style="color:#82aaff">mean_squared_error</span><span style="color:#89ddff">(</span><span style="color:#a6accd;font-style:italic">y</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> </span><span style="color:#a6accd;font-style:italic">t</span><span style="color:#89ddff">):</span></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#89ddff;font-style:italic">return</span><span style="color:#a6accd"> </span><span style="color:#f78c6c">0.5</span><span style="color:#a6accd"> </span><span style="color:#89ddff">*</span><span style="color:#a6accd"> np</span><span style="color:#89ddff">.</span><span style="color:#82aaff">sum</span><span style="color:#89ddff">((</span><span style="color:#82aaff">y </span><span style="color:#89ddff">-</span><span style="color:#82aaff"> t</span><span style="color:#89ddff">)</span><span style="color:#82aaff"> </span><span style="color:#89ddff">**</span><span style="color:#82aaff"> </span><span style="color:#f78c6c">2</span><span style="color:#89ddff">)</span></span>
<span class="line"></span></code></pre></div><p>均方误差得出的结果越小，说明结果与监督数据之间的误差越小。</p><h3 id="交叉熵误差" tabindex="-1">交叉熵误差 <a aria-current="page" href="/posts/learning/deep-learning-from-scratch-learning-of-neural-network#交叉熵误差" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>公式如下：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>E</mi><mo>=</mo><mo>−</mo><munder><mo>∑</mo><mi>k</mi></munder><msub><mi>t</mi><mi>k</mi></msub><mi>log</mi><mo>⁡</mo><msub><mi>y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">E = - \sum \limits_k t_k \log y_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord mathnormal" style="margin-right:.05764em">E</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:2.3521em;vertical-align:-1.3021em"></span><span class="mord">−</span><span class="mspace" style="margin-right:.1667em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em"><span style="top:-1.8479em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3021em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.1667em"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.1667em"></span><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mspace" style="margin-right:.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:-.0359em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span></span></p><p>其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>log</mi><mo>⁡</mo></mrow><annotation encoding="application/x-tex">\log</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8889em;vertical-align:-.1944em"></span><span class="mop">lo<span style="margin-right:.01389em">g</span></span></span></span></span> 表示 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mi>log</mi><mo>⁡</mo></mrow><mi>e</mi></msub></mrow><annotation encoding="application/x-tex">\log_e</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.9386em;vertical-align:-.2441em"></span><span class="mop"><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.0573em"><span style="top:-2.4559em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">e</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2441em"><span></span></span></span></span></span></span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">y_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:-.0359em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 是神经网络的输出，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mi>k</mi></msub></mrow><annotation encoding="application/x-tex">t_k</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.7651em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 是正确解的标签（独热编码）。显然上式只会计算正确解标签的输出的自然对数（因为只有正确解标签的索引为1），也就是说交叉熵误差的值是由正确解标签所对应的输出结果决定的。</p><p>自然对数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo>=</mo><mi>log</mi><mo>⁡</mo><mi>x</mi></mrow><annotation encoding="application/x-tex">y = \log x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.1944em"></span><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:.8889em;vertical-align:-.1944em"></span><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mspace" style="margin-right:.1667em"></span><span class="mord mathnormal">x</span></span></span></span> 的图像如下：</p><p><img src="https://s2.loli.net/2022/10/09/3dHoWFkPCrpvBGh.png" alt="自然对数 y = log x 的图像"></p><p>那么可以看出正确解标签对应的输出为1时，交叉熵误差的输出为0，输出越小，交叉熵误差的结果越大。</p><p>实现方式：</p><div class="language-python"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#676e95;font-style:italic"># 交叉熵误差</span></span>
<span class="line"><span style="color:#c792ea">def</span><span style="color:#a6accd"> </span><span style="color:#82aaff">cross_entropy_error</span><span style="color:#89ddff">(</span><span style="color:#a6accd;font-style:italic">y</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> </span><span style="color:#a6accd;font-style:italic">t</span><span style="color:#89ddff">):</span></span>
<span class="line"><span style="color:#a6accd">    delta </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#f78c6c">1e-7</span></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#89ddff;font-style:italic">return</span><span style="color:#a6accd"> </span><span style="color:#89ddff">-</span><span style="color:#a6accd">np</span><span style="color:#89ddff">.</span><span style="color:#82aaff">sum</span><span style="color:#89ddff">(</span><span style="color:#82aaff">t </span><span style="color:#89ddff">*</span><span style="color:#82aaff"> np</span><span style="color:#89ddff">.</span><span style="color:#82aaff">log</span><span style="color:#89ddff">(</span><span style="color:#82aaff">y </span><span style="color:#89ddff">+</span><span style="color:#82aaff"> delta</span><span style="color:#89ddff">))</span><span style="color:#a6accd">  </span><span style="color:#676e95;font-style:italic"># 防止出现 log(0) 无限大</span></span>
<span class="line"></span></code></pre></div><p>计算例子：</p><div class="language-pycon"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">&gt;&gt;&gt; t = [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]</span></span>
<span class="line"><span style="color:#a6accd">&gt;&gt;&gt; y = [0.1, 0.05, 0.6, 0.0, 0.05, 0.1, 0.0, 0.1, 0.0, 0.0]</span></span>
<span class="line"><span style="color:#a6accd">&gt;&gt;&gt; cross_entropy_error(np.array(y), np.array(t))</span></span>
<span class="line"><span style="color:#a6accd">0.51082545709933802</span></span>
<span class="line"><span style="color:#a6accd">&gt;&gt;&gt;</span></span>
<span class="line"><span style="color:#a6accd">&gt;&gt;&gt; y = [0.1, 0.05, 0.1, 0.0, 0.05, 0.1, 0.0, 0.6, 0.0, 0.0]</span></span>
<span class="line"><span style="color:#a6accd">&gt;&gt;&gt; cross_entropy_error(np.array(y), np.array(t))</span></span>
<span class="line"><span style="color:#a6accd">2.3025840929945458</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><h3 id="mini-batch-学习" tabindex="-1">mini-batch 学习 <a aria-current="page" href="/posts/learning/deep-learning-from-scratch-learning-of-neural-network#mini-batch-学习" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>所谓使用训练数据进行学习，就是针对训练数据计算损失函数的值，找出使该值尽可能小的参数。计算损失函数时必须将所有的训练数据作为对象，考虑所有训练数据的损失函数的总和。</p><p>以交叉熵误差为例，如果要计算所有训练数据的损失函数的总和，可以这样：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>E</mi><mo>=</mo><mo>−</mo><mfrac><mn>1</mn><mi>N</mi></mfrac><munder><mo>∑</mo><mi>n</mi></munder><munder><mo>∑</mo><mi>k</mi></munder><msub><mi>t</mi><mrow><mi>n</mi><mi>k</mi></mrow></msub><mi>log</mi><mo>⁡</mo><msub><mi>y</mi><mrow><mi>n</mi><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">E = - \frac{1}{N} \sum \limits_n \sum \limits_k t_{nk} \log y_{nk}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord mathnormal" style="margin-right:.05764em">E</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:2.6236em;vertical-align:-1.3021em"></span><span class="mord">−</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3214em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.10903em">N</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.1667em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em"><span style="top:-1.9em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.25em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.1667em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.05em"><span style="top:-1.8479em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3021em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.1667em"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">nk</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.1667em"></span><span class="mop">lo<span style="margin-right:.01389em">g</span></span><span class="mspace" style="margin-right:.1667em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:-.0359em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">nk</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span></span></p><p>N 自然是数据个数，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>y</mi><mrow><mi>n</mi><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">y_{nk}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.1944em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.03588em">y</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:-.0359em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">nk</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 是神经网络的输出中第 n 个数据的第 k 个元素的值，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>t</mi><mrow><mi>n</mi><mi>k</mi></mrow></msub></mrow><annotation encoding="application/x-tex">t_{nk}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.7651em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">t</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">nk</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 则是对应的监督数据。观察可以发现这里其实就是把单个数据的损失函数的公式扩大到了 N 个数据，随后除以 N 正规化处理。这个式子也可以说是“平均损失函数”。</p><p>在数据集比较大的情况下（比如之前用到的 MNIST 数据集，训练数据就有60000个），根据所有的训练数据来算损失函数的和代价就太大了。实际操作中一般是从全部数据中选出一部分作为全部数据的“近似”（<strong>mini-batch</strong>），用这些数据进行学习（mini-batch 学习）。比方说从60000个训练数据中随机选择100笔，在用这100笔数据进行学习。</p><p>（按我的理解，书上这里的说法应该是用样本代表整体。搜到的比较多的说法是将一批所有数据再分成若干份，称作 mini-batch，训练时一次更新一个 mini-batch，整个数据集会更新多次，最终还是使用了所有数据。）</p><p>随机抽取数据时可以利用 <code>np.random.choice()</code>，像这样：</p><div class="language-python"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#a6accd">train_size </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> x_train</span><span style="color:#89ddff">.</span><span style="color:#f07178">shape</span><span style="color:#89ddff">[</span><span style="color:#f78c6c">0</span><span style="color:#89ddff">]</span><span style="color:#a6accd">  </span><span style="color:#676e95;font-style:italic"># 对于 MNIST 的训练数据，是60000</span></span>
<span class="line"><span style="color:#a6accd">batch_size </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#f78c6c">10</span></span>
<span class="line"><span style="color:#a6accd">batch_mask </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> np</span><span style="color:#89ddff">.</span><span style="color:#f07178">random</span><span style="color:#89ddff">.</span><span style="color:#82aaff">choice</span><span style="color:#89ddff">(</span><span style="color:#82aaff">train_size</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> batch_size</span><span style="color:#89ddff">)</span><span style="color:#a6accd">  </span><span style="color:#676e95;font-style:italic"># 在0到59999之间随机选择10个数，得到包含被选数据的索引的数组</span></span>
<span class="line"><span style="color:#a6accd">x_batch </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> x_train</span><span style="color:#89ddff">[</span><span style="color:#a6accd">batch_mask</span><span style="color:#89ddff">]</span><span style="color:#a6accd">  </span><span style="color:#676e95;font-style:italic"># 被选测试数据</span></span>
<span class="line"><span style="color:#a6accd">t_batch </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> t_train</span><span style="color:#89ddff">[</span><span style="color:#a6accd">batch_mask</span><span style="color:#89ddff">]</span><span style="color:#a6accd">  </span><span style="color:#676e95;font-style:italic"># 被选测试数据的标签</span></span>
<span class="line"></span></code></pre></div><p>如果要实现 mini-batch 的交叉熵误差，可以这样：</p><div class="language-python"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#c792ea">def</span><span style="color:#a6accd"> </span><span style="color:#82aaff">cross_entropy_error</span><span style="color:#89ddff">(</span><span style="color:#a6accd;font-style:italic">y</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> </span><span style="color:#a6accd;font-style:italic">t</span><span style="color:#89ddff">):</span></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#676e95;font-style:italic"># 只有一个数据的时候改变数据形状</span></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#89ddff;font-style:italic">if</span><span style="color:#a6accd"> y</span><span style="color:#89ddff">.</span><span style="color:#f07178">ndim</span><span style="color:#a6accd"> </span><span style="color:#89ddff">==</span><span style="color:#a6accd"> </span><span style="color:#f78c6c">1</span><span style="color:#89ddff">:</span></span>
<span class="line"><span style="color:#a6accd">        t </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> t</span><span style="color:#89ddff">.</span><span style="color:#82aaff">reshape</span><span style="color:#89ddff">(</span><span style="color:#f78c6c">1</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> t</span><span style="color:#89ddff">.</span><span style="color:#f07178">size</span><span style="color:#89ddff">)</span></span>
<span class="line"><span style="color:#a6accd">        y </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> y</span><span style="color:#89ddff">.</span><span style="color:#82aaff">reshape</span><span style="color:#89ddff">(</span><span style="color:#f78c6c">1</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> y</span><span style="color:#89ddff">.</span><span style="color:#f07178">size</span><span style="color:#89ddff">)</span></span>
<span class="line"><span style="color:#a6accd"> </span></span>
<span class="line"><span style="color:#a6accd">    batch_size </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> y</span><span style="color:#89ddff">.</span><span style="color:#f07178">shape</span><span style="color:#89ddff">[</span><span style="color:#f78c6c">0</span><span style="color:#89ddff">]</span></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#676e95;font-style:italic"># 如果监督数据不是独热形式而是正常的标签表示</span></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#676e95;font-style:italic"># return -np.sum(np.log(y[np.arange(batch_size), t] + 1e-7)) / batch_size</span></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#89ddff;font-style:italic">return</span><span style="color:#a6accd"> </span><span style="color:#89ddff">-</span><span style="color:#a6accd">np</span><span style="color:#89ddff">.</span><span style="color:#82aaff">sum</span><span style="color:#89ddff">(</span><span style="color:#82aaff">t </span><span style="color:#89ddff">*</span><span style="color:#82aaff"> np</span><span style="color:#89ddff">.</span><span style="color:#82aaff">log</span><span style="color:#89ddff">(</span><span style="color:#82aaff">y </span><span style="color:#89ddff">+</span><span style="color:#82aaff"> </span><span style="color:#f78c6c">1e-7</span><span style="color:#89ddff">))</span><span style="color:#a6accd"> </span><span style="color:#89ddff">/</span><span style="color:#a6accd"> batch_size</span></span>
<span class="line"></span></code></pre></div><p>应该可以根据独热编码1值的索引拿到对应标签，这样不论监督数据是哪种形式都可以写在一个实现里。</p><h3 id="为什么需要损失函数" tabindex="-1">为什么需要损失函数 <a aria-current="page" href="/posts/learning/deep-learning-from-scratch-learning-of-neural-network#为什么需要损失函数" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>按说学习的目标是使神经网络的识别精度足够高，那么用识别精度作为评判标准就好了，为什么还需要损失函数呢？</p><p>从前面的内容可以看出，寻找最优参数其实也是寻找使损失函数值尽可能小的参数的过程，为了找到损失函数的“最低点”，需要算出参数的导数（准确地说是梯度），根据导数反映出的变化趋势继续更新参数（对权重参数的损失函数求导，就表示如果稍微改变权重参数，损失函数将如何变化）。而识别精度很明显是离散值，很多时候微调参数后识别精度也不变化，这就导致在很多地方参数的导数会变为0，无法反映识别精度的变化趋势，也就无法继续进行神经网络的学习。</p><p>在激活函数上也是同样的道理，阶跃函数只在某个地方突变，其他地方导数都是0，无法体现参数改变带来的变化。而 sigmoid 函数的输出和曲线斜率（导数）都是连续变化的（且导数始终不为0），能保证神经网络的学习正确进行。</p><p><s>暂且记下，更“深”的理解可能还要我接着学吧……</s></p><h2 id="数值微分" tabindex="-1">数值微分 <a aria-current="page" href="/posts/learning/deep-learning-from-scratch-learning-of-neural-network#数值微分" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h2><p><s>这里引入数值微分的方法，用它计算导数和偏导数。</s></p><h3 id="导数" tabindex="-1">导数 <a aria-current="page" href="/posts/learning/deep-learning-from-scratch-learning-of-neural-network#导数" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>导数的概念应该不用多说，就算高数渣如我也应该有所认识……简单来说就是“瞬间的变化量”。</p><p>求函数的导数：</p><div class="language-python"><span class="copy"></span><pre class="shiki material-theme-palenight has-diff" tabindex="0"><code><span class="line"><span style="color:#c792ea">def</span><span style="color:#a6accd"> </span><span style="color:#82aaff">numerical_diff</span><span style="color:#89ddff">(</span><span style="color:#a6accd;font-style:italic">f</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> </span><span style="color:#a6accd;font-style:italic">x</span><span style="color:#89ddff">):</span></span>
<span class="line"><span style="color:#a6accd">    h </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#f78c6c">1e-4</span><span style="color:#a6accd"> </span><span style="color:#676e95;font-style:italic"># 0.0001，避免使用过小的值</span></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#89ddff;font-style:italic">return</span><span style="color:#a6accd"> </span><span style="color:#89ddff">(</span><span style="color:#82aaff">f</span><span style="color:#89ddff">(</span><span style="color:#82aaff">x</span><span style="color:#89ddff">+</span><span style="color:#82aaff">h</span><span style="color:#89ddff">)</span><span style="color:#a6accd"> </span><span style="color:#89ddff">-</span><span style="color:#a6accd"> </span><span style="color:#82aaff">f</span><span style="color:#89ddff">(</span><span style="color:#82aaff">x</span><span style="color:#89ddff">-</span><span style="color:#82aaff">h</span><span style="color:#89ddff">))</span><span style="color:#a6accd"> </span><span style="color:#89ddff">/</span><span style="color:#a6accd"> </span><span style="color:#89ddff">(</span><span style="color:#f78c6c">2</span><span style="color:#89ddff">*</span><span style="color:#a6accd">h</span><span style="color:#89ddff">)</span><span style="color:#a6accd"> </span><span style="color:#676e95;font-style:italic"># 使用中心差分来计算</span></span>
<span class="line"></span></code></pre></div><p>使用例，有函数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0.01</mn><msup><mi>x</mi><mn>2</mn></msup><mo>+</mo><mn>0.1</mn><mi>x</mi></mrow><annotation encoding="application/x-tex">f(x) = 0.01 x^2 + 0.1 x</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mopen">(</span><span class="mord mathnormal">x</span><span class="mclose">)</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:.8974em;vertical-align:-.0833em"></span><span class="mord">0.01</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8141em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:.6444em"></span><span class="mord">0.1</span><span class="mord mathnormal">x</span></span></span></span>：</p><div class="language-python"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#c792ea">def</span><span style="color:#a6accd"> </span><span style="color:#82aaff">function_1</span><span style="color:#89ddff">(</span><span style="color:#a6accd;font-style:italic">x</span><span style="color:#89ddff">):</span></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#89ddff;font-style:italic">return</span><span style="color:#a6accd"> </span><span style="color:#f78c6c">0.01</span><span style="color:#89ddff">*</span><span style="color:#a6accd">x</span><span style="color:#89ddff">**</span><span style="color:#f78c6c">2</span><span style="color:#a6accd"> </span><span style="color:#89ddff">+</span><span style="color:#a6accd"> </span><span style="color:#f78c6c">0.1</span><span style="color:#89ddff">*</span><span style="color:#a6accd">x  </span><span style="color:#676e95;font-style:italic"># 0.01x^2 + 0.1x</span></span>
<span class="line"></span></code></pre></div><p>求其在 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>=</mo><msub><mi>x</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">x=x_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.4306em"></span><span class="mord mathnormal">x</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:.5806em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 处的导数：</p><div class="language-pycon"><span class="copy"></span><pre class="shiki material-theme-palenight has-diff" tabindex="0"><code><span class="line"><span style="color:#a6accd">&gt;&gt;&gt; numerical_diff(function_1, x0)</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><blockquote><p>利用微小的差分求导数的过程称为数值微分，而基于数学式的推导求导数的过程，则用“解析性”（analytic）一词，称为“解析性求解”或者“解析性求导”。</p></blockquote><h3 id="偏导数" tabindex="-1">偏导数 <a aria-current="page" href="/posts/learning/deep-learning-from-scratch-learning-of-neural-network#偏导数" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>一个多变量的函数，关于其中一个变量求导数，其他变量恒定。<s>应该不用再解释……</s></p><p>计算偏导的例子，有函数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo>=</mo><msubsup><mi>x</mi><mn>0</mn><mn>2</mn></msubsup><mo>+</mo><msubsup><mi>x</mi><mn>1</mn><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">f(x_0, x_1) = x_0^2 + x_1^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:1.0622em;vertical-align:-.2481em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8141em"><span style="top:-2.4519em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2481em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1.0622em;vertical-align:-.2481em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8141em"><span style="top:-2.4519em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2481em"><span></span></span></span></span></span></span></span></span></span>：</p><div class="language-python"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#c792ea">def</span><span style="color:#a6accd"> </span><span style="color:#82aaff">function_2</span><span style="color:#89ddff">(</span><span style="color:#a6accd;font-style:italic">x</span><span style="color:#89ddff">):</span></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#89ddff;font-style:italic">return</span><span style="color:#a6accd"> np</span><span style="color:#89ddff">.</span><span style="color:#82aaff">sum</span><span style="color:#89ddff">(</span><span style="color:#82aaff">x</span><span style="color:#89ddff">**</span><span style="color:#f78c6c">2</span><span style="color:#89ddff">)</span></span>
<span class="line"></span></code></pre></div><p>求 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">x_0 = 3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.5806em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:.6444em"></span><span class="mord">3</span></span></span></span>，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub><mo>=</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">x_1 = 4</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.5806em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:.6444em"></span><span class="mord">4</span></span></span></span> 时，关于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">x_0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.5806em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 的偏导数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>f</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>x</mi><mn>0</mn></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial f}{\partial x_0}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3773em;vertical-align:-.4451em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.9322em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:.05556em">∂</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3173em"><span style="top:-2.357em;margin-left:0;margin-right:.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.4461em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:.05556em">∂</span><span class="mord mathnormal mtight" style="margin-right:.10764em">f</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.4451em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span>：</p><div class="language-pycon"><span class="copy"></span><pre class="shiki material-theme-palenight has-diff" tabindex="0"><code><span class="line"><span style="color:#a6accd">&gt;&gt;&gt; def function_tmp1(x0):</span></span>
<span class="line"><span style="color:#a6accd">...     return x0*x0 + 4.0**2.0</span></span>
<span class="line"><span style="color:#a6accd">...</span></span>
<span class="line"><span style="color:#a6accd">&gt;&gt;&gt; numerical_diff(function_tmp1, 3.0)</span></span>
<span class="line"><span style="color:#a6accd"></span></span></code></pre></div><p><s>求关于 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">x_1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.5806em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 的偏导数也是差不多的方法。</s></p><h2 id="梯度" tabindex="-1">梯度 <a aria-current="page" href="/posts/learning/deep-learning-from-scratch-learning-of-neural-network#梯度" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h2><p>前面按变量分别求偏导，如果把全部变量的偏导数汇总成向量，就是<strong>梯度</strong>。求梯度的实现方法可以是这样，非批处理：</p><div class="language-python"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#676e95;font-style:italic"># 求梯度</span></span>
<span class="line"><span style="color:#c792ea">def</span><span style="color:#a6accd"> </span><span style="color:#82aaff">numerical_gradient</span><span style="color:#89ddff">(</span><span style="color:#a6accd;font-style:italic">f</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> </span><span style="color:#a6accd;font-style:italic">x</span><span style="color:#89ddff">):</span></span>
<span class="line"><span style="color:#a6accd">    h </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#f78c6c">1e-4</span><span style="color:#a6accd">  </span><span style="color:#676e95;font-style:italic"># 0.0001</span></span>
<span class="line"><span style="color:#a6accd">    grad </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> np</span><span style="color:#89ddff">.</span><span style="color:#82aaff">zeros_like</span><span style="color:#89ddff">(</span><span style="color:#82aaff">x</span><span style="color:#89ddff">)</span><span style="color:#a6accd">  </span><span style="color:#676e95;font-style:italic"># 生成和 x 形状相同、元素都为0的数组</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#89ddff;font-style:italic">for</span><span style="color:#a6accd"> idx </span><span style="color:#89ddff;font-style:italic">in</span><span style="color:#a6accd"> </span><span style="color:#82aaff">range</span><span style="color:#89ddff">(</span><span style="color:#82aaff">x</span><span style="color:#89ddff">.</span><span style="color:#f07178">size</span><span style="color:#89ddff">):</span></span>
<span class="line"><span style="color:#a6accd">        tmp_val </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> x</span><span style="color:#89ddff">[</span><span style="color:#a6accd">idx</span><span style="color:#89ddff">]</span></span>
<span class="line"><span style="color:#a6accd">        </span><span style="color:#676e95;font-style:italic"># 计算 f(x+h)</span></span>
<span class="line"><span style="color:#a6accd">        x</span><span style="color:#89ddff">[</span><span style="color:#a6accd">idx</span><span style="color:#89ddff">]</span><span style="color:#a6accd"> </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> tmp_val </span><span style="color:#89ddff">+</span><span style="color:#a6accd"> h</span></span>
<span class="line"><span style="color:#a6accd">        fxh1 </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#82aaff">f</span><span style="color:#89ddff">(</span><span style="color:#82aaff">x</span><span style="color:#89ddff">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">        </span><span style="color:#676e95;font-style:italic"># 计算 f(x-h)</span></span>
<span class="line"><span style="color:#a6accd">        x</span><span style="color:#89ddff">[</span><span style="color:#a6accd">idx</span><span style="color:#89ddff">]</span><span style="color:#a6accd"> </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> tmp_val </span><span style="color:#89ddff">-</span><span style="color:#a6accd"> h</span></span>
<span class="line"><span style="color:#a6accd">        fxh2 </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#82aaff">f</span><span style="color:#89ddff">(</span><span style="color:#82aaff">x</span><span style="color:#89ddff">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">        </span><span style="color:#676e95;font-style:italic"># 算出偏导，还原 x</span></span>
<span class="line"><span style="color:#a6accd">        grad</span><span style="color:#89ddff">[</span><span style="color:#a6accd">idx</span><span style="color:#89ddff">]</span><span style="color:#a6accd"> </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#89ddff">(</span><span style="color:#a6accd">fxh1 </span><span style="color:#89ddff">-</span><span style="color:#a6accd"> fxh2</span><span style="color:#89ddff">)</span><span style="color:#a6accd"> </span><span style="color:#89ddff">/</span><span style="color:#a6accd"> </span><span style="color:#89ddff">(</span><span style="color:#f78c6c">2</span><span style="color:#89ddff">*</span><span style="color:#a6accd">h</span><span style="color:#89ddff">)</span></span>
<span class="line"><span style="color:#a6accd">        x</span><span style="color:#89ddff">[</span><span style="color:#a6accd">idx</span><span style="color:#89ddff">]</span><span style="color:#a6accd"> </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> tmp_val</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#89ddff;font-style:italic">return</span><span style="color:#a6accd"> grad</span></span>
<span class="line"></span></code></pre></div><p>这里求梯度用的方法其实和前面求单个变量的数值微分所用的方法没有什么区别……按照<a target="_blank" rel="noreferrer" href="https://github.com/oreilly-japan/deep-learning-from-scratch/blob/master/ch04/gradient_2d.py"><!--[-->作者给出的方法<!--]--><!----></a>（里面实现了批处理计算梯度）可以画出 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo>=</mo><msubsup><mi>x</mi><mn>0</mn><mn>2</mn></msubsup><mo>+</mo><msubsup><mi>x</mi><mn>1</mn><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">f(x_0, x_1) = x_0^2 + x_1^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:1.0622em;vertical-align:-.2481em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8141em"><span style="top:-2.4519em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2481em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1.0622em;vertical-align:-.2481em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8141em"><span style="top:-2.4519em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2481em"><span></span></span></span></span></span></span></span></span></span> 的负梯度：</p><p><img src="https://s2.loli.net/2022/10/14/XjxmfqakndbtHrc.png" alt="函数的负梯度"></p><p>~~函数图像可看做下凹的曲面，负梯度会指向最低点，更好理解梯度在这里的作用吧……~~在这个图中，离函数最小值越远，梯度向量的模就越大（变化越快），且向量都指向了“最低处”。而一般来说，“梯度”指向该点处函数值减小最多的方向。</p><h3 id="梯度法" tabindex="-1">梯度法 <a aria-current="page" href="/posts/learning/deep-learning-from-scratch-learning-of-neural-network#梯度法" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>神经网络需要在学习过程中找到最优参数（权重和偏置），也就是使损失函数取最小值时的参数。损失函数很复杂的时候就难以找到最小值所在的“点”，但是可以根据梯度表示的“变化快慢”来寻找尽可能小的值。不过梯度反映的是各点处函数值减小最多的方向，并不一定能找到最小值：梯度为0的点除了最小值还有极小值和鞍点。尽管如此，沿着梯度方向也能最大限度地减小函数值，所以可以沿着梯度方向寻找尽可能小的值。</p><blockquote><p>在梯度法中，函数的取值从当前位置沿着梯度方向前进一定距离，然后在新的地方重新求梯度，再沿着新梯度方向前进，如此反复，不断地沿梯度方向前进。像这样，通过不断地沿梯度方向前进，逐渐减小函数值的过程就是<strong>梯度法</strong>（gradient method）。梯度法是解决机器学习中最优化问题的常用方法，特别是在神经网络的学习中经常被使用。</p></blockquote><p>寻找最小值的梯度法叫做梯度下降法，寻找最大值的梯度法叫做梯度上升法。反转损失函数的符号，两类问题就可以互相转化。在神经网络中，梯度法主要指梯度下降法。</p><p>对于函数 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>f</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mn>0</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo>=</mo><msubsup><mi>x</mi><mn>0</mn><mn>2</mn></msubsup><mo>+</mo><msubsup><mi>x</mi><mn>1</mn><mn>2</mn></msubsup></mrow><annotation encoding="application/x-tex">f(x_0, x_1) = x_0^2 + x_1^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord mathnormal" style="margin-right:.10764em">f</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:1.0622em;vertical-align:-.2481em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8141em"><span style="top:-2.4519em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2481em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1.0622em;vertical-align:-.2481em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8141em"><span style="top:-2.4519em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2481em"><span></span></span></span></span></span></span></span></span></span>，用数学式表示梯度法：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>x</mi><mn>0</mn></msub><mo>=</mo><msub><mi>x</mi><mn>0</mn></msub><mo>−</mo><mi>η</mi><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>f</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>x</mi><mn>0</mn></msub></mrow></mfrac><mspace linebreak="newline"></mspace><mtext>&nbsp;</mtext><mspace linebreak="newline"></mspace><mtext>&nbsp;</mtext><msub><mi>x</mi><mn>1</mn></msub><mo>=</mo><msub><mi>x</mi><mn>1</mn></msub><mo>−</mo><mi>η</mi><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>f</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>x</mi><mn>1</mn></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">x_0 = x_0 - \eta \frac{\partial f}{\partial x_0} \\\ \\\ x_1 = x_1 - \eta \frac{\partial f}{\partial x_1}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.5806em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:.7333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:2.2074em;vertical-align:-.836em"></span><span class="mord mathnormal" style="margin-right:.03588em">η</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord" style="margin-right:.05556em">∂</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord" style="margin-right:.05556em">∂</span><span class="mord mathnormal" style="margin-right:.10764em">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.836em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:0"></span><span class="mspace">&nbsp;</span></span><span class="mspace newline"></span><span class="base"><span class="strut" style="height:.5806em;vertical-align:-.15em"></span><span class="mspace">&nbsp;</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:.7333em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:2.2074em;vertical-align:-.836em"></span><span class="mord mathnormal" style="margin-right:.03588em">η</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord" style="margin-right:.05556em">∂</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord" style="margin-right:.05556em">∂</span><span class="mord mathnormal" style="margin-right:.10764em">f</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.836em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span></span></p><p>上式中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>η</mi></mrow><annotation encoding="application/x-tex">\eta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.625em;vertical-align:-.1944em"></span><span class="mord mathnormal" style="margin-right:.03588em">η</span></span></span></span> 表示更新量（<strong>学习率</strong>），它决定了在一次学习中应该学习多少以及应该在多大程度上更新参数。这组式子表示更新一次，学习时反复执行这个步骤减小函数值。变量数量增加后方法也是类似的。</p><p>学习率需要事先确定，过大或过小都无法取得理想的结果。在学习过程中一般会一边改变学习率，一边观察学习是否正确进行。</p><p>使用梯度下降法的例子（<code>numerical_gradient</code> 的实现参考<a target="_blank" rel="noreferrer" href="https://github.com/oreilly-japan/deep-learning-from-scratch/blob/master/ch04/gradient_2d.py"><!--[-->这里<!--]--><!----></a>）：</p><div class="language-python"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#89ddff;font-style:italic">import</span><span style="color:#a6accd"> numpy </span><span style="color:#89ddff;font-style:italic">as</span><span style="color:#a6accd"> np</span></span>
<span class="line"><span style="color:#89ddff;font-style:italic">import</span><span style="color:#a6accd"> sys</span></span>
<span class="line"><span style="color:#89ddff;font-style:italic">import</span><span style="color:#a6accd"> os</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">sys</span><span style="color:#89ddff">.</span><span style="color:#f07178">path</span><span style="color:#89ddff">.</span><span style="color:#82aaff">append</span><span style="color:#89ddff">(</span><span style="color:#82aaff">os</span><span style="color:#89ddff">.</span><span style="color:#f07178">curdir</span><span style="color:#89ddff">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#89ddff;font-style:italic">from</span><span style="color:#a6accd"> ch04</span><span style="color:#89ddff">.</span><span style="color:#a6accd">gradient_2d </span><span style="color:#89ddff;font-style:italic">import</span><span style="color:#a6accd"> numerical_gradient</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#c792ea">def</span><span style="color:#a6accd"> </span><span style="color:#82aaff">function_2</span><span style="color:#89ddff">(</span><span style="color:#a6accd;font-style:italic">x</span><span style="color:#89ddff">):</span></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#89ddff;font-style:italic">return</span><span style="color:#a6accd"> x</span><span style="color:#89ddff">[</span><span style="color:#f78c6c">0</span><span style="color:#89ddff">]**</span><span style="color:#f78c6c">2</span><span style="color:#a6accd"> </span><span style="color:#89ddff">+</span><span style="color:#a6accd"> x</span><span style="color:#89ddff">[</span><span style="color:#f78c6c">1</span><span style="color:#89ddff">]**</span><span style="color:#f78c6c">2</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#676e95;font-style:italic"># f: 函数</span></span>
<span class="line"><span style="color:#676e95;font-style:italic"># init_x: 初始值</span></span>
<span class="line"><span style="color:#676e95;font-style:italic"># lr: 学习率</span></span>
<span class="line"><span style="color:#676e95;font-style:italic"># step_num： 梯度法重复次数</span></span>
<span class="line"><span style="color:#c792ea">def</span><span style="color:#a6accd"> </span><span style="color:#82aaff">gradient_descent</span><span style="color:#89ddff">(</span><span style="color:#a6accd;font-style:italic">f</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> </span><span style="color:#a6accd;font-style:italic">init_x</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> </span><span style="color:#a6accd;font-style:italic">lr</span><span style="color:#89ddff">=</span><span style="color:#f78c6c">0.01</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> </span><span style="color:#a6accd;font-style:italic">step_num</span><span style="color:#89ddff">=</span><span style="color:#f78c6c">100</span><span style="color:#89ddff">):</span></span>
<span class="line"><span style="color:#a6accd">    x </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> init_x</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#89ddff;font-style:italic">for</span><span style="color:#a6accd"> i </span><span style="color:#89ddff;font-style:italic">in</span><span style="color:#a6accd"> </span><span style="color:#82aaff">range</span><span style="color:#89ddff">(</span><span style="color:#82aaff">step_num</span><span style="color:#89ddff">):</span><span style="color:#a6accd">  </span><span style="color:#676e95;font-style:italic"># 反复执行更新</span></span>
<span class="line"><span style="color:#a6accd">        grad </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#82aaff">numerical_gradient</span><span style="color:#89ddff">(</span><span style="color:#82aaff">f</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> x</span><span style="color:#89ddff">)</span></span>
<span class="line"><span style="color:#a6accd">        x </span><span style="color:#89ddff">-=</span><span style="color:#a6accd"> lr </span><span style="color:#89ddff">*</span><span style="color:#a6accd"> grad</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#89ddff;font-style:italic">return</span><span style="color:#a6accd"> x</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">init_x </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> np</span><span style="color:#89ddff">.</span><span style="color:#82aaff">array</span><span style="color:#89ddff">([-</span><span style="color:#f78c6c">3.0</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> </span><span style="color:#f78c6c">4.0</span><span style="color:#89ddff">])</span></span>
<span class="line"><span style="color:#82aaff">print</span><span style="color:#89ddff">(</span><span style="color:#82aaff">gradient_descent</span><span style="color:#89ddff">(</span><span style="color:#82aaff">function_2</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> </span><span style="color:#a6accd;font-style:italic">init_x</span><span style="color:#89ddff">=</span><span style="color:#82aaff">init_x</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> </span><span style="color:#a6accd;font-style:italic">lr</span><span style="color:#89ddff">=</span><span style="color:#f78c6c">0.1</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> </span><span style="color:#a6accd;font-style:italic">step_num</span><span style="color:#89ddff">=</span><span style="color:#f78c6c">100</span><span style="color:#89ddff">))</span></span>
<span class="line"></span></code></pre></div><p>输出：</p><div class="language-bash"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#89ddff">[</span><span style="color:#a6accd">-</span><span style="color:#f78c6c">6.11110793e</span><span style="color:#89ddff">-</span><span style="color:#f78c6c">10</span><span style="color:#a6accd">  </span><span style="color:#f78c6c">8.14814391e</span><span style="color:#89ddff">-</span><span style="color:#f78c6c">10</span><span style="color:#89ddff">]</span></span>
<span class="line"></span></code></pre></div><p>上面设初始值为 <code>(-3.0, 4.0)</code>，用梯度法寻找最小值，得到的结果很接近函数的最小值点 <code>(0, 0)</code>。如果学习率不合适，得到的结果就会偏离更远。事实上，学习率过大时结果会过度发散，学习率太小时参数更新幅度太小，也很难得到合适的结果。</p><blockquote><p>像学习率这样的参数称为超参数。这是一种和神经网络的参数（权重和偏置）性质不同的参数。相对于神经网络的权重参数是通过训练数据和学习算法自动获得的，学习率这样的超参数则是人工设定的。一般来说，超参数需要尝试多个值，以便找到一种可以使学习顺利进行的设定。</p></blockquote><h3 id="神经网络的梯度" tabindex="-1">神经网络的梯度 <a aria-current="page" href="/posts/learning/deep-learning-from-scratch-learning-of-neural-network#神经网络的梯度" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>神经网络的学习需要用到损失函数关于权重参数的梯度。~~在一定的输入下权重参数确实就是变量呢……数学渣的小心确认……~~参考书上举的例子的话，对于一个只有一个形状为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo>×</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">2 \times 3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.7278em;vertical-align:-.0833em"></span><span class="mord">2</span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:.6444em"></span><span class="mord">3</span></span></span></span> 的权重 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold-italic">W</mi></mrow><annotation encoding="application/x-tex">\boldsymbol{W}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6861em"></span><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:.15972em">W</span></span></span></span></span></span> 的神经网络，损失函数用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>L</mi></mrow><annotation encoding="application/x-tex">L</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord mathnormal">L</span></span></span></span> 表示，梯度就可以用 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold-italic">W</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial L}{\partial \boldsymbol{W}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2251em;vertical-align:-.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8801em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:.05556em">∂</span><span class="mord mtight"><span class="mord mtight"><span class="mord boldsymbol mtight" style="margin-right:.15972em">W</span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:.05556em">∂</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> 表示。数学式如下：</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="bold-italic">W</mi><mo>=</mo><mrow><mo fence="true">(</mo><mtable rowspacing="0.16em" columnalign="center center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>w</mi><mn>11</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>w</mi><mn>12</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>w</mi><mn>13</mn></msub></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>&nbsp;</mtext><msub><mi>w</mi><mn>21</mn></msub></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>w</mi><mn>22</mn></msub></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><msub><mi>w</mi><mn>23</mn></msub></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\boldsymbol{W} = \begin{pmatrix} w_{1 1} &amp; w_{1 2} &amp; w_{1 3} \\\ w_{2 1} &amp; w_{2 2} &amp; w_{2 3} \end{pmatrix}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6861em"></span><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:.15972em">W</span></span></span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:2.4em;vertical-align:-.95em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em"><span style="top:-3.61em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:-.0269em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">11</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span><span style="top:-2.41em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mspace">&nbsp;</span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:-.0269em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">21</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.95em"><span></span></span></span></span></span><span class="arraycolsep" style="width:.5em"></span><span class="arraycolsep" style="width:.5em"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em"><span style="top:-3.61em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:-.0269em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">12</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span><span style="top:-2.41em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:-.0269em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">22</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.95em"><span></span></span></span></span></span><span class="arraycolsep" style="width:.5em"></span><span class="arraycolsep" style="width:.5em"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.45em"><span style="top:-3.61em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:-.0269em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">13</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span><span style="top:-2.41em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:-.0269em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">23</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.95em"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0"><span class="delimsizing size3">)</span></span></span></span></span></span></span></p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold-italic">W</mi></mrow></mfrac><mo>=</mo><mrow><mo fence="true">(</mo><mtable rowspacing="0.16em" columnalign="center center center" columnspacing="1em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>w</mi><mn>11</mn></msub></mrow></mfrac></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>w</mi><mn>12</mn></msub></mrow></mfrac></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>w</mi><mn>13</mn></msub></mrow></mfrac></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="false"><mrow><mtext>&nbsp;</mtext><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>w</mi><mn>21</mn></msub></mrow></mfrac></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>w</mi><mn>22</mn></msub></mrow></mfrac></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="false"><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>w</mi><mn>23</mn></msub></mrow></mfrac></mstyle></mtd></mtr></mtable><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">\frac{\partial L}{\partial \boldsymbol{W}} = \begin{pmatrix} \frac{\partial L}{\partial w_{1 1}} &amp; \frac{\partial L}{\partial w_{1 2}} &amp; \frac{\partial L}{\partial w_{1 3}} \\\ \frac{\partial L}{\partial w_{2 1}} &amp; \frac{\partial L}{\partial w_{2 2}} &amp; \frac{\partial L}{\partial w_{2 3}} \end{pmatrix}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.0574em;vertical-align:-.686em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3714em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord" style="margin-right:.05556em">∂</span><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:.15972em">W</span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.677em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord" style="margin-right:.05556em">∂</span><span class="mord mathnormal">L</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.686em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:2.6504em;vertical-align:-1.0752em"></span><span class="minner"><span class="mopen delimcenter" style="top:0"><span class="delimsizing size3">(</span></span><span class="mord"><span class="mtable"><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5752em"><span style="top:-3.6951em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8801em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:.05556em">∂</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3173em"><span style="top:-2.357em;margin-left:-.0269em;margin-right:.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">11</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:.05556em">∂</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.4451em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-2.3699em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mspace">&nbsp;</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8801em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:.05556em">∂</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3173em"><span style="top:-2.357em;margin-left:-.0269em;margin-right:.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">21</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:.05556em">∂</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.4451em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.0752em"><span></span></span></span></span></span><span class="arraycolsep" style="width:.5em"></span><span class="arraycolsep" style="width:.5em"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5752em"><span style="top:-3.6951em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8801em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:.05556em">∂</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3173em"><span style="top:-2.357em;margin-left:-.0269em;margin-right:.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">12</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:.05556em">∂</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.4451em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-2.3699em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8801em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:.05556em">∂</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3173em"><span style="top:-2.357em;margin-left:-.0269em;margin-right:.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">22</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:.05556em">∂</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.4451em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.0752em"><span></span></span></span></span></span><span class="arraycolsep" style="width:.5em"></span><span class="arraycolsep" style="width:.5em"></span><span class="col-align-c"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5752em"><span style="top:-3.6951em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8801em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:.05556em">∂</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3173em"><span style="top:-2.357em;margin-left:-.0269em;margin-right:.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">13</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:.05556em">∂</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.4451em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span><span style="top:-2.3699em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8801em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:.05556em">∂</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3173em"><span style="top:-2.357em;margin-left:-.0269em;margin-right:.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">23</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:.05556em">∂</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.4451em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.0752em"><span></span></span></span></span></span></span></span><span class="mclose delimcenter" style="top:0"><span class="delimsizing size3">)</span></span></span></span></span></span></span></p><p><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="bold-italic">W</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial L}{\partial \boldsymbol{W}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.2251em;vertical-align:-.345em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8801em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:.05556em">∂</span><span class="mord mtight"><span class="mord mtight"><span class="mord boldsymbol mtight" style="margin-right:.15972em">W</span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:.05556em">∂</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.345em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> 的元素由各个元素对应的偏导数构成，形状与 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold-italic">W</mi></mrow><annotation encoding="application/x-tex">\boldsymbol{W}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6861em"></span><span class="mord"><span class="mord"><span class="mord boldsymbol" style="margin-right:.15972em">W</span></span></span></span></span></span> 相同。</p><p>就以这样一个神经网络为例，实现求梯度：</p><div class="language-python"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#89ddff;font-style:italic">import</span><span style="color:#a6accd"> sys</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> os</span></span>
<span class="line"><span style="color:#89ddff;font-style:italic">import</span><span style="color:#a6accd"> numpy </span><span style="color:#89ddff;font-style:italic">as</span><span style="color:#a6accd"> np</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">sys</span><span style="color:#89ddff">.</span><span style="color:#f07178">path</span><span style="color:#89ddff">.</span><span style="color:#82aaff">append</span><span style="color:#89ddff">(</span><span style="color:#82aaff">os</span><span style="color:#89ddff">.</span><span style="color:#f07178">curdir</span><span style="color:#89ddff">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#89ddff;font-style:italic">from</span><span style="color:#a6accd"> common</span><span style="color:#89ddff">.</span><span style="color:#a6accd">func </span><span style="color:#89ddff;font-style:italic">import</span><span style="color:#a6accd"> softmax</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> cross_entropy_error</span></span>
<span class="line"><span style="color:#89ddff;font-style:italic">from</span><span style="color:#a6accd"> common</span><span style="color:#89ddff">.</span><span style="color:#a6accd">gradient </span><span style="color:#89ddff;font-style:italic">import</span><span style="color:#a6accd"> numerical_gradient</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#c792ea">class</span><span style="color:#a6accd"> </span><span style="color:#ffcb6b">simpleNet</span><span style="color:#89ddff">:</span></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#c792ea">def</span><span style="color:#a6accd"> </span><span style="color:#82aaff">__init__</span><span style="color:#89ddff">(</span><span style="color:#f07178;font-style:italic">self</span><span style="color:#89ddff">)</span><span style="color:#a6accd"> </span><span style="color:#89ddff">-&gt;</span><span style="color:#a6accd"> </span><span style="color:#89ddff">None:</span></span>
<span class="line"><span style="color:#a6accd">        self</span><span style="color:#89ddff">.</span><span style="color:#f07178">W</span><span style="color:#a6accd"> </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> np</span><span style="color:#89ddff">.</span><span style="color:#f07178">random</span><span style="color:#89ddff">.</span><span style="color:#82aaff">randn</span><span style="color:#89ddff">(</span><span style="color:#f78c6c">2</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> </span><span style="color:#f78c6c">3</span><span style="color:#89ddff">)</span><span style="color:#a6accd">  </span><span style="color:#676e95;font-style:italic"># 利用高斯分布随机生成0到1之间的数，填充指定形状的多维数组</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#c792ea">def</span><span style="color:#a6accd"> </span><span style="color:#82aaff">predict</span><span style="color:#89ddff">(</span><span style="color:#f07178;font-style:italic">self</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> </span><span style="color:#a6accd;font-style:italic">x</span><span style="color:#89ddff">):</span></span>
<span class="line"><span style="color:#a6accd">        </span><span style="color:#89ddff;font-style:italic">return</span><span style="color:#a6accd"> np</span><span style="color:#89ddff">.</span><span style="color:#82aaff">dot</span><span style="color:#89ddff">(</span><span style="color:#82aaff">x</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> </span><span style="color:#a6accd">self</span><span style="color:#89ddff">.</span><span style="color:#f07178">W</span><span style="color:#89ddff">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#c792ea">def</span><span style="color:#a6accd"> </span><span style="color:#82aaff">loss</span><span style="color:#89ddff">(</span><span style="color:#f07178;font-style:italic">self</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> </span><span style="color:#a6accd;font-style:italic">x</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> </span><span style="color:#a6accd;font-style:italic">t</span><span style="color:#89ddff">):</span></span>
<span class="line"><span style="color:#a6accd">        z </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> self</span><span style="color:#89ddff">.</span><span style="color:#82aaff">predict</span><span style="color:#89ddff">(</span><span style="color:#82aaff">x</span><span style="color:#89ddff">)</span></span>
<span class="line"><span style="color:#a6accd">        y </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#82aaff">softmax</span><span style="color:#89ddff">(</span><span style="color:#82aaff">z</span><span style="color:#89ddff">)</span></span>
<span class="line"><span style="color:#a6accd">        loss </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#82aaff">cross_entropy_error</span><span style="color:#89ddff">(</span><span style="color:#82aaff">y</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> t</span><span style="color:#89ddff">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">        </span><span style="color:#89ddff;font-style:italic">return</span><span style="color:#a6accd"> loss</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">net </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#82aaff">simpleNet</span><span style="color:#89ddff">()</span></span>
<span class="line"><span style="color:#82aaff">print</span><span style="color:#89ddff">(</span><span style="color:#89ddff">'</span><span style="color:#c3e88d">net.W:</span><span style="color:#a6accd">\n</span><span style="color:#89ddff">'</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> net</span><span style="color:#89ddff">.</span><span style="color:#f07178">W</span><span style="color:#89ddff">)</span><span style="color:#a6accd">  </span><span style="color:#676e95;font-style:italic"># net 的权重参数</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">x </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> np</span><span style="color:#89ddff">.</span><span style="color:#82aaff">array</span><span style="color:#89ddff">([</span><span style="color:#f78c6c">0.6</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> </span><span style="color:#f78c6c">0.9</span><span style="color:#89ddff">])</span></span>
<span class="line"><span style="color:#a6accd">p </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> net</span><span style="color:#89ddff">.</span><span style="color:#82aaff">predict</span><span style="color:#89ddff">(</span><span style="color:#82aaff">x</span><span style="color:#89ddff">)</span></span>
<span class="line"><span style="color:#82aaff">print</span><span style="color:#89ddff">(</span><span style="color:#89ddff">'</span><span style="color:#c3e88d">predict x:</span><span style="color:#a6accd">\n</span><span style="color:#89ddff">'</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> p</span><span style="color:#89ddff">)</span><span style="color:#a6accd">  </span><span style="color:#676e95;font-style:italic"># 输出</span></span>
<span class="line"><span style="color:#82aaff">print</span><span style="color:#89ddff">(</span><span style="color:#89ddff">'</span><span style="color:#c3e88d">index of max value:</span><span style="color:#a6accd">\n</span><span style="color:#89ddff">'</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> np</span><span style="color:#89ddff">.</span><span style="color:#82aaff">argmax</span><span style="color:#89ddff">(</span><span style="color:#82aaff">p</span><span style="color:#89ddff">))</span><span style="color:#a6accd">  </span><span style="color:#676e95;font-style:italic"># 最大值索引</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">t </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> np</span><span style="color:#89ddff">.</span><span style="color:#82aaff">array</span><span style="color:#89ddff">([</span><span style="color:#f78c6c">0</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> </span><span style="color:#f78c6c">0</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> </span><span style="color:#f78c6c">1</span><span style="color:#89ddff">])</span></span>
<span class="line"><span style="color:#82aaff">print</span><span style="color:#89ddff">(</span><span style="color:#89ddff">'</span><span style="color:#c3e88d">net.loss:</span><span style="color:#a6accd">\n</span><span style="color:#89ddff">'</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> net</span><span style="color:#89ddff">.</span><span style="color:#82aaff">loss</span><span style="color:#89ddff">(</span><span style="color:#82aaff">x</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> t</span><span style="color:#89ddff">))</span><span style="color:#a6accd">  </span><span style="color:#676e95;font-style:italic"># 计算交叉熵损失</span></span>
<span class="line"></span>
<span class="line"><span style="color:#676e95;font-style:italic"># W 是伪参数，计算梯度时会执行 f，用到的是 net 内的 W</span></span>
<span class="line"><span style="color:#676e95;font-style:italic"># def f(W):</span></span>
<span class="line"><span style="color:#676e95;font-style:italic">#     return net.loss(x, t)</span></span>
<span class="line"><span style="color:#676e95;font-style:italic"># 也可以用 lambda 表达式</span></span>
<span class="line"><span style="color:#a6accd">f </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#c792ea">lambda</span><span style="color:#a6accd"> </span><span style="color:#a6accd;font-style:italic">w</span><span style="color:#89ddff">:</span><span style="color:#a6accd"> net</span><span style="color:#89ddff">.</span><span style="color:#82aaff">loss</span><span style="color:#89ddff">(</span><span style="color:#82aaff">x</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> t</span><span style="color:#89ddff">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">dW </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#82aaff">numerical_gradient</span><span style="color:#89ddff">(</span><span style="color:#82aaff">f</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> net</span><span style="color:#89ddff">.</span><span style="color:#f07178">W</span><span style="color:#89ddff">)</span><span style="color:#a6accd">  </span><span style="color:#676e95;font-style:italic"># 求关于权重的梯度，权重自然是 f 的参数</span></span>
<span class="line"><span style="color:#82aaff">print</span><span style="color:#89ddff">(</span><span style="color:#89ddff">'</span><span style="color:#c3e88d">dW:</span><span style="color:#a6accd">\n</span><span style="color:#89ddff">'</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> dW</span><span style="color:#89ddff">)</span></span>
<span class="line"></span></code></pre></div><p>某一次运行上面代码的输出：</p><div class="language-bash"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#ffcb6b">net.W:</span></span>
<span class="line"><span style="color:#a6accd"> </span><span style="color:#89ddff">[[</span><span style="color:#a6accd"> </span><span style="color:#f78c6c">0.03900802</span><span style="color:#a6accd"> -</span><span style="color:#f78c6c">0.24126244</span><span style="color:#a6accd"> -</span><span style="color:#f78c6c">1.60380801</span><span style="color:#89ddff">]</span></span>
<span class="line"><span style="color:#a6accd"> </span><span style="color:#89ddff">[</span><span style="color:#a6accd">-</span><span style="color:#f78c6c">0.94332177</span><span style="color:#a6accd">  </span><span style="color:#f78c6c">1.36421781</span><span style="color:#a6accd"> -</span><span style="color:#f78c6c">1.05313682</span><span style="color:#89ddff">]]</span></span>
<span class="line"><span style="color:#ffcb6b">predict</span><span style="color:#a6accd"> </span><span style="color:#c3e88d">x:</span></span>
<span class="line"><span style="color:#a6accd"> </span><span style="color:#89ddff">[</span><span style="color:#a6accd">-</span><span style="color:#f78c6c">0.82558478</span><span style="color:#a6accd">  </span><span style="color:#f78c6c">1.08303856</span><span style="color:#a6accd"> -</span><span style="color:#f78c6c">1.91010794</span><span style="color:#89ddff">]</span></span>
<span class="line"><span style="color:#ffcb6b">index</span><span style="color:#a6accd"> </span><span style="color:#c3e88d">of</span><span style="color:#a6accd"> </span><span style="color:#c3e88d">max</span><span style="color:#a6accd"> </span><span style="color:#c3e88d">value:</span></span>
<span class="line"><span style="color:#a6accd"> </span><span style="color:#ffcb6b">1</span></span>
<span class="line"><span style="color:#ffcb6b">net.loss:</span></span>
<span class="line"><span style="color:#a6accd"> </span><span style="color:#ffcb6b">3.174142995517425</span></span>
<span class="line"><span style="color:#ffcb6b">dW:</span></span>
<span class="line"><span style="color:#a6accd"> </span><span style="color:#89ddff">[[</span><span style="color:#a6accd"> </span><span style="color:#f78c6c">0.07424015</span><span style="color:#a6accd">  </span><span style="color:#f78c6c">0.50066058</span><span style="color:#a6accd"> -</span><span style="color:#f78c6c">0.57490072</span><span style="color:#89ddff">]</span></span>
<span class="line"><span style="color:#a6accd"> </span><span style="color:#89ddff">[</span><span style="color:#a6accd"> </span><span style="color:#f78c6c">0.11136022</span><span style="color:#a6accd">  </span><span style="color:#f78c6c">0.75099087</span><span style="color:#a6accd"> -</span><span style="color:#f78c6c">0.86235108</span><span style="color:#89ddff">]]</span></span>
<span class="line"></span></code></pre></div><p>计算 <code>dW</code> 得到的结果是与 <code>W</code> 形状一致的二维数组。看结果的话，例如 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>w</mi><mn>12</mn></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial L}{\partial w_{1 2}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3252em;vertical-align:-.4451em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8801em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:.05556em">∂</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3173em"><span style="top:-2.357em;margin-left:-.0269em;margin-right:.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">12</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:.05556em">∂</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.4451em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> 的值约为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.5</mn></mrow><annotation encoding="application/x-tex">0.5</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6444em"></span><span class="mord">0.5</span></span></span></span>，表示如果 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>12</mn></msub></mrow><annotation encoding="application/x-tex">w_{1 2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.5806em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:-.0269em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">12</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 增加 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6944em"></span><span class="mord mathnormal">h</span></span></span></span>，损失函数的值会增加 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.5</mn><mi>h</mi></mrow><annotation encoding="application/x-tex">0.5 h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6944em"></span><span class="mord">0.5</span><span class="mord mathnormal">h</span></span></span></span>；再比方说 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>L</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>w</mi><mn>23</mn></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial L}{\partial w_{2 3}}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.3252em;vertical-align:-.4451em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8801em"><span style="top:-2.655em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:.05556em">∂</span><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3173em"><span style="top:-2.357em;margin-left:-.0269em;margin-right:.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mtight"><span class="mord mtight">23</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.143em"><span></span></span></span></span></span></span></span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:.04em"></span></span><span style="top:-3.394em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight" style="margin-right:.05556em">∂</span><span class="mord mathnormal mtight">L</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.4451em"><span></span></span></span></span></span><span class="mclose nulldelimiter"></span></span></span></span></span> 的值约为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>0.86</mn></mrow><annotation encoding="application/x-tex">-0.86</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.7278em;vertical-align:-.0833em"></span><span class="mord">−</span><span class="mord">0.86</span></span></span></span>，表示如果 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>23</mn></msub></mrow><annotation encoding="application/x-tex">w_{2 3}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.5806em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:-.0269em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">23</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 增加 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi></mrow><annotation encoding="application/x-tex">h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6944em"></span><span class="mord mathnormal">h</span></span></span></span>，损失函数的值会减小 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.86</mn><mi>h</mi></mrow><annotation encoding="application/x-tex">0.86 h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6944em"></span><span class="mord">0.86</span><span class="mord mathnormal">h</span></span></span></span>。因为要减小损失函数的值，所以 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>12</mn></msub></mrow><annotation encoding="application/x-tex">w_{1 2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.5806em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:-.0269em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">12</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 应该往负方向更新，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>23</mn></msub></mrow><annotation encoding="application/x-tex">w_{2 3}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.5806em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:-.0269em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">23</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 应该往正方向更新，且更新 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>23</mn></msub></mrow><annotation encoding="application/x-tex">w_{2 3}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.5806em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:-.0269em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">23</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 比更新 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>w</mi><mn>12</mn></msub></mrow><annotation encoding="application/x-tex">w_{1 2}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.5806em;vertical-align:-.15em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:.02691em">w</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:-.0269em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">12</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span></span></span></span> 效果更明显。</p><h2 id="实现学习算法" tabindex="-1">实现学习算法 <a aria-current="page" href="/posts/learning/deep-learning-from-scratch-learning-of-neural-network#实现学习算法" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h2><blockquote><p>神经网络的学习步骤如下所示。</p><ul><li><strong>前提</strong><ul><li>神经网络存在合适的权重和偏置，调整权重和偏置以便拟合训练数据的过程称为“学习”。神经网络的学习分成下面4个步骤。</li></ul></li><li><strong>步骤1（mini-batch）</strong><ul><li>从训练数据中随机选出一部分数据，这部分数据称为 mini-batch。我们的目标是减小 mini-batch 的损失函数的值。</li></ul></li><li><strong>步骤2（计算梯度）</strong><ul><li>为了减小 mini-batch 的损失函数的值，需要求出各个权重参数的梯度。梯度表示损失函数的值减小最多的方向。</li></ul></li><li><strong>步骤3（更新参数）</strong><ul><li>将权重参数沿梯度方向进行微小更新。</li></ul></li><li><strong>步骤4（重复）</strong><ul><li>重复步骤1、步骤2、步骤3</li></ul></li></ul></blockquote><p>上面的方法通过梯度下降更新参数，因为使用了随机选择的 mini-batch，所以又叫做<strong>随机梯度下降法</strong>（stochastic gradient descent，SGD）。</p><p>下面跟着书上的指导实现手写数字识别的神经网络。以2层神经网络（有1层隐藏层）为对象，使用 MNIST 数据集进行学习。</p><h3 id="_2层神经网络的类" tabindex="-1">2层神经网络的类 <a aria-current="page" href="/posts/learning/deep-learning-from-scratch-learning-of-neural-network#_2层神经网络的类" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>为2层神经网络实现一个类，如下所示：</p><div class="language-python"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#89ddff;font-style:italic">import</span><span style="color:#a6accd"> sys</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> os</span></span>
<span class="line"><span style="color:#89ddff;font-style:italic">import</span><span style="color:#a6accd"> numpy </span><span style="color:#89ddff;font-style:italic">as</span><span style="color:#a6accd"> np</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">sys</span><span style="color:#89ddff">.</span><span style="color:#f07178">path</span><span style="color:#89ddff">.</span><span style="color:#82aaff">append</span><span style="color:#89ddff">(</span><span style="color:#82aaff">os</span><span style="color:#89ddff">.</span><span style="color:#f07178">curdir</span><span style="color:#89ddff">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#89ddff;font-style:italic">from</span><span style="color:#a6accd"> common</span><span style="color:#89ddff">.</span><span style="color:#a6accd">func </span><span style="color:#89ddff;font-style:italic">import</span><span style="color:#a6accd"> </span><span style="color:#89ddff">*</span></span>
<span class="line"><span style="color:#89ddff;font-style:italic">from</span><span style="color:#a6accd"> common</span><span style="color:#89ddff">.</span><span style="color:#a6accd">gradient </span><span style="color:#89ddff;font-style:italic">import</span><span style="color:#a6accd"> numerical_gradient</span></span>
<span class="line"></span>
<span class="line"></span>
<span class="line"><span style="color:#c792ea">class</span><span style="color:#a6accd"> </span><span style="color:#ffcb6b">TwoLayerNet</span><span style="color:#89ddff">:</span></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#c792ea">def</span><span style="color:#a6accd"> </span><span style="color:#82aaff">__init__</span><span style="color:#89ddff">(</span><span style="color:#f07178;font-style:italic">self</span><span style="color:#89ddff">,</span></span>
<span class="line"><span style="color:#a6accd">                 </span><span style="color:#a6accd;font-style:italic">input_size</span><span style="color:#89ddff">,</span></span>
<span class="line"><span style="color:#a6accd">                 </span><span style="color:#a6accd;font-style:italic">hidden_size</span><span style="color:#89ddff">,</span></span>
<span class="line"><span style="color:#a6accd">                 </span><span style="color:#a6accd;font-style:italic">output_size</span><span style="color:#89ddff">,</span></span>
<span class="line"><span style="color:#a6accd">                 </span><span style="color:#a6accd;font-style:italic">weight_init_std</span><span style="color:#89ddff">=</span><span style="color:#f78c6c">0.01</span><span style="color:#89ddff">):</span></span>
<span class="line"><span style="color:#a6accd">        </span><span style="color:#676e95;font-style:italic"># 初始化权重偏置，注意各层参数的形状</span></span>
<span class="line"><span style="color:#a6accd">        self</span><span style="color:#89ddff">.</span><span style="color:#f07178">params</span><span style="color:#a6accd"> </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#89ddff">{}</span></span>
<span class="line"><span style="color:#a6accd">        self</span><span style="color:#89ddff">.</span><span style="color:#f07178">params</span><span style="color:#89ddff">[</span><span style="color:#89ddff">'</span><span style="color:#c3e88d">W1</span><span style="color:#89ddff">'</span><span style="color:#89ddff">]</span><span style="color:#a6accd"> </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> weight_init_std </span><span style="color:#89ddff">*</span><span style="color:#a6accd"> np</span><span style="color:#89ddff">.</span><span style="color:#f07178">random</span><span style="color:#89ddff">.</span><span style="color:#82aaff">randn</span><span style="color:#89ddff">(</span></span>
<span class="line"><span style="color:#82aaff">            input_size</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> hidden_size</span><span style="color:#89ddff">)</span></span>
<span class="line"><span style="color:#a6accd">        self</span><span style="color:#89ddff">.</span><span style="color:#f07178">params</span><span style="color:#89ddff">[</span><span style="color:#89ddff">'</span><span style="color:#c3e88d">b1</span><span style="color:#89ddff">'</span><span style="color:#89ddff">]</span><span style="color:#a6accd"> </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> np</span><span style="color:#89ddff">.</span><span style="color:#82aaff">zeros</span><span style="color:#89ddff">(</span><span style="color:#82aaff">hidden_size</span><span style="color:#89ddff">)</span></span>
<span class="line"><span style="color:#a6accd">        self</span><span style="color:#89ddff">.</span><span style="color:#f07178">params</span><span style="color:#89ddff">[</span><span style="color:#89ddff">'</span><span style="color:#c3e88d">W2</span><span style="color:#89ddff">'</span><span style="color:#89ddff">]</span><span style="color:#a6accd"> </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> weight_init_std </span><span style="color:#89ddff">*</span><span style="color:#a6accd"> np</span><span style="color:#89ddff">.</span><span style="color:#f07178">random</span><span style="color:#89ddff">.</span><span style="color:#82aaff">randn</span><span style="color:#89ddff">(</span></span>
<span class="line"><span style="color:#82aaff">            hidden_size</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> output_size</span><span style="color:#89ddff">)</span></span>
<span class="line"><span style="color:#a6accd">        self</span><span style="color:#89ddff">.</span><span style="color:#f07178">params</span><span style="color:#89ddff">[</span><span style="color:#89ddff">'</span><span style="color:#c3e88d">b2</span><span style="color:#89ddff">'</span><span style="color:#89ddff">]</span><span style="color:#a6accd"> </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> np</span><span style="color:#89ddff">.</span><span style="color:#82aaff">zeros</span><span style="color:#89ddff">(</span><span style="color:#82aaff">output_size</span><span style="color:#89ddff">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#676e95;font-style:italic"># 推理过程</span></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#c792ea">def</span><span style="color:#a6accd"> </span><span style="color:#82aaff">predict</span><span style="color:#89ddff">(</span><span style="color:#f07178;font-style:italic">self</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> </span><span style="color:#a6accd;font-style:italic">x</span><span style="color:#89ddff">):</span></span>
<span class="line"><span style="color:#a6accd">        W1</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> W2 </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> self</span><span style="color:#89ddff">.</span><span style="color:#f07178">params</span><span style="color:#89ddff">[</span><span style="color:#89ddff">'</span><span style="color:#c3e88d">W1</span><span style="color:#89ddff">'</span><span style="color:#89ddff">],</span><span style="color:#a6accd"> self</span><span style="color:#89ddff">.</span><span style="color:#f07178">params</span><span style="color:#89ddff">[</span><span style="color:#89ddff">'</span><span style="color:#c3e88d">W2</span><span style="color:#89ddff">'</span><span style="color:#89ddff">]</span></span>
<span class="line"><span style="color:#a6accd">        b1</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> b2 </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> self</span><span style="color:#89ddff">.</span><span style="color:#f07178">params</span><span style="color:#89ddff">[</span><span style="color:#89ddff">'</span><span style="color:#c3e88d">b1</span><span style="color:#89ddff">'</span><span style="color:#89ddff">],</span><span style="color:#a6accd"> self</span><span style="color:#89ddff">.</span><span style="color:#f07178">params</span><span style="color:#89ddff">[</span><span style="color:#89ddff">'</span><span style="color:#c3e88d">b2</span><span style="color:#89ddff">'</span><span style="color:#89ddff">]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">        a1 </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> np</span><span style="color:#89ddff">.</span><span style="color:#82aaff">dot</span><span style="color:#89ddff">(</span><span style="color:#82aaff">x</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> W1</span><span style="color:#89ddff">)</span><span style="color:#a6accd"> </span><span style="color:#89ddff">+</span><span style="color:#a6accd"> b1</span></span>
<span class="line"><span style="color:#a6accd">        z1 </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#82aaff">sigmoid</span><span style="color:#89ddff">(</span><span style="color:#82aaff">a1</span><span style="color:#89ddff">)</span></span>
<span class="line"><span style="color:#a6accd">        a2 </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> np</span><span style="color:#89ddff">.</span><span style="color:#82aaff">dot</span><span style="color:#89ddff">(</span><span style="color:#82aaff">z1</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> W2</span><span style="color:#89ddff">)</span><span style="color:#a6accd"> </span><span style="color:#89ddff">+</span><span style="color:#a6accd"> b2</span></span>
<span class="line"><span style="color:#a6accd">        y </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#82aaff">softmax</span><span style="color:#89ddff">(</span><span style="color:#82aaff">a2</span><span style="color:#89ddff">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">        </span><span style="color:#89ddff;font-style:italic">return</span><span style="color:#a6accd"> y</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#676e95;font-style:italic"># 计算损失函数的值</span></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#676e95;font-style:italic"># x 是输入数据，t 是监督数据</span></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#c792ea">def</span><span style="color:#a6accd"> </span><span style="color:#82aaff">loss</span><span style="color:#89ddff">(</span><span style="color:#f07178;font-style:italic">self</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> </span><span style="color:#a6accd;font-style:italic">x</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> </span><span style="color:#a6accd;font-style:italic">t</span><span style="color:#89ddff">):</span></span>
<span class="line"><span style="color:#a6accd">        y </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> self</span><span style="color:#89ddff">.</span><span style="color:#82aaff">predict</span><span style="color:#89ddff">(</span><span style="color:#82aaff">x</span><span style="color:#89ddff">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">        </span><span style="color:#89ddff;font-style:italic">return</span><span style="color:#a6accd"> </span><span style="color:#82aaff">cross_entropy_error</span><span style="color:#89ddff">(</span><span style="color:#82aaff">y</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> t</span><span style="color:#89ddff">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#676e95;font-style:italic"># 计算识别精度</span></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#676e95;font-style:italic"># x 是输入数据，t 是监督数据</span></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#c792ea">def</span><span style="color:#a6accd"> </span><span style="color:#82aaff">accuracy</span><span style="color:#89ddff">(</span><span style="color:#f07178;font-style:italic">self</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> </span><span style="color:#a6accd;font-style:italic">x</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> </span><span style="color:#a6accd;font-style:italic">t</span><span style="color:#89ddff">):</span></span>
<span class="line"><span style="color:#a6accd">        y </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> self</span><span style="color:#89ddff">.</span><span style="color:#82aaff">predict</span><span style="color:#89ddff">(</span><span style="color:#82aaff">x</span><span style="color:#89ddff">)</span><span style="color:#a6accd">  </span><span style="color:#676e95;font-style:italic"># 获得输出</span></span>
<span class="line"><span style="color:#a6accd">        y </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> np</span><span style="color:#89ddff">.</span><span style="color:#82aaff">argmax</span><span style="color:#89ddff">(</span><span style="color:#82aaff">y</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> </span><span style="color:#a6accd;font-style:italic">axis</span><span style="color:#89ddff">=</span><span style="color:#f78c6c">1</span><span style="color:#89ddff">)</span><span style="color:#a6accd">  </span><span style="color:#676e95;font-style:italic"># 取得输出最大值对应索引（标签）</span></span>
<span class="line"><span style="color:#a6accd">        t </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> np</span><span style="color:#89ddff">.</span><span style="color:#82aaff">argmax</span><span style="color:#89ddff">(</span><span style="color:#82aaff">t</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> </span><span style="color:#a6accd;font-style:italic">axis</span><span style="color:#89ddff">=</span><span style="color:#f78c6c">1</span><span style="color:#89ddff">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">        accuracy </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> np</span><span style="color:#89ddff">.</span><span style="color:#82aaff">sum</span><span style="color:#89ddff">(</span><span style="color:#82aaff">y </span><span style="color:#89ddff">==</span><span style="color:#82aaff"> t</span><span style="color:#89ddff">)</span><span style="color:#a6accd"> </span><span style="color:#89ddff">/</span><span style="color:#a6accd"> </span><span style="color:#ffcb6b">float</span><span style="color:#89ddff">(</span><span style="color:#82aaff">x</span><span style="color:#89ddff">.</span><span style="color:#f07178">shape</span><span style="color:#89ddff">[</span><span style="color:#f78c6c">0</span><span style="color:#89ddff">])</span></span>
<span class="line"><span style="color:#a6accd">        </span><span style="color:#89ddff;font-style:italic">return</span><span style="color:#a6accd"> accuracy</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#676e95;font-style:italic"># 求梯度</span></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#676e95;font-style:italic"># x 是输入数据，t 是监督数据</span></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#c792ea">def</span><span style="color:#a6accd"> </span><span style="color:#82aaff">numerical_gradient</span><span style="color:#89ddff">(</span><span style="color:#f07178;font-style:italic">self</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> </span><span style="color:#a6accd;font-style:italic">x</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> </span><span style="color:#a6accd;font-style:italic">t</span><span style="color:#89ddff">):</span></span>
<span class="line"><span style="color:#a6accd">        loss_W </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#c792ea">lambda</span><span style="color:#a6accd"> </span><span style="color:#a6accd;font-style:italic">W</span><span style="color:#89ddff">:</span><span style="color:#a6accd"> self</span><span style="color:#89ddff">.</span><span style="color:#82aaff">loss</span><span style="color:#89ddff">(</span><span style="color:#82aaff">x</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> t</span><span style="color:#89ddff">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">        </span><span style="color:#676e95;font-style:italic"># 对每层的参数求梯度</span></span>
<span class="line"><span style="color:#a6accd">        grads </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#89ddff">{}</span></span>
<span class="line"><span style="color:#a6accd">        grads</span><span style="color:#89ddff">[</span><span style="color:#89ddff">'</span><span style="color:#c3e88d">W1</span><span style="color:#89ddff">'</span><span style="color:#89ddff">]</span><span style="color:#a6accd"> </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#82aaff">numerical_gradient</span><span style="color:#89ddff">(</span><span style="color:#82aaff">loss_W</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> </span><span style="color:#a6accd">self</span><span style="color:#89ddff">.</span><span style="color:#f07178">params</span><span style="color:#89ddff">[</span><span style="color:#89ddff">'</span><span style="color:#c3e88d">W1</span><span style="color:#89ddff">'</span><span style="color:#89ddff">])</span></span>
<span class="line"><span style="color:#a6accd">        grads</span><span style="color:#89ddff">[</span><span style="color:#89ddff">'</span><span style="color:#c3e88d">b1</span><span style="color:#89ddff">'</span><span style="color:#89ddff">]</span><span style="color:#a6accd"> </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#82aaff">numerical_gradient</span><span style="color:#89ddff">(</span><span style="color:#82aaff">loss_W</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> </span><span style="color:#a6accd">self</span><span style="color:#89ddff">.</span><span style="color:#f07178">params</span><span style="color:#89ddff">[</span><span style="color:#89ddff">'</span><span style="color:#c3e88d">b1</span><span style="color:#89ddff">'</span><span style="color:#89ddff">])</span></span>
<span class="line"><span style="color:#a6accd">        grads</span><span style="color:#89ddff">[</span><span style="color:#89ddff">'</span><span style="color:#c3e88d">W2</span><span style="color:#89ddff">'</span><span style="color:#89ddff">]</span><span style="color:#a6accd"> </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#82aaff">numerical_gradient</span><span style="color:#89ddff">(</span><span style="color:#82aaff">loss_W</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> </span><span style="color:#a6accd">self</span><span style="color:#89ddff">.</span><span style="color:#f07178">params</span><span style="color:#89ddff">[</span><span style="color:#89ddff">'</span><span style="color:#c3e88d">W2</span><span style="color:#89ddff">'</span><span style="color:#89ddff">])</span></span>
<span class="line"><span style="color:#a6accd">        grads</span><span style="color:#89ddff">[</span><span style="color:#89ddff">'</span><span style="color:#c3e88d">b2</span><span style="color:#89ddff">'</span><span style="color:#89ddff">]</span><span style="color:#a6accd"> </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#82aaff">numerical_gradient</span><span style="color:#89ddff">(</span><span style="color:#82aaff">loss_W</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> </span><span style="color:#a6accd">self</span><span style="color:#89ddff">.</span><span style="color:#f07178">params</span><span style="color:#89ddff">[</span><span style="color:#89ddff">'</span><span style="color:#c3e88d">b2</span><span style="color:#89ddff">'</span><span style="color:#89ddff">])</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">        </span><span style="color:#89ddff;font-style:italic">return</span><span style="color:#a6accd"> grads</span></span>
<span class="line"></span></code></pre></div><p>（<code>weight_init_std</code> 似乎是为了解决激活后分布集中在0和1附近？）</p><p>之前也提到过，根据数据集和要识别的目标，<code>input_size</code> 就是<code>784</code>，<code>output_size</code> 是<code>10</code>。这里的隐藏层神经元个数设置为一个合理的值就行。</p><h3 id="mini-batch-的实现" tabindex="-1">mini-batch 的实现 <a aria-current="page" href="/posts/learning/deep-learning-from-scratch-learning-of-neural-network#mini-batch-的实现" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>实现过程如下：</p><div class="language-python"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#89ddff;font-style:italic">import</span><span style="color:#a6accd"> sys</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> os</span></span>
<span class="line"><span style="color:#89ddff;font-style:italic">import</span><span style="color:#a6accd"> numpy </span><span style="color:#89ddff;font-style:italic">as</span><span style="color:#a6accd"> np</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">sys</span><span style="color:#89ddff">.</span><span style="color:#f07178">path</span><span style="color:#89ddff">.</span><span style="color:#82aaff">append</span><span style="color:#89ddff">(</span><span style="color:#82aaff">os</span><span style="color:#89ddff">.</span><span style="color:#f07178">curdir</span><span style="color:#89ddff">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#89ddff;font-style:italic">from</span><span style="color:#a6accd"> ch04</span><span style="color:#89ddff">.</span><span style="color:#a6accd">two_layer_net </span><span style="color:#89ddff;font-style:italic">import</span><span style="color:#a6accd"> TwoLayerNet</span></span>
<span class="line"><span style="color:#89ddff;font-style:italic">from</span><span style="color:#a6accd"> dataset</span><span style="color:#89ddff">.</span><span style="color:#a6accd">mnist </span><span style="color:#89ddff;font-style:italic">import</span><span style="color:#a6accd"> load_mnist</span></span>
<span class="line"></span>
<span class="line"><span style="color:#82aaff">print</span><span style="color:#89ddff">(</span><span style="color:#89ddff">'</span><span style="color:#c3e88d">Load mnist dataset...</span><span style="color:#89ddff">'</span><span style="color:#89ddff">)</span></span>
<span class="line"><span style="color:#89ddff">(</span><span style="color:#a6accd">x_train</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> t_train</span><span style="color:#89ddff">),</span><span style="color:#a6accd"> </span><span style="color:#89ddff">(</span><span style="color:#a6accd">x_test</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> t_test</span><span style="color:#89ddff">)</span><span style="color:#a6accd"> </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#82aaff">load_mnist</span><span style="color:#89ddff">(</span><span style="color:#a6accd;font-style:italic">normalize</span><span style="color:#89ddff">=True,</span></span>
<span class="line"><span style="color:#82aaff">                                                  </span><span style="color:#a6accd;font-style:italic">one_hot_label</span><span style="color:#89ddff">=True)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">train_loss_list </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#89ddff">[]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#676e95;font-style:italic"># 超参数</span></span>
<span class="line"><span style="color:#a6accd">iters_num </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#f78c6c">10000</span><span style="color:#a6accd">  </span><span style="color:#676e95;font-style:italic"># 梯度法更新次数</span></span>
<span class="line"><span style="color:#a6accd">train_size </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> x_train</span><span style="color:#89ddff">.</span><span style="color:#f07178">shape</span><span style="color:#89ddff">[</span><span style="color:#f78c6c">0</span><span style="color:#89ddff">]</span><span style="color:#a6accd">  </span><span style="color:#676e95;font-style:italic"># 训练集大小</span></span>
<span class="line"><span style="color:#a6accd">batch_size </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#f78c6c">100</span><span style="color:#a6accd">  </span><span style="color:#676e95;font-style:italic"># batch 大小</span></span>
<span class="line"><span style="color:#a6accd">learning_rate </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#f78c6c">0.1</span><span style="color:#a6accd">  </span><span style="color:#676e95;font-style:italic"># 学习率</span></span>
<span class="line"></span>
<span class="line"><span style="color:#82aaff">print</span><span style="color:#89ddff">(</span><span style="color:#89ddff">'</span><span style="color:#c3e88d">Initialize network...</span><span style="color:#89ddff">'</span><span style="color:#89ddff">)</span></span>
<span class="line"><span style="color:#a6accd">network </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#82aaff">TwoLayerNet</span><span style="color:#89ddff">(</span><span style="color:#a6accd;font-style:italic">input_size</span><span style="color:#89ddff">=</span><span style="color:#f78c6c">784</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> </span><span style="color:#a6accd;font-style:italic">hidden_size</span><span style="color:#89ddff">=</span><span style="color:#f78c6c">50</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> </span><span style="color:#a6accd;font-style:italic">output_size</span><span style="color:#89ddff">=</span><span style="color:#f78c6c">10</span><span style="color:#89ddff">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#89ddff;font-style:italic">for</span><span style="color:#a6accd"> i </span><span style="color:#89ddff;font-style:italic">in</span><span style="color:#a6accd"> </span><span style="color:#82aaff">range</span><span style="color:#89ddff">(</span><span style="color:#82aaff">iters_num</span><span style="color:#89ddff">):</span></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#676e95;font-style:italic"># 从训练数据中随机获取 mini-batch</span></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#82aaff">print</span><span style="color:#89ddff">(</span><span style="color:#82aaff">i</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> </span><span style="color:#89ddff">'</span><span style="color:#c3e88d">: choose mini-batch...</span><span style="color:#89ddff">'</span><span style="color:#89ddff">)</span></span>
<span class="line"><span style="color:#a6accd">    batch_mask </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> np</span><span style="color:#89ddff">.</span><span style="color:#f07178">random</span><span style="color:#89ddff">.</span><span style="color:#82aaff">choice</span><span style="color:#89ddff">(</span><span style="color:#82aaff">train_size</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> batch_size</span><span style="color:#89ddff">)</span></span>
<span class="line"><span style="color:#a6accd">    x_batch </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> x_train</span><span style="color:#89ddff">[</span><span style="color:#a6accd">batch_mask</span><span style="color:#89ddff">]</span></span>
<span class="line"><span style="color:#a6accd">    t_batch </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> t_train</span><span style="color:#89ddff">[</span><span style="color:#a6accd">batch_mask</span><span style="color:#89ddff">]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#676e95;font-style:italic"># 计算梯度</span></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#82aaff">print</span><span style="color:#89ddff">(</span><span style="color:#82aaff">i</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> </span><span style="color:#89ddff">'</span><span style="color:#c3e88d">: calculate grads...</span><span style="color:#89ddff">'</span><span style="color:#89ddff">)</span></span>
<span class="line"><span style="color:#a6accd">    grad </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> network</span><span style="color:#89ddff">.</span><span style="color:#82aaff">numerical_gradient</span><span style="color:#89ddff">(</span><span style="color:#82aaff">x_batch</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> t_batch</span><span style="color:#89ddff">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#676e95;font-style:italic"># 更新参数</span></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#82aaff">print</span><span style="color:#89ddff">(</span><span style="color:#82aaff">i</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> </span><span style="color:#89ddff">'</span><span style="color:#c3e88d">: update params...</span><span style="color:#89ddff">'</span><span style="color:#89ddff">)</span></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#89ddff;font-style:italic">for</span><span style="color:#a6accd"> key </span><span style="color:#89ddff;font-style:italic">in</span><span style="color:#a6accd"> </span><span style="color:#89ddff">(</span><span style="color:#89ddff">'</span><span style="color:#c3e88d">W1</span><span style="color:#89ddff">'</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> </span><span style="color:#89ddff">'</span><span style="color:#c3e88d">b1</span><span style="color:#89ddff">'</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> </span><span style="color:#89ddff">'</span><span style="color:#c3e88d">W2</span><span style="color:#89ddff">'</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> </span><span style="color:#89ddff">'</span><span style="color:#c3e88d">b2</span><span style="color:#89ddff">'</span><span style="color:#89ddff">):</span></span>
<span class="line"><span style="color:#a6accd">        network</span><span style="color:#89ddff">.</span><span style="color:#f07178">params</span><span style="color:#89ddff">[</span><span style="color:#f07178">key</span><span style="color:#89ddff">]</span><span style="color:#a6accd"> </span><span style="color:#89ddff">-=</span><span style="color:#a6accd"> learning_rate </span><span style="color:#89ddff">*</span><span style="color:#a6accd"> grad</span><span style="color:#89ddff">[</span><span style="color:#a6accd">key</span><span style="color:#89ddff">]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#676e95;font-style:italic"># 记录学习过程</span></span>
<span class="line"><span style="color:#a6accd">    loss </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> network</span><span style="color:#89ddff">.</span><span style="color:#82aaff">loss</span><span style="color:#89ddff">(</span><span style="color:#82aaff">x_batch</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> t_batch</span><span style="color:#89ddff">)</span></span>
<span class="line"><span style="color:#a6accd">    train_loss_list</span><span style="color:#89ddff">.</span><span style="color:#82aaff">append</span><span style="color:#89ddff">(</span><span style="color:#82aaff">loss</span><span style="color:#89ddff">)</span></span>
<span class="line"></span></code></pre></div><p>上面的学习过程应该算很清楚了，共更新10000次参数，会记录每一次训练后的损失函数值。</p><h3 id="基于测试数据的评价" tabindex="-1">基于测试数据的评价 <a aria-current="page" href="/posts/learning/deep-learning-from-scratch-learning-of-neural-network#基于测试数据的评价" class="router-link-active router-link-exact-active header-anchor" aria-hidden="true"><!--[-->#<!--]--></a></h3><p>上面的学习过程得到的损失函数值其实是对训练数据的某个 mini-batch 的损失函数值，这个值减小说明学习过程确实在正常进行，但是不能保证神经网络能正确识别训练集以外的数据。要评价神经网络的泛化能力，就要使用不在训练集中的数据。</p><p>这里就涉及了 <strong>epoch</strong>（之前做比赛看队友的代码里出现过这个东西，不过当时不知道具体表示什么意思），一个 epoch 表示学习中所有训练数据均被使用过一次时的更新次数。比如对于10000笔训练数据，如果 mini-batch 的大小是100，那么重复梯度下降100次，所有的训练数据就都被使用过一次，此时100次就是一个 epoch。（一般的做法是把训练数据打乱，根据指定的批大小生成 mini-batch，遍历所有 mini-batch 完成一个 epoch。像前面直接每次随机选择不能保证每个数据都被用到。）</p><p>在学习过程中需要定期对训练数据和测试数据记录识别精度，这里每经过一个 epoch 就记录一次：</p><div class="language-python"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#89ddff;font-style:italic">import</span><span style="color:#a6accd"> sys</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> os</span></span>
<span class="line"><span style="color:#89ddff;font-style:italic">import</span><span style="color:#a6accd"> numpy </span><span style="color:#89ddff;font-style:italic">as</span><span style="color:#a6accd"> np</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">sys</span><span style="color:#89ddff">.</span><span style="color:#f07178">path</span><span style="color:#89ddff">.</span><span style="color:#82aaff">append</span><span style="color:#89ddff">(</span><span style="color:#82aaff">os</span><span style="color:#89ddff">.</span><span style="color:#f07178">curdir</span><span style="color:#89ddff">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#89ddff;font-style:italic">from</span><span style="color:#a6accd"> ch04</span><span style="color:#89ddff">.</span><span style="color:#a6accd">two_layer_net </span><span style="color:#89ddff;font-style:italic">import</span><span style="color:#a6accd"> TwoLayerNet</span></span>
<span class="line"><span style="color:#89ddff;font-style:italic">from</span><span style="color:#a6accd"> dataset</span><span style="color:#89ddff">.</span><span style="color:#a6accd">mnist </span><span style="color:#89ddff;font-style:italic">import</span><span style="color:#a6accd"> load_mnist</span></span>
<span class="line"></span>
<span class="line"><span style="color:#82aaff">print</span><span style="color:#89ddff">(</span><span style="color:#89ddff">'</span><span style="color:#c3e88d">Load mnist dataset...</span><span style="color:#89ddff">'</span><span style="color:#89ddff">)</span></span>
<span class="line"><span style="color:#89ddff">(</span><span style="color:#a6accd">x_train</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> t_train</span><span style="color:#89ddff">),</span><span style="color:#a6accd"> </span><span style="color:#89ddff">(</span><span style="color:#a6accd">x_test</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> t_test</span><span style="color:#89ddff">)</span><span style="color:#a6accd"> </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#82aaff">load_mnist</span><span style="color:#89ddff">(</span><span style="color:#a6accd;font-style:italic">normalize</span><span style="color:#89ddff">=True,</span></span>
<span class="line"><span style="color:#82aaff">                                                  </span><span style="color:#a6accd;font-style:italic">one_hot_label</span><span style="color:#89ddff">=True)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#82aaff">print</span><span style="color:#89ddff">(</span><span style="color:#89ddff">'</span><span style="color:#c3e88d">Initialize network...</span><span style="color:#89ddff">'</span><span style="color:#89ddff">)</span></span>
<span class="line"><span style="color:#a6accd">network </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#82aaff">TwoLayerNet</span><span style="color:#89ddff">(</span><span style="color:#a6accd;font-style:italic">input_size</span><span style="color:#89ddff">=</span><span style="color:#f78c6c">784</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> </span><span style="color:#a6accd;font-style:italic">hidden_size</span><span style="color:#89ddff">=</span><span style="color:#f78c6c">50</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> </span><span style="color:#a6accd;font-style:italic">output_size</span><span style="color:#89ddff">=</span><span style="color:#f78c6c">10</span><span style="color:#89ddff">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#676e95;font-style:italic"># 超参数</span></span>
<span class="line"><span style="color:#a6accd">iters_num </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#f78c6c">10000</span><span style="color:#a6accd">  </span><span style="color:#676e95;font-style:italic"># 梯度法更新次数</span></span>
<span class="line"><span style="color:#a6accd">train_size </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> x_train</span><span style="color:#89ddff">.</span><span style="color:#f07178">shape</span><span style="color:#89ddff">[</span><span style="color:#f78c6c">0</span><span style="color:#89ddff">]</span><span style="color:#a6accd">  </span><span style="color:#676e95;font-style:italic"># 训练集大小</span></span>
<span class="line"><span style="color:#a6accd">batch_size </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#f78c6c">100</span><span style="color:#a6accd">  </span><span style="color:#676e95;font-style:italic"># batch 大小</span></span>
<span class="line"><span style="color:#a6accd">learning_rate </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#f78c6c">0.1</span><span style="color:#a6accd">  </span><span style="color:#676e95;font-style:italic"># 学习率</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">train_loss_list </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#89ddff">[]</span></span>
<span class="line"><span style="color:#a6accd">train_acc_list </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#89ddff">[]</span></span>
<span class="line"><span style="color:#a6accd">test_acc_list </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#89ddff">[]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#676e95;font-style:italic"># 平均每个 epoch 的重复次数</span></span>
<span class="line"><span style="color:#a6accd">iter_per_epoch </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> </span><span style="color:#82aaff">max</span><span style="color:#89ddff">(</span><span style="color:#82aaff">train_size </span><span style="color:#89ddff">/</span><span style="color:#82aaff"> batch_size</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> </span><span style="color:#f78c6c">1</span><span style="color:#89ddff">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#89ddff;font-style:italic">for</span><span style="color:#a6accd"> i </span><span style="color:#89ddff;font-style:italic">in</span><span style="color:#a6accd"> </span><span style="color:#82aaff">range</span><span style="color:#89ddff">(</span><span style="color:#82aaff">iters_num</span><span style="color:#89ddff">):</span></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#676e95;font-style:italic"># 获取 mini-batch</span></span>
<span class="line"><span style="color:#a6accd">    batch_mask </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> np</span><span style="color:#89ddff">.</span><span style="color:#f07178">random</span><span style="color:#89ddff">.</span><span style="color:#82aaff">choice</span><span style="color:#89ddff">(</span><span style="color:#82aaff">train_size</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> batch_size</span><span style="color:#89ddff">)</span></span>
<span class="line"><span style="color:#a6accd">    x_batch </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> x_train</span><span style="color:#89ddff">[</span><span style="color:#a6accd">batch_mask</span><span style="color:#89ddff">]</span></span>
<span class="line"><span style="color:#a6accd">    t_batch </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> t_train</span><span style="color:#89ddff">[</span><span style="color:#a6accd">batch_mask</span><span style="color:#89ddff">]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#676e95;font-style:italic"># 计算梯度</span></span>
<span class="line"><span style="color:#a6accd">    grad </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> network</span><span style="color:#89ddff">.</span><span style="color:#82aaff">numerical_gradient</span><span style="color:#89ddff">(</span><span style="color:#82aaff">x_batch</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> t_batch</span><span style="color:#89ddff">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#676e95;font-style:italic"># 更新参数</span></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#89ddff;font-style:italic">for</span><span style="color:#a6accd"> key </span><span style="color:#89ddff;font-style:italic">in</span><span style="color:#a6accd"> </span><span style="color:#89ddff">(</span><span style="color:#89ddff">'</span><span style="color:#c3e88d">W1</span><span style="color:#89ddff">'</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> </span><span style="color:#89ddff">'</span><span style="color:#c3e88d">b1</span><span style="color:#89ddff">'</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> </span><span style="color:#89ddff">'</span><span style="color:#c3e88d">W2</span><span style="color:#89ddff">'</span><span style="color:#89ddff">,</span><span style="color:#a6accd"> </span><span style="color:#89ddff">'</span><span style="color:#c3e88d">b2</span><span style="color:#89ddff">'</span><span style="color:#89ddff">):</span></span>
<span class="line"><span style="color:#a6accd">        network</span><span style="color:#89ddff">.</span><span style="color:#f07178">params</span><span style="color:#89ddff">[</span><span style="color:#f07178">key</span><span style="color:#89ddff">]</span><span style="color:#a6accd"> </span><span style="color:#89ddff">-=</span><span style="color:#a6accd"> learning_rate </span><span style="color:#89ddff">*</span><span style="color:#a6accd"> grad</span><span style="color:#89ddff">[</span><span style="color:#a6accd">key</span><span style="color:#89ddff">]</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#676e95;font-style:italic"># 记录学习过程</span></span>
<span class="line"><span style="color:#a6accd">    loss </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> network</span><span style="color:#89ddff">.</span><span style="color:#82aaff">loss</span><span style="color:#89ddff">(</span><span style="color:#82aaff">x_batch</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> t_batch</span><span style="color:#89ddff">)</span></span>
<span class="line"><span style="color:#a6accd">    train_loss_list</span><span style="color:#89ddff">.</span><span style="color:#82aaff">append</span><span style="color:#89ddff">(</span><span style="color:#82aaff">loss</span><span style="color:#89ddff">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#676e95;font-style:italic"># 每个 epoch 完成后计算识别精度</span></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#89ddff;font-style:italic">if</span><span style="color:#a6accd"> i </span><span style="color:#89ddff">%</span><span style="color:#a6accd"> iter_per_epoch </span><span style="color:#89ddff">==</span><span style="color:#a6accd"> </span><span style="color:#f78c6c">0</span><span style="color:#89ddff">:</span></span>
<span class="line"><span style="color:#a6accd">        train_acc </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> network</span><span style="color:#89ddff">.</span><span style="color:#82aaff">accuracy</span><span style="color:#89ddff">(</span><span style="color:#82aaff">x_train</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> t_train</span><span style="color:#89ddff">)</span></span>
<span class="line"><span style="color:#a6accd">        test_acc </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> network</span><span style="color:#89ddff">.</span><span style="color:#82aaff">accuracy</span><span style="color:#89ddff">(</span><span style="color:#82aaff">x_test</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> t_test</span><span style="color:#89ddff">)</span></span>
<span class="line"><span style="color:#a6accd">        train_acc_list</span><span style="color:#89ddff">.</span><span style="color:#82aaff">append</span><span style="color:#89ddff">(</span><span style="color:#82aaff">train_acc</span><span style="color:#89ddff">)</span></span>
<span class="line"><span style="color:#a6accd">        test_acc_list</span><span style="color:#89ddff">.</span><span style="color:#82aaff">append</span><span style="color:#89ddff">(</span><span style="color:#82aaff">test_acc</span><span style="color:#89ddff">)</span></span>
<span class="line"><span style="color:#a6accd">        </span><span style="color:#82aaff">print</span><span style="color:#89ddff">(</span><span style="color:#89ddff">'</span><span style="color:#c3e88d">Train acc, test acc | </span><span style="color:#89ddff">'</span><span style="color:#82aaff"> </span><span style="color:#89ddff">+</span><span style="color:#82aaff"> </span><span style="color:#ffcb6b">str</span><span style="color:#89ddff">(</span><span style="color:#82aaff">train_acc</span><span style="color:#89ddff">)</span><span style="color:#82aaff"> </span><span style="color:#89ddff">+</span><span style="color:#82aaff"> </span><span style="color:#89ddff">'</span><span style="color:#c3e88d">,</span><span style="color:#89ddff">'</span><span style="color:#82aaff"> </span><span style="color:#89ddff">+</span><span style="color:#82aaff"> </span><span style="color:#ffcb6b">str</span><span style="color:#89ddff">(</span><span style="color:#82aaff">test_acc</span><span style="color:#89ddff">))</span></span>
<span class="line"></span></code></pre></div><p>画出识别精度关于 epoch 的曲线：</p><p><img src="https://s2.loli.net/2022/10/15/jE2J9w5pGhmbWfX.png" alt="识别精度"></p><p>随着学习进行，使用训练数据和测试数据评价的识别精度都在提高，两者几乎没有差距，没有发生过拟合。</p><p><s>这一部分就到这里……</s></p><p>之前写过的 softmax 函数似乎要换成这样的实现，可能和多维数组有关（具体到这里就是二维的吧，因为数据都是 mini-batch 了，max 和 sum 都需要沿着第2维），不过是不是我还得想想……</p><div class="language-python"><span class="copy"></span><pre class="shiki material-theme-palenight" tabindex="0"><code><span class="line"><span style="color:#c792ea">def</span><span style="color:#a6accd"> </span><span style="color:#82aaff">softmax</span><span style="color:#89ddff">(</span><span style="color:#a6accd;font-style:italic">x</span><span style="color:#89ddff">):</span></span>
<span class="line"><span style="color:#a6accd">    x </span><span style="color:#89ddff">=</span><span style="color:#a6accd"> x </span><span style="color:#89ddff">-</span><span style="color:#a6accd"> np</span><span style="color:#89ddff">.</span><span style="color:#82aaff">max</span><span style="color:#89ddff">(</span><span style="color:#82aaff">x</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> </span><span style="color:#a6accd;font-style:italic">axis</span><span style="color:#89ddff">=-</span><span style="color:#f78c6c">1</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> </span><span style="color:#a6accd;font-style:italic">keepdims</span><span style="color:#89ddff">=True)</span><span style="color:#a6accd">  </span><span style="color:#676e95;font-style:italic"># 防止 exp() 溢出</span></span>
<span class="line"><span style="color:#a6accd">    </span><span style="color:#89ddff;font-style:italic">return</span><span style="color:#a6accd"> np</span><span style="color:#89ddff">.</span><span style="color:#82aaff">exp</span><span style="color:#89ddff">(</span><span style="color:#82aaff">x</span><span style="color:#89ddff">)</span><span style="color:#a6accd"> </span><span style="color:#89ddff">/</span><span style="color:#a6accd"> np</span><span style="color:#89ddff">.</span><span style="color:#82aaff">sum</span><span style="color:#89ddff">(</span><span style="color:#82aaff">np</span><span style="color:#89ddff">.</span><span style="color:#82aaff">exp</span><span style="color:#89ddff">(</span><span style="color:#82aaff">x</span><span style="color:#89ddff">),</span><span style="color:#82aaff"> </span><span style="color:#a6accd;font-style:italic">axis</span><span style="color:#89ddff">=-</span><span style="color:#f78c6c">1</span><span style="color:#89ddff">,</span><span style="color:#82aaff"> </span><span style="color:#a6accd;font-style:italic">keepdims</span><span style="color:#89ddff">=True)</span></span>
<span class="line"></span></code></pre></div><!--]--><!--[--><!--]--><!--]--><div text="center"><!----></div><!----></article><!--]--><!--[--><!--[--><!--[--><!--v-if--><ul class="post-copyright" m="y-4"><li class="post-copyright-author"><strong>本文作者：</strong><span>零歌</span></li><li class="post-copyright-link"><strong>本文链接：</strong><a href="https://afool.top/posts/learning/deep-learning-from-scratch-learning-of-neural-network">https://afool.top/posts/learning/deep-learning-from-scratch-learning-of-neural-network</a></li><li class="post-copyright-license"><strong>版权声明：</strong><span>本博客所有文章除特别声明外，均默认采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/deed.zh" target="_blank" rel="noopener" title="CC BY-NC-SA 4.0 ">CC BY-NC-SA</a> 许可协议。</span></li></ul><!--]--><!--]--><!--]--></div><!--]--><!----></div><!--[--><!--]--><!--[--><div class="post-nav"><div class="post-nav-item"><a href="/posts/learning/deep-learning-from-scratch-error-back-propagation" class="post-nav-prev" title="深度学习入门：误差反向传播法"><div class="icon" i-ri-arrow-left-s-line=""></div><span class="title truncate" text="sm">深度学习入门：误差反向传播法</span></a></div><div class="post-nav-item"><a href="/posts/learning/deep-learning-from-scratch-neural-network" class="post-nav-next" title="深度学习入门：神经网络"><span class="title truncate" text="sm">深度学习入门：神经网络</span><div class="icon" i-ri-arrow-right-s-line=""></div></a></div></div><!--]--><!--[--><!--]--><!--[--><div class="yun-card comment sm:p-6 lg:px-12 xl:px-16" w="full" p="4"><!----><!----><!--[--><!----><!--]--><!----></div><!--]--><!--[--><!--]--><footer class="va-footer p-4 text-$va-c-text-light" text="center sm"><!----><div class="copyright flex justify-center items-center gap-2" p="1"><span>©<!--[--> 2020 -<!--]--> 2023</span><a class="animate-pulse inline-flex" href="https://sponsors.yunyoujun.cn" target="_blank" title="Sponsor YunYouJun"><div class="i-ri-cloud-line"></div></a><span>零歌</span></div><div class="powered" m="2"><span>由 <a href="https://github.com/YunYouJun/valaxy" target="_blank" rel="noopener">Valaxy</a> v0.14.25 驱动</span> | <span>主题 - <a href="https://github.com/YunYouJun/valaxy/tree/main/packages/valaxy-theme-yun" title="valaxy-theme-yun" target="_blank">Yun</a> v0.14.25</span></div><!--[--><!--]--></footer><!--[--><!--]--></div><!--]--><!--[--><!--[--><button class="xl:hidden toc-btn shadow fixed yun-icon-btn z-350" opacity="75" right="2" bottom="19"><div i-ri-file-list-line=""></div></button><!----><!--  --><aside class="va-card aside" m="l-4" text="center"><div class="aside-container" flex="~ col" overflow="auto"><h2 m="t-6 b-2" font="serif black">文章目录</h2><div style="display:none" data-v-3ec1ec4d=""><div class="content" data-v-3ec1ec4d=""><div class="outline-title" data-v-3ec1ec4d="">On this page</div><div class="outline-marker" data-v-3ec1ec4d=""></div><nav aria-labelledby="doc-outline-aria-label" data-v-3ec1ec4d=""><span id="doc-outline-aria-label" class="visually-hidden" data-v-3ec1ec4d="">Table of Contents for current page</span><ul class="root va-toc relative z-1" data-v-3ec1ec4d="" data-v-00264c1d=""><!--[--><!--]--></ul></nav></div></div><div class="flex-grow"></div><div class="custom-container"><!--[--><!--]--></div></div></aside><!--]--><!--]--></div></main><a href="#" class="back-to-top yun-icon-btn"><div w="8" h="8" i-ri-arrow-up-s-line=""></div><svg class="progress-circle-container" viewBox="0 0 100 100"><circle stroke-dasharray="301.59289474462014 301.59289474462014" stroke-dashoffset="301.59289474462014" class="progress-circle" cx="50" cy="50" r="48" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round"></circle></svg></a><!--]--><!--]--></div><script>window.__INITIAL_STATE__='{"pinia":{"app":{"isSidebarOpen":false,"isRightSidebarOpen":false},"site":{}}}'</script><script type="application/ld+json" id="schema-org-graph" data-h-3437552="">{
  "@context": "https://schema.org",
  "@graph": [
    {
      "@id": "https://afool.top/#identity",
      "@type": "Person",
      "name": "零歌",
      "url": "https://afool.top/",
      "image": {
        "@id": "https://afool.top/#/schema/image/2177a58"
      },
      "sameAs": [
        "https://github.com/charliedu2000",
        "https://space.bilibili.com/22660607",
        "mailto:charliedu2000@hotmail.com"
      ]
    },
    {
      "@id": "https://afool.top/#website",
      "@type": "WebSite",
      "dateModified": "2022-10-07T23:18:35+00:00",
      "datePublished": "2022-10-07T23:18:35+00:00",
      "inLanguage": "zh-CN",
      "name": "深度学习入门：神经网络的学习",
      "url": "https://afool.top/",
      "publisher": {
        "@id": "https://afool.top/#identity"
      }
    },
    {
      "@id": "https://afool.top/posts/learning/deep-learning-from-scratch-learning-of-neural-network/#webpage",
      "@type": "WebPage",
      "description": "敬请见证！（bushi",
      "name": "深度学习入门：神经网络的学习",
      "url": "https://afool.top/posts/learning/deep-learning-from-scratch-learning-of-neural-network",
      "about": {
        "@id": "https://afool.top/#identity"
      },
      "isPartOf": {
        "@id": "https://afool.top/#website"
      },
      "potentialAction": [
        {
          "@type": "ReadAction",
          "target": [
            "https://afool.top/posts/learning/deep-learning-from-scratch-learning-of-neural-network"
          ]
        }
      ]
    },
    {
      "@id": "https://afool.top/posts/learning/deep-learning-from-scratch-learning-of-neural-network/#article",
      "description": "敬请见证！（bushi",
      "headline": "深度学习入门：神经网络的学习",
      "inLanguage": "zh-CN",
      "thumbnailUrl": "https://afool.top/afool.svg",
      "@type": [
        "Article",
        "BlogPosting"
      ],
      "author": {
        "@id": "https://afool.top/#/schema/person/632466c"
      },
      "image": {
        "@id": "https://afool.top/#/schema/image/789ab98"
      },
      "isPartOf": {
        "@id": "https://afool.top/posts/learning/deep-learning-from-scratch-learning-of-neural-network/#webpage"
      },
      "mainEntityOfPage": {
        "@id": "https://afool.top/posts/learning/deep-learning-from-scratch-learning-of-neural-network/#webpage"
      },
      "publisher": {
        "@id": "https://afool.top/#identity"
      }
    },
    {
      "@id": "https://afool.top/#/schema/person/632466c",
      "@type": "Person",
      "name": "零歌",
      "url": "https://valaxy.site"
    },
    {
      "@id": "https://afool.top/#/schema/image/2177a58",
      "@type": "ImageObject",
      "contentUrl": "https://afool.top/images/nekosense.jpeg",
      "inLanguage": "zh-CN",
      "url": "https://afool.top/images/nekosense.jpeg"
    },
    {
      "@id": "https://afool.top/#/schema/image/789ab98",
      "@type": "ImageObject",
      "contentUrl": "https://afool.top/afool.svg",
      "inLanguage": "zh-CN",
      "url": "https://afool.top/afool.svg"
    }
  ]
}</script><link rel="stylesheet" href="/assets/post-1d1be697.css"><link rel="stylesheet" href="/assets/index-67f11a9b.css"><link rel="stylesheet" href="/assets/ValaxyMain-e55e6dd1.css"></body></html>