---
title: 深度学习入门：卷积神经网络
tags:
  - 深度学习
  - 卷积神经网络
categories:
  - 快去学习
date: 2022-11-24 22:52:03
updated: 2022-11-24 22:52:03
katex: true
---

**施工中**

内容参考：

- 《深度学习入门：基于 Python 的理论与实现》(斋藤康毅)
- [上述书籍作者提供的代码](https://github.com/oreilly-japan/deep-learning-from-scratch)

## CNN（卷积神经网络）是什么样的？

之前用到的神经网络中，相邻层所有的神经元之间都有连接，那么这些层就是所谓的**全连接层**。前面的全连接的神经网络中的每层可以看作是由 Affine 层和激活函数 ReLU/Sigmoid 层组成的，而最后是由 Softmax 层输出结果，整体的结构就像这样：

![基于全连接层（Affine 层）的网络的例子](https://s2.loli.net/2022/11/24/K1lrG2doEiOvzfT.png)

而 CNN 的结构就像是这样：

![CNN 的例子](https://s2.loli.net/2022/11/24/9itHWlSMq85uswc.png)

引入了卷积层（Convolution）和池化层（Pooling），Affine-ReLU 的连接方式被换成了 Convolution-ReLU-Pooling（不过有时会省略池化层）。

*接近输出的位置有时也会使用全连接层的那种结构。*

~~那么就从新引入的两种层结构讲起吧。~~

## 卷积层

为什么要引入卷积层呢？这是因为全连接层（Affine）存在一些问题。比如前面使用 MNIST 数据集的例子，图像本来是1通道、高28像素、长28像素的（1, 28, 28）三维形状，但输入时却*被排成一列，以784个数据的形式输入到最开始的 Affine 层*。对于图像而言，邻近的像素之间可能存在某种关联性，但是全连接层忽视了图像数据原本的形状，显然丢掉了这种信息。

而卷积层不会有这个问题，它能按图像数据原本的三维形式接收它们，并以同样的形式传到下一层。这样就有可能找出藏在图像形状里的信息。

### 卷积运算
