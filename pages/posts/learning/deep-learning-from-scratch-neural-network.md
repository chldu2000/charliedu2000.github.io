---
title: æ·±åº¦å­¦ä¹ å…¥é—¨ï¼šç¥ç»ç½‘ç»œ
tags:
  - æ·±åº¦å­¦ä¹ 
  - ç¥ç»ç½‘ç»œ
categories:
  - å¿«å»å­¦ä¹ 
date: 2022-10-05 21:17:12
updated: 2022-10-05 21:17:12
katex: true
---

å†…å®¹å‚è€ƒï¼š

- ã€Šæ·±åº¦å­¦ä¹ å…¥é—¨ï¼šåŸºäº Python çš„ç†è®ºä¸å®ç°ã€‹(æ–‹è—¤åº·æ¯…)
- [ä¸Šè¿°ä¹¦ç±ä½œè€…æä¾›çš„ä»£ç ](https://github.com/oreilly-japan/deep-learning-from-scratch)

ä»£ç ä¸­å¦‚æœå‡ºç° `np`ï¼Œåº”è¯¥éƒ½æ˜¯å› ä¸ºå¿½ç•¥äº† `import numpy as np`ï¼Œè¯·ä¸è¦åœ¨æ„ã€‚

## ä»æ„ŸçŸ¥æœºåˆ°ç¥ç»ç½‘ç»œ

é€šè¿‡å‰é¢å­¦çš„å†…å®¹å¯ä»¥çœ‹å‡ºæ¥æ„ŸçŸ¥æœºä¹Ÿèƒ½è¡¨ç¤ºå¤æ‚çš„å†…å®¹ï¼Œä½†æ˜¾ç„¶ç¡®å®šæƒé‡æ˜¯ä¸ªéº»çƒ¦äº‹ã€‚å¥½æ¶ˆæ¯æ˜¯ï¼Œç°åœ¨æœ‰ç¥ç»ç½‘ç»œè¿™ä¸ªä¸œè¥¿èƒ½è‡ªåŠ¨ä»æ•°æ®ä¸­å­¦ä¹ åˆ°åˆé€‚çš„æƒé‡å‚æ•°ã€‚é‚£å°±çœ‹çœ‹å§ã€‚

ç”¨å›¾è¡¨ç¤ºç¥ç»ç½‘ç»œï¼š

![ç¥ç»ç½‘ç»œçš„åŸºæœ¬ç»“æ„](https://s2.loli.net/2022/10/06/56M1dzptNKeiXIq.png)

ä¸­é—´å±‚æœ‰æ—¶ä¹Ÿè¢«ç§°ä¸º**éšè—å±‚**ï¼ˆâ€œè‚‰çœ¼çœ‹ä¸è§â€ï¼‰ã€‚

ä»å›¾ä¸­å¯ä»¥çœ‹å‡ºï¼Œç¥ç»ç½‘ç»œçš„å½¢çŠ¶å’Œæ„ŸçŸ¥æœºå¾ˆåƒã€‚*å®é™…ä¸Šï¼Œå°±ç¥ç»å…ƒçš„è¿æ¥æ–¹å¼è€Œè¨€ï¼Œä¸æ„ŸçŸ¥æœºå¹¶æ²¡æœ‰ä»»ä½•å·®å¼‚*ã€‚æ—¢ç„¶å¦‚æ­¤ï¼Œå®ƒä»¬æœ‰ä»€ä¹ˆåŒºåˆ«å‘¢ï¼Ÿå°±ä»ä¿¡å·çš„ä¼ é€’æ–¹å¼å…¥æ‰‹å§ã€‚

åœ¨æ¢ç©¶ç¥ç»ç½‘ç»œä¹‹å‰ï¼Œéœ€è¦å†çœ‹ä¸€ä¸‹æ„ŸçŸ¥æœºï¼Œè¿™æ˜¯æ„ŸçŸ¥æœºçš„ç½‘ç»œç»“æ„ï¼ˆè¿™ä¸ªå›¾å¹¶æ²¡æœ‰è¡¨ç¤ºå‡ºåç½®ï¼Œè¦ä½“ç°åç½®çš„è¯éœ€è¦å†åŠ ä¸€ä¸ªè¡¨ç¤ºåç½®çš„è¾“å…¥ä¿¡å·ï¼‰ï¼š

![æ„ŸçŸ¥æœºçš„ç»“æ„](https://s2.loli.net/2022/10/06/9bpEaniNYfl7eq3.png)

ç”¨æ•°å­¦å¼è¡¨ç¤ºè¿™ä¸ªæ„ŸçŸ¥æœºï¼š

$$ y = \begin{cases} 0 & (b + w_1 x_1 + w_2 x_2 \le 0) \\\ 1 & (b + w_1 x_1 + w_2 x_2 \gt 0) \end{cases} $$

è¿™ä¸ªæ•°å­¦å¼å¯ä»¥æ”¹å†™æˆï¼š

$$ y = h(b + w_1 x_1 + w_2 x_2) $$

å…¶ä¸­ï¼š

$$ h(x) = \begin{cases} 0 & (x \le 0) \\\ 1 & (x \gt 0) \end{cases} $$

è¾“å…¥ä¿¡å·çš„æ€»å’Œè¢«å‡½æ•° $h(x)$ è½¬æ¢ä¹‹åæ‰æ˜¯è¾“å‡º $y$ã€‚

### è½®åˆ°æ¿€æ´»å‡½æ•°ä¸Šåœºâ€¦â€¦

ä¸Šé¢çš„ $h(x)$ é€šå¸¸è¢«ç§°ä¸º**æ¿€æ´»å‡½æ•°**ï¼Œå®ƒå†³å®šå¦‚ä½•æ¿€æ´»è¾“å…¥ä¿¡å·çš„æ€»å’Œã€‚é‚£ä¹ˆä¸Šé¢çš„å¼å­ä¹Ÿå¯ä»¥è¡¨ç¤ºä¸ºï¼š

$$ a = b + w_1 x_1 + w_2 x_2 \\\ y = h(a) $$

ä¹Ÿå°±æ˜¯è¯´ï¼Œè®¡ç®—è¾“å‡ºçš„è¿‡ç¨‹å¯ä»¥åˆ†ä¸ºï¼šè®¡ç®—è¾“å…¥ä¿¡å·çš„æ€»å’Œã€ç”¨æ¿€æ´»å‡½æ•°è½¬æ¢è¿™ä¸€æ€»å’Œã€‚åœ¨ç¥ç»å…ƒä¸­æ˜ç¡®è¡¨ç¤ºå‡ºæ¿€æ´»å‡½æ•°çš„è®¡ç®—è¿‡ç¨‹ï¼ˆä¸‹å›¾åŒ…å«åç½®ï¼‰ï¼š

![æ˜ç¡®è¡¨ç¤ºå‡ºæ¿€æ´»å‡½æ•°çš„è®¡ç®—è¿‡ç¨‹](https://s2.loli.net/2022/10/06/sFzIqrO1hoN926V.png)

#### å¸¸ç”¨çš„æ¿€æ´»å‡½æ•°

- é˜¶è·ƒå‡½æ•°
  - è¾“å…¥ä¸è¶…è¿‡0æ—¶è¾“å‡º0ï¼Œè¶…è¿‡0æ—¶è¾“å‡º1ã€‚
  - ![é˜¶è·ƒå‡½æ•°çš„å›¾å½¢](https://s2.loli.net/2022/10/06/fhCzFJSnbaIRpym.png)
- sigmoid å‡½æ•°
  - $h(x) = \frac{1}{1 + exp(-x)}$ï¼Œå…¶ä¸­ $exp(-x)$ è¡¨ç¤º $e^{-x}$
  - ![sigmoid å‡½æ•°çš„å›¾å½¢](https://s2.loli.net/2022/10/06/hNPZtR67nGjQyBq.png)

å¯è¡Œçš„å®ç°ï¼š

```python
# é˜¶è·ƒå‡½æ•°ï¼Œæ”¯æŒ numpy æ•°ç»„çš„å®ç°
def step_function(x):
    y = x > 0  # å¯¹ numpy æ•°ç»„è¿›è¡Œä¸ç­‰å·è¿ç®—åï¼Œæ•°ç»„ä¸­çš„å„ä¸ªå…ƒç´ éƒ½ä¼šè¿›è¡Œç›¸åº”è¿ç®—ï¼Œç”Ÿæˆä¸€ä¸ªå¸ƒå°”å‹æ•°ç»„
    return y.astype(np.int32)  # å°†å¸ƒå°”å‹æ•°ç»„è½¬æ¢ä¸º int32

def sigmoid(x):
    return 1 / (1 + np.exp(-x))  # ç”±äº numpy çš„å¹¿æ’­åŠŸèƒ½ï¼Œè¯¥å®ç°å¯ä»¥æ”¯æŒ numpy æ•°ç»„
```

æ˜¾ç„¶ï¼š

- sigmoid å‡½æ•°å›¾åƒæ˜¯ä¸€æ¡å¹³æ»‘æ›²çº¿ï¼Œé˜¶è·ƒå‡½æ•°ä»¥0ä¸ºç•Œï¼Œè¾“å‡ºå‘ç”Ÿæ€¥å‰§å˜åŒ–ï¼›
- é˜¶è·ƒå‡½æ•°åªè¿”å›0æˆ–1ï¼Œsigmoid å‡½æ•°è¿”å›è¿ç»­çš„å®æ•°å€¼ï¼›
- ä¸¤è€…å½¢çŠ¶ç›¸ä¼¼ï¼Œä¸”éƒ½æ˜¯éçº¿æ€§å‡½æ•°ï¼›

> æ¿€æ´»å‡½æ•°å¿…é¡»ä½¿ç”¨éçº¿æ€§å‡½æ•°ï¼Œä¸ºä»€ä¹ˆï¼Ÿ
> 
> çº¿æ€§å‡½æ•°çš„é—®é¢˜åœ¨äºï¼Œä¸ç®¡å¦‚ä½•åŠ æ·±å±‚æ•°ï¼Œæ€»æ˜¯å­˜åœ¨ä¸ä¹‹ç­‰æ•ˆçš„â€œæ— éšè—å±‚çš„ç¥ç»ç½‘ç»œâ€ã€‚ä¸ºäº†å…·ä½“åœ°ï¼ˆç¨å¾®ç›´è§‚åœ°ï¼‰ç†è§£è¿™ä¸€ç‚¹ï¼Œæˆ‘ä»¬æ¥æ€è€ƒä¸‹é¢è¿™ä¸ªç®€å•çš„ä¾‹å­ã€‚è¿™é‡Œæˆ‘ä»¬è€ƒè™‘æŠŠçº¿æ€§å‡½æ•° $h(x) = cx$ ä½œä¸ºæ¿€æ´»å‡½æ•°ï¼ŒæŠŠ $y(x) = h(h(h(x)))$ çš„è¿ç®—å¯¹åº”3å±‚ç¥ç»ç½‘ç»œAã€‚è¿™ä¸ªè¿ç®—ä¼šè¿›è¡Œ $y(x) = c Ã— c Ã— c Ã— x$ çš„ä¹˜æ³•è¿ç®—ï¼Œä½†æ˜¯åŒæ ·çš„å¤„ç†å¯ä»¥ç”± $y(x) = ax$ï¼ˆæ³¨æ„ï¼Œ$a = c^3$ï¼‰è¿™ä¸€æ¬¡ä¹˜æ³•è¿ç®—ï¼ˆå³æ²¡æœ‰éšè—å±‚çš„ç¥ç»ç½‘ç»œï¼‰æ¥è¡¨ç¤ºã€‚å¦‚æœ¬ä¾‹æ‰€ç¤ºï¼Œä½¿ç”¨çº¿æ€§å‡½æ•°æ—¶ï¼Œæ— æ³•å‘æŒ¥å¤šå±‚ç½‘ç»œå¸¦æ¥çš„ä¼˜åŠ¿ã€‚å› æ­¤ï¼Œä¸ºäº†å‘æŒ¥å åŠ å±‚æ‰€å¸¦æ¥çš„ä¼˜åŠ¿ï¼Œæ¿€æ´»å‡½æ•°å¿…é¡»ä½¿ç”¨éçº¿æ€§å‡½æ•°ã€‚

æ®ä¹¦ä¸Šæ‰€è¯´ï¼Œæœ€è¿‘ä½¿ç”¨ **ReLU** å‡½æ•°çš„æ›´å¤šã€‚è¿™ä¸ªå‡½æ•°å¾ˆç®€å•ï¼Œè¾“å…¥å¤§äº0æ—¶ç›´æ¥è¾“å‡ºè¯¥å€¼ï¼Œè¾“å…¥ä¸å¤§äº0æ—¶è¾“å‡º0ã€‚

ReLU å‡½æ•°çš„ä¸€ç§å®ç°ï¼š

```python
def relu(x):
    return np.maximum(0, x)
```

## å¤šç»´æ•°ç»„çš„è¿ç®—

å¯ä»¥ç›´æ¥ç”¨ `numpy.array()` æ¥ç”Ÿæˆå¤šç»´æ•°ç»„ï¼Œæ¯”å¦‚ï¼š

```python
x = np.array([-1, 1, 0])
y = np.array([[1, 2], [3, 4]])
```

å¯ä»¥ç”¨ `numpy.ndim()` è·å–æ•°ç»„çš„ç»´æ•°ï¼Œç”¨æ•°ç»„å®ä¾‹çš„å±æ€§å˜é‡ `shape` ï¼ˆå…ƒç»„ç±»å‹ï¼‰è·å–å…¶å½¢çŠ¶ã€‚

æˆ‘ä»¬æœ€å¸¸ç”¨çš„å¤šç»´æ•°ç»„çš„è¿ç®—åº”è¯¥æ˜¯çŸ©é˜µï¼ˆäºŒç»´æ•°ç»„ï¼‰ä¹˜æ³•äº†ï¼ˆæˆ‘çŒœï¼‰ã€‚çŸ©é˜µä¹˜æ³•æ€ä¹ˆç®—å°±ä¸è¯´äº†ï¼Œå·¦è¾¹åˆ—æ•°ç­‰äºå³è¾¹è¡Œæ•°å°±è¡Œï¼Œåœ¨ä»£ç ä¸­å¯ä»¥ç”¨ `numpy.dot()` æ¥å®Œæˆã€‚çŸ©é˜µä¹˜æ³•çš„ä¾‹å­ï¼š

```python
A = np.array([[1, 2], [3, 4]])
B = np.array([[5, 6], [7, 8]])
print(np.dot(A, B))

A = np.array([[1,2], [3, 4], [5,6]])
B = np.array([7,8])
print(np.dot(A, B))
```

è¾“å‡ºï¼š

```bash
[[19 22]
 [43 50]]
[23 53 83]
```

### ç¥ç»ç½‘ç»œçš„å†…ç§¯

çŸ©é˜µä¹˜æ³•åˆå’Œç¥ç»ç½‘ç»œæœ‰ä»€ä¹ˆå…³ç³»å‘¢ï¼Ÿçœ‹è¿™ä¸ªç½‘ç»œï¼š

![ç¥ç»ç½‘ç»œå’ŒçŸ©é˜µä¹˜æ³•](https://s2.loli.net/2022/10/06/GSolM6v7B3AcWDd.png)

ä»å›¾ä¸Šå¯ä»¥çœ‹å‡ºï¼Œè¿™ä¸ªç¥ç»ç½‘ç»œçš„è®¡ç®—ç›¸å½“äº X çŸ©é˜µç‚¹ä¹˜ W çŸ©é˜µï¼Œå¯ä»¥ç”¨çŸ©é˜µè¿ç®—ä¸€æ¬¡æ€§ç®—å‡ºç»“æœï¼š

```python
x = np.array([1, 2])  # x1 x2
w = np.array([[1, 3, 5], [2, 4, 6]])  # æƒé‡
print(x)
print(x.shape)
print(w)
print(w.shape)
print(np.dot(x, w))
```

è¾“å‡ºç»“æœï¼š

```bash
[1 2]
(2,)
[[1 3 5]
 [2 4 6]]
(2, 3)
[ 5 11 17]
```

æ‰€ä»¥æˆ‘ä»¬å°±å¯ä»¥ç”¨çŸ©é˜µè¿ç®—ç®€åŒ–ä¿¡å·ä¼ é€’çš„è¿‡ç¨‹ï¼Œå¯å–œå¯è´ºã€‚

## ç¥ç»ç½‘ç»œçš„å®ç°

![è¦å®ç°çš„ç¥ç»ç½‘ç»œ](https://s2.loli.net/2022/10/06/vbICLGd341DRlnz.png)

å®ç°è¯¥ç¥ç»ç½‘ç»œã€‚å…¶ä¸­ï¼š

- è¾“å…¥å±‚ï¼ˆ0ï¼‰2ä¸ªç¥ç»å…ƒï¼›
- ç¬¬ä¸€ä¸ªéšè—å±‚ï¼ˆ1ï¼‰3ä¸ªç¥ç»å…ƒï¼Œç¬¬äºŒä¸ªéšè—å±‚ï¼ˆ2ï¼‰2ä¸ªç¥ç»å…ƒï¼›
- è¾“å‡ºå±‚ï¼ˆ3ï¼‰2ä¸ªç¥ç»å…ƒã€‚

ä¹¦ä¸­ç»™æˆ‘ä»¬å®šä¹‰äº†ç¬¦å·æ¥è¡¨ç¤ºç¥ç»å…ƒå’Œä¿¡å·ï¼Œä»¥æƒé‡çš„ç¬¦å·ä¸ºä¾‹ï¼š

![æƒé‡çš„ç¬¦å·](https://s2.loli.net/2022/10/06/p8sriFWC2tVNb1O.png)

### ä¿¡å·ä¼ é€’

ç¤ºä¾‹ï¼Œä»è¾“å…¥å±‚åˆ°ç¬¬1å±‚çš„ä¿¡å·ä¼ é€’ï¼Œè€ƒè™‘åç½®ï¼š

![è¾“å…¥å±‚åˆ°ç¬¬1å±‚çš„ä¿¡å·ä¼ é€’](https://s2.loli.net/2022/10/06/GkWuzmDV1QCqM2E.png)

å¯ä»¥ç”¨æ•°å­¦å¼æ¥è¡¨ç¤º $a_1^{(1)}$ï¼š

$$ a_1^{(1)} = w_{1 1}^{(1)}x_1 + w_{1 2}^{(1)}x_2 + b_1^{(1)} $$

å¦‚æœä½¿ç”¨çŸ©é˜µä¹˜æ³•ï¼Œå¯ä»¥å°†ç¬¬1å±‚çš„åŠ æƒå’Œè¡¨ç¤ºä¸ºå¦‚ä¸‹å½¢å¼ï¼š

$$ \boldsymbol{A}^{(1)} = \boldsymbol{X}\boldsymbol{W}^{(1)} + \boldsymbol{B}^{(1)} $$

å…¶ä¸­ï¼š

$$ \boldsymbol{A}^{(1)} = \begin{pmatrix} a_1^{(1)} & a_2^{(1)} & a_3^{(1)} \end{pmatrix} \\\ \boldsymbol{X} = \begin{pmatrix} x_1 & x_2 \end{pmatrix} \\\ \boldsymbol{B}^{(1)} = \begin{pmatrix} b_1^{(1)} & b_2^{(1)} & b_3^{(1)} \end{pmatrix} \\\ \boldsymbol{W}^{(1)} =  \begin{pmatrix} w_{1 1}^{(1)} & w_{2 1}^{(1)} & w_{3 1}^{(1)} \\\ w_{1 2}^{(1)} & w_{2 2}^{(1)} & w_{3 2}^{(1)} \end{pmatrix} $$

å†™æˆ Python å®ç°ï¼ˆæ‰‹åŠ¨æŒ‡å®šæƒé‡å’Œåç½®ï¼‰ï¼š

```python
X = np.array([1.0, 0.5])  # shape: (2, 3)
W1 = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])  # shape: (2,)
B1 = np.array([0.1, 0.2, 0.3])  # shape: (3,)
A1 = np.dot(X, W1) + B1
```

è€ƒè™‘æ¿€æ´»å‡½æ•°ï¼Œé‚£ä¹ˆç¬¬1å±‚çš„è®¡ç®—è¿‡ç¨‹å°±æ˜¯ï¼š

![è¾“å…¥å±‚åˆ°ç¬¬1å±‚çš„ä¿¡å·ä¼ é€’2](https://s2.loli.net/2022/10/06/T3uDapWMw1eK9Xq.png)

ä¸Šå›¾ä¸­éšè—å±‚çš„åŠ æƒå’Œï¼ˆåŠ æƒä¿¡å·ä¸åç½®çš„å’Œï¼‰ç”¨ $a$ è¡¨ç¤ºï¼Œè¢«æ¿€æ´»å‡½æ•°è½¬æ¢åçš„ä¿¡å·ç”¨ $z$ è¡¨ç¤ºã€‚$h()$ è¡¨ç¤ºæ¿€æ´»å‡½æ•°ï¼Œå¦‚æœä½¿ç”¨ sigmoid å‡½æ•°ä½œä¸ºæ¿€æ´»å‡½æ•°ï¼Œ$z$ çš„è®¡ç®—æ–¹æ³•å°±æ˜¯ `Z1 = sigmoid(A1)`ã€‚

ç”¨åŒæ ·çš„æ–¹æ³•å¯ä»¥å®ç°ç¬¬1å±‚åˆ°ç¬¬2å±‚çš„ä¿¡å·ä¼ é€’ï¼š

![ç¬¬1å±‚åˆ°ç¬¬2å±‚çš„ä¿¡å·ä¼ é€’](https://s2.loli.net/2022/10/06/Q8c1eOVod6WFSZu.png)

```python
W2 = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])
B2 = np.array([0.1, 0.2])
A2 = np.dot(Z1, W2) + B2  # ç¬¬1å±‚çš„è¾“å‡ºæ˜¯ç¬¬2å±‚çš„è¾“å…¥
Z2 = sigmoid(A2)
```

ä»ç¬¬2å±‚åˆ°è¾“å‡ºå±‚çš„å®ç°ä¸ä¸Šé¢ä¹ŸåŸºæœ¬ä¸€è‡´ï¼Œå°†æ’ç­‰å‡½æ•°ä½œä¸ºæ¿€æ´»å‡½æ•°ï¼ˆè¾“å‡ºå±‚çš„æ¿€æ´»å‡½æ•°ç”¨ $\sigma()$ è¡¨ç¤ºï¼‰ï¼š

```python
def identity_function(x):
    return x

W3 = np.array([[0.1, 0.3], [0.2, 0.4]])
B3 = np.array([0.1, 0.2])
A3 = np.dot(Z2, W3) + B3
Y = identity_function(A3)  # æˆ–è€…Y = A3
```

æ•´ç†ä¸Šé¢çš„å®ç°ï¼š

```python
# æŠŠæƒé‡è®°ä¸ºå¤§å†™å­—æ¯ï¼Œå…¶ä»–å¦‚åç½®å’Œä¸­é—´ç»“æœç­‰è®°ä¸ºå°å†™å­—æ¯
def init_network():
    network = {}
    network['W1'] = np.array([[0.1, 0.3, 0.5], [0.2, 0.4, 0.6]])
    network['b1'] = np.array([0.1, 0.2, 0.3])
    network['W2'] = np.array([[0.1, 0.4], [0.2, 0.5], [0.3, 0.6]])
    network['b2'] = np.array([0.1, 0.2])
    network['W3'] = np.array([[0.1, 0.3], [0.2, 0.4]])
    network['b3'] = np.array([0.1, 0.2])
    return network

# å°†è¾“å…¥ä¿¡å·è½¬åŒ–ä¸ºè¾“å‡ºä¿¡å·çš„è¿‡ç¨‹ï¼ˆå‰å‘ä¼ æ’­ï¼Ÿï¼‰
def forward(network, x):
    W1, W2, W3 = network['W1'], network['W2'], network['W3']
    b1, b2, b3 = network['b1'], network['b2'], network['b3']
    a1 = np.dot(x, W1) + b1
    z1 = sigmoid(a1)
    a2 = np.dot(z1, W2) + b2
    z2 = sigmoid(a2)
    a3 = np.dot(z2, W3) + b3
    y = identity_function(a3)
    return y

network = init_network()
x = np.array([1.0, 0.5])
y = forward(network, x)
print(y)  # [0.31682708 0.69627909]
```

## è¾“å‡ºå±‚çš„è®¾è®¡

ç¥ç»ç½‘ç»œå¯ä»¥ç”¨åœ¨åˆ†ç±»é—®é¢˜å’Œå›å½’é—®é¢˜ä¸Šï¼Œè¦æ ¹æ®æƒ…å†µæ”¹å˜ä½¿ç”¨çš„æ¿€æ´»å‡½æ•°ï¼Œä¸€èˆ¬å›å½’é—®é¢˜ç”¨æ’ç­‰å‡½æ•°ï¼Œåˆ†ç±»é—®é¢˜ç”¨ softmax å‡½æ•°ã€‚softmax å‡½æ•°å¯ä»¥ç”¨å¦‚ä¸‹å¼å­è¡¨ç¤ºï¼š

$$ y_k = \frac{exp(a_k)}{\sum\limits_{i=1}^{n}exp(a_i)} $$

å…¶ä¸­ $exp()$ æ˜¯è¡¨ç¤º $e^x$ çš„æŒ‡æ•°å‡½æ•°ã€‚è¯¥å¼å­å‡è®¾è¾“å‡ºå±‚å…±æœ‰ $n$ ä¸ªç¥ç»å…ƒï¼Œè®¡ç®—ç¬¬ $k$ ä¸ªç¥ç»å…ƒçš„è¾“å‡º $y_k$ã€‚softmax å‡½æ•°çš„åˆ†å­æ˜¯è¾“å…¥ä¿¡å· $a_k$ çš„æŒ‡æ•°å‡½æ•°ï¼Œåˆ†æ¯æ˜¯æ‰€æœ‰è¾“å…¥ä¿¡å·çš„æŒ‡æ•°å‡½æ•°çš„å’Œã€‚

ä»ä¸Šé¢å¯ä»¥çœ‹å‡ºè¾“å‡ºå±‚çš„å„ä¸ªç¥ç»å…ƒéƒ½å—åˆ°æ‰€æœ‰è¾“å…¥ä¿¡å·çš„å½±å“ã€‚ç”¨å›¾è¡¨ç¤ºè¿™ä¸ªå‡½æ•°ï¼Œå®ƒçš„è¾“å‡ºä¸æ‰€æœ‰çš„è¾“å…¥ä¿¡å·ç›¸è¿ï¼š

![softmax å‡½æ•°](https://s2.loli.net/2022/10/06/hANMxfLWD6pBvl5.png)

### softmax å‡½æ•°

ç›´æ¥å®ç° softmax å‡½æ•°ï¼š

```python
def softmax(a):
    exp_a = np.exp(a)
    sum_exp_a = np.sum(exp_a)
    y = exp_a / sum_exp_a
    return y
```

è¿™ä¸ªå®ç°æœ‰ç¼ºé™·ï¼Œä¸»è¦é—®é¢˜å‡ºåœ¨ `exp()` ä¸Šã€‚`exp(x)` è¡¨ç¤º $e^x$ï¼Œå½“ x æ¯”è¾ƒå¤§çš„æ—¶å€™ï¼Œç»“æœå¾ˆå®¹æ˜“æº¢å‡ºï¼ˆå¯ä»¥è‡ªè¡Œç®—ä¸€ä¸‹ï¼Œ`int` ç±»å‹æ ¹æœ¬ä¸å¤Ÿç”¨ï¼‰ã€‚ä¹¦çš„ä½œè€…ä»‹ç»äº†ä¸€ç§å¸¸ç”¨çš„ä¼˜åŒ–æ–¹æ³•ï¼Œé¦–å…ˆçœ‹è¿™ä¸ªå¼å­ï¼š

$$ \begin{aligned} y_k &= \frac{exp(a_k)}{\sum \limits_{i = 1}^n exp(a_i)} \\\ &= \frac{C exp(a_k)}{C \sum \limits_{i = 1}^n exp(a_i)} \\\ &= \frac{exp(a_k + \log C)}{\sum \limits_{i = 1}^n exp(a_i + \log C)} \\\ &= \frac{exp(a_k + C')}{\sum \limits_{i = 1}^n exp(a_i + C')} \end{aligned} $$

ä»è¿™ä¸ªå¼å­å¯ä»¥çœ‹å‡ºï¼Œè®¡ç®—æ—¶åœ¨æŒ‡æ•°ä¸ŠåŠ å‡ä»»æ„å¸¸æ•°éƒ½ä¸ä¼šæ”¹å˜è¿ç®—ç»“æœã€‚ä¸ºäº†é˜²æ­¢æº¢å‡ºï¼Œä¸€èˆ¬æ˜¯å‡å»è¾“å…¥ä¿¡å·ä¸­çš„æœ€å¤§å€¼ã€‚ä½œè€…ç»™å‡ºçš„ä¾‹å­ï¼š

```pycon
>>> a = np.array([1010, 1000, 990])
>>> np.exp(a) / np.sum(np.exp(a))  # softmaxå‡½æ•°çš„è¿ç®—
array([ nan, nan, nan])  # æº¢å‡º
>>>
>>> c = np.max(a) # 1010
>>> a - c
array([ 0, -10, -20])
>>>
>>> np.exp(a - c) / np.sum(np.exp(a - c))
array([ 9.99954600e-01, 4.53978686e-05, 2.06106005e-09])
```

æ‰€ä»¥ softmax å‡½æ•°çš„å®ç°å°±å¯ä»¥æ”¹æˆï¼š

```python
def softmax(a):
    c = np.max(a)  # è¾“å…¥ä¿¡å·çš„æœ€å¤§å€¼
    exp_a = np.exp(a - c)  # æº¢å‡ºå¯¹ç­–
    sum_exp_a = np.sum(exp_a)
    y = exp_a / sum_exp_a
    return y
```

softmax å‡½æ•°çš„è¾“å‡ºæ˜¯0.0åˆ°1.0ä¹‹é—´çš„å®æ•°ï¼Œè¾“å‡ºå€¼çš„æ€»å’Œæ˜¯1ï¼Œæ‰€ä»¥ softmax å‡½æ•°çš„è¾“å‡ºä¹Ÿå¯ä»¥è¢«è§£é‡Šä¸ºæ¦‚ï¼Œä¹Ÿå› ä¸ºè¿™æ ·ï¼Œsoftmax å‡½æ•°é€‚ç”¨äºåˆ†ç±»é—®é¢˜ã€‚

ç”±äº softmax å‡½æ•°ä¸ä¼šæ”¹å˜å„ä¸ªå…ƒç´ ä¹‹é—´çš„å¤§å°å…³ç³»ï¼ˆå› ä¸ºæŒ‡æ•°å‡½æ•°æ˜¯å•è°ƒé€’å¢çš„ï¼‰ï¼Œå¦‚æœåªéœ€è¦çŸ¥é“è¾“å‡ºå€¼æœ€å¤§çš„ç¥ç»å…ƒå¯¹åº”çš„ç±»åˆ«ï¼Œå¯ä»¥å¿½ç•¥è¾“å‡ºå±‚çš„ softmax å‡½æ•°ä»¥å‡å°‘è¿ç®—é‡ã€‚

### è¾“å‡ºå±‚çš„ç¥ç»å…ƒæ•°é‡

è¾“å‡ºå±‚çš„ç¥ç»å…ƒæ•°é‡å–å†³äºå¾…è§£å†³çš„é—®é¢˜ã€‚å¯¹äºåˆ†ç±»é—®é¢˜ï¼Œä¸€èˆ¬æŠŠè¾“å‡ºå±‚ç¥ç»å…ƒæ•°é‡è®¾å®šä¸ºç±»åˆ«çš„æ•°é‡ã€‚

## å®é™…é—®é¢˜ï¼šæ‰‹å†™æ•°å­—è¯†åˆ«

å¯¹äºè¿™ä¸ªé—®é¢˜ï¼Œä¹¦çš„ä½œè€…æä¾›äº†å¯ä»¥ç›´æ¥ä½¿ç”¨çš„å­¦ä¹ ç»“æœï¼Œåªéœ€è¦å®ç°ç¥ç»ç½‘ç»œçš„æ¨ç†å¤„ç†è¿‡ç¨‹ï¼ˆå‰å‘ä¼ æ’­ï¼‰å°±å¯ä»¥äº†ã€‚

> ä½¿ç”¨ MNIST æ•°æ®é›†ã€‚è¯¥æ•°æ®é›†ç”±0åˆ°9çš„æ•°å­—å›¾åƒæ„æˆï¼Œè®­ç»ƒå›¾åƒ6ä¸‡å¼ ï¼Œæµ‹è¯•å›¾åƒ1ä¸‡å¼ ã€‚å…ˆç”¨è®­ç»ƒå›¾åƒè¿›è¡Œå­¦ä¹ ï¼Œå†ç”¨å­¦ä¹ åˆ°çš„æ¨¡å‹åº¦é‡èƒ½åœ¨å¤šå¤§ç¨‹åº¦ä¸Šå¯¹æµ‹è¯•å›¾åƒè¿›è¡Œæ­£ç¡®çš„åˆ†ç±»ã€‚
>
> MNISTçš„å›¾åƒæ•°æ®æ˜¯28åƒç´  Ã— 28åƒç´ çš„ç°åº¦å›¾åƒï¼ˆ1é€šé“ï¼‰ï¼Œå„ä¸ªåƒç´ çš„å–å€¼åœ¨0åˆ°255ä¹‹é—´ã€‚æ¯ä¸ªå›¾åƒæ•°æ®éƒ½ç›¸åº”åœ°æ ‡æœ‰â€œ7â€ã€â€œ2â€ã€â€œ1â€ç­‰æ ‡ç­¾ã€‚

ä¸‹è½½ã€åŠ è½½æ•°æ®é›†ç­‰éœ€è¦æå‰å‡†å¤‡çš„ä»£ç ä½œè€…ä¹Ÿç»™å‡ºæ¥äº†ï¼Œåœ¨[è¿™é‡Œ](https://github.com/oreilly-japan/deep-learning-from-scratch/blob/master/dataset/mnist.py)ã€‚

éœ€è¦å®ç°çš„ç¥ç»ç½‘ç»œè¾“å…¥å±‚æœ‰784ä¸ªç¥ç»å…ƒï¼ˆæ¯å¼ å›¾ç‰‡784åƒç´ ï¼‰ï¼Œè¾“å‡ºå±‚æœ‰10ä¸ªç¥ç»å…ƒï¼ˆ10ä¸ªæ•°å­—åˆ†ç±»ï¼‰ã€‚æŒ‰ç…§ä½œè€…çš„æç¤ºï¼Œè®¾ç½®ä¸¤ä¸ªéšè—å±‚ï¼Œç¬¬ä¸€ä¸ªéšè—å±‚æœ‰50ä¸ªç¥ç»å…ƒï¼Œç¬¬äºŒä¸ªéšè—å±‚æœ‰100ä¸ªç¥ç»å…ƒã€‚

```python
import sys, os
sys.path.append(os.curdir)
print(sys.path)
from dataset.mnist import load_mnist
import pickle
import numpy as np

# å®ç° sigmoid å‡½æ•°
# å½“ç„¶åƒè¿™ç§é€šç”¨çš„å‡½æ•°æœ€å¥½ç‰¹æ„æ‰¾ä¸ªåœ°æ–¹å†™å®ç°ï¼Œä¸è¦å†™å¾—åˆ°å¤„éƒ½æ˜¯â€¦â€¦
def sigmoid(x):
    return 1 / (1 + np.exp(-x))  # ç”±äº numpy çš„å¹¿æ’­åŠŸèƒ½ï¼Œè¯¥å®ç°å¯ä»¥æ”¯æŒ numpy æ•°ç»„

def softmax(a):
    c = np.max(a)
    exp_a = np.exp(a - c) # æº¢å‡ºå¯¹ç­–
    sum_exp_a = np.sum(exp_a)
    y = exp_a / sum_exp_a
    return y

# è·å–æµ‹è¯•æ•°æ®
# å¯¹æ•°æ®è¿›è¡Œäº†æ­£è§„åŒ–å¤„ç†ï¼ˆå±äºé¢„å¤„ç†ï¼‰ï¼Œä½¿æ•°æ®çš„å€¼åœ¨0.0ï½1.0çš„èŒƒå›´å†…
def get_data():
    (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False)
    return x_test, t_test

# è¯»å…¥å­¦ä¹ åˆ°çš„æƒé‡å‚æ•°
def init_network():
    # rb, read as text, binary
    with open("ch0203/sample_weight.pkl", 'rb') as f:
        network = pickle.load(f)
    return network

# å‰å‘ä¼ æ’­æ¨ç†è¿‡ç¨‹
def predict(network, x):
    w1, w2, w3 = network['W1'], network['W2'], network['W3']
    b1, b2, b3 = network['b1'], network['b2'], network['b3']

    a1 = np.dot(x, w1) + b1
    z1 = sigmoid(a1)
    a2 = np.dot(z1, w2) + b2
    z2 = sigmoid(a2)
    a3 = np.dot(z2, w3) + b3
    y = softmax(a3)
    return y

x, t = get_data()
network = init_network()
accuracy_cnt = 0  # è¯†åˆ«ç²¾åº¦
for i in range(len(x)):
    y = predict(network, x[i])
    p = np.argmax(y)  # å–æ¦‚ç‡æœ€é«˜çš„å…ƒç´ çš„ç´¢å¼•
    if p == t[i]:
        accuracy_cnt += 1

print("Accuracy: " + str(float(accuracy_cnt) / len(x)))
```

PSï¼šå¦‚æœå»çœ‹ä½œè€…ç»™çš„[å®ç°ä»£ç ](https://github.com/oreilly-japan/deep-learning-from-scratch/blob/master/ch03/neuralnet_mnist.py)ï¼Œä¼šå‘ç°æœ€å¼€å§‹æ·»åŠ è·¯å¾„ï¼Œä½œè€…æ·»åŠ äº† `pardir`ï¼Œæˆ‘è¿™é‡Œæ·»åŠ çš„æ˜¯ `curdir`ï¼Œè¯»å–æƒé‡æ—¶çš„æ–‡ä»¶è·¯å¾„ä¹Ÿä¸å¤ªä¸€æ ·ã€‚è¿™æ˜¯å› ä¸ºæˆ‘æ‰“å¼€é¡¹ç›®æ—¶çš„å·¥ä½œç›®å½•åœ¨ `ch0203`ï¼ˆç›¸å½“äºä½œè€…çš„ `ch03`ï¼‰ä¸Šé¢ä¸€å±‚ï¼Œè€Œä½œè€…è®¾å®šçš„å·¥ä½œç›®å½•å°±æ˜¯ `ch03`â€¦â€¦å—¯ï¼Œåº”è¯¥æ˜¯è¿™ä¸ªåŸå› å§ï¼Œæˆ‘è¿˜æœäº†æŒºé•¿ä¸€æ®µæ—¶é—´â€¦â€¦ğŸ˜¢

### æ‰¹å¤„ç†

è§‚å¯Ÿä¸€ä¸‹ç¥ç»ç½‘ç»œå„å±‚æƒé‡çš„å½¢çŠ¶ï¼š

```pycon
>>> x, _ = get_data()
>>> network = init_network()
>>> W1, W2, W3 = network['W1'], network['W2'], network['W3']
>>>
>>> x.shape
(10000, 784)
>>> x[0].shape
(784,)
>>> W1.shape
(784, 50)
>>> W2.shape
(50, 100)
>>> W3.shape
(100, 10)
```

~~æ˜¾ç„¶ç¬¦åˆçŸ©é˜µè¿ç®—çš„è¦æ±‚ã€‚~~å¤šç»´æ•°ç»„å½¢çŠ¶å˜åŒ–è¿‡ç¨‹å¦‚å›¾ï¼ˆ$X$ çš„å½¢çŠ¶ä¹Ÿå¯ä»¥è¡¨ç¤ºä¸º $1 \times 784$ï¼ŒåŒç† $Y$ çš„å½¢çŠ¶ä¹Ÿå¯ä»¥è¡¨ç¤ºä¸º $1 \times 10$ï¼‰ï¼š

![æ•°ç»„å½¢çŠ¶çš„å˜åŒ–](https://s2.loli.net/2022/10/07/l25NM8BjZ3ohcfg.png)

ä»æ•´ä½“çš„æµç¨‹æ¥çœ‹ï¼Œè¾“å…¥ä¸€ä¸ªç”±784ä¸ªå…ƒç´ æ„æˆçš„ä¸€ç»´æ•°ç»„åï¼Œè¾“å‡ºä¸€ä¸ªæœ‰10ä¸ªå…ƒç´ çš„ä¸€ç»´æ•°ç»„ã€‚è€ƒè™‘ä¸€æ¬¡æ€§å¤„ç†100å¼ å›¾ç‰‡ï¼Œé‚£ä¹ˆè¾“å…¥æ•°ç»„çš„å½¢çŠ¶å¯ä»¥æ”¹æˆ $100 \times 784$ï¼Œæ­¤æ—¶å¤šç»´æ•°ç»„/çŸ©é˜µå½¢çŠ¶çš„å˜åŒ–è¿‡ç¨‹å°±ä¼šæ˜¯ï¼š

![æ‰¹å¤„ç†ä¸­æ•°ç»„å½¢çŠ¶çš„å˜åŒ–](https://s2.loli.net/2022/10/07/3eWDaKFkYHp6riU.png)

è¿™æ ·è¾“å‡ºæ•°æ®çš„å½¢çŠ¶å°±æ˜¯ $100 \times 10$ã€‚*è¿™è¡¨ç¤ºè¾“å…¥çš„100å¼ å›¾åƒçš„ç»“æœè¢«ä¸€æ¬¡æ€§è¾“å‡ºäº†ã€‚æ¯”å¦‚ï¼Œ`x[0]`å’Œ`y[0]`ä¸­ä¿å­˜äº†ç¬¬0å¼ å›¾åƒåŠå…¶æ¨ç†ç»“æœï¼Œx[1]å’Œy[1]ä¸­ä¿å­˜äº†ç¬¬1å¼ å›¾åƒåŠå…¶æ¨ç†ç»“æœï¼Œç­‰ç­‰ã€‚* 

*è¿™ç§æ‰“åŒ…å¼çš„è¾“å…¥æ•°æ®è¢«ç§°ä¸ºæ‰¹ï¼ˆbatchï¼‰ã€‚*

æ‰¹å¤„ç†çš„å®ç°ï¼š

```python
import sys, os
sys.path.append(os.curdir)
print(sys.path)
from dataset.mnist import load_mnist
import pickle
import numpy as np

# å®ç° sigmoid å‡½æ•°
# å½“ç„¶åƒè¿™ç§é€šç”¨çš„å‡½æ•°æœ€å¥½ç‰¹æ„æ‰¾ä¸ªåœ°æ–¹å†™å®ç°ï¼Œä¸è¦å†™å¾—åˆ°å¤„éƒ½æ˜¯â€¦â€¦
def sigmoid(x):
    return 1 / (1 + np.exp(-x))  # ç”±äº numpy çš„å¹¿æ’­åŠŸèƒ½ï¼Œè¯¥å®ç°å¯ä»¥æ”¯æŒ numpy æ•°ç»„

def softmax(a):
    c = np.max(a)
    exp_a = np.exp(a - c) # æº¢å‡ºå¯¹ç­–
    sum_exp_a = np.sum(exp_a)
    y = exp_a / sum_exp_a
    return y

# è·å–æµ‹è¯•æ•°æ®
# å¯¹æ•°æ®è¿›è¡Œäº†æ­£è§„åŒ–å¤„ç†ï¼ˆå±äºé¢„å¤„ç†ï¼‰ï¼Œä½¿æ•°æ®çš„å€¼åœ¨0.0ï½1.0çš„èŒƒå›´å†…
def get_data():
    (x_train, t_train), (x_test, t_test) = load_mnist(normalize=True, flatten=True, one_hot_label=False)
    return x_test, t_test

# è¯»å…¥å­¦ä¹ åˆ°çš„æƒé‡å‚æ•°
def init_network():
    # rb, read as text, binary
    with open("ch0203/sample_weight.pkl", 'rb') as f:
        network = pickle.load(f)
    return network

# å‰å‘ä¼ æ’­æ¨ç†è¿‡ç¨‹
def predict(network, x):
    w1, w2, w3 = network['W1'], network['W2'], network['W3']
    b1, b2, b3 = network['b1'], network['b2'], network['b3']

    a1 = np.dot(x, w1) + b1
    z1 = sigmoid(a1)
    a2 = np.dot(z1, w2) + b2
    z2 = sigmoid(a2)
    a3 = np.dot(z2, w3) + b3
    y = softmax(a3)
    return y

x, t = get_data()
network = init_network()

batch_size = 100  # â€œä¸€æ‰¹â€çš„å¤§å°
accuracy_cnt = 0  # è¯†åˆ«ç²¾åº¦

for i in range(0, len(x), batch_size):  # range(start, end, step)
    x_batch = x[i:i+batch_size]  # æŒ‰æ‰¹å–å‡ºæ•°æ®
    y_batch = predict(network, x_batch)
    p = np.argmax(y_batch, axis=1)  # åœ¨100*10çš„æ•°ç»„ä¸­ï¼Œæ²¿ç€ç¬¬1ç»´ï¼ˆä»0å¼€å§‹æ•°ï¼‰æ–¹å‘æ‰¾åˆ°å€¼æœ€å¤§çš„å…ƒç´ çš„ç´¢å¼•
    accuracy_cnt += np.sum(p == t[i:i+batch_size])  # ä½¿ç”¨æ¯”è¾ƒè¿ç®—ç¬¦ä¼šç”Ÿæˆå¸ƒå°”å€¼æ•°ç»„ï¼Œsum ä¼šè®¡ç®— True çš„ä¸ªæ•°

print("Accuracy: " + str(float(accuracy_cnt) / len(x)))
```

*å¤§å¤šæ•°å¤„ç†æ•°å€¼è®¡ç®—çš„åº“éƒ½è¿›è¡Œäº†èƒ½å¤Ÿé«˜æ•ˆå¤„ç†å¤§å‹æ•°ç»„è¿ç®—çš„æœ€ä¼˜åŒ–*ï¼Œè€Œä¸”æ‰¹å¤„ç†å¯ä»¥å‡å°‘è¯»å–æ•°æ®æ–¹é¢çš„å¼€é”€ï¼Œæ‰€ä»¥æ‰¹å¤„ç†è®¡ç®—å¤§å‹æ•°ç»„æ¯”åˆ†å¼€è®¡ç®—å„ä¸ªå°æ•°ç»„é€Ÿåº¦å¿«ã€‚

PPSï¼šè¿™ä¸€éƒ¨åˆ†è¯´æ˜¯ç¥ç»ç½‘ç»œï¼Œå…¶å®åº”è¯¥è¯´æ˜¯ç¥ç»ç½‘ç»œçš„å‰å‘ä¼ æ’­å’¯â€¦â€¦é‚£å°±å…ˆåˆ°è¿™é‡Œã€‚